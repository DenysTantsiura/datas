{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HWW5:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В домашньому завданні до даного модулю ви потренуєтесь робити тестове завдання для влаштування на роботу. \n",
    "За даними акселерометра з мобільного телефону потрібно класифікувати, якою діяльністю займається людина: йде, стоїть, біжить чи йде по сходах. \n",
    "Знайти датасет ви можете за посиланням....\n",
    "\n",
    "Використайте алгоритми SVM та випадковий ліс з бібліотеки scikit-learn. Як характеристики можете брати показники з акселерометра, проте щоб покращити результати роботи алгоритмів, спочатку можна підготувати наш датасет і розрахувати часові ознаки (time domain features). Більше ці характеристики описані в даній статті.\n",
    "\n",
    "Порівняйте результати роботи обох алгоритмів на різних фічах та різні моделі між собою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Union\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_csvfile(file: Path) -> pd.DataFrame:\n",
    "    \"\"\"Read content from csv-file and return dataframe from content.\"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "classification_human_activity = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.geeksforgeeks.org/different-ways-to-create-pandas-dataframe/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.skew.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.kurt.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmax.html\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.idxmin.html\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html\n",
    "- https://stackoverflow.com/questions/53177327/how-to-compute-shannon-entropy-of-information-from-a-pandas-dataframe\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistical_features(y: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # y - type real data; df - sample data. \n",
    "    if y not in classification_human_activity:\n",
    "        classification_human_activity[y] = len(classification_human_activity)\n",
    "\n",
    "    data = {\n",
    "            'activity': [classification_human_activity[y]],\n",
    "            # 'max_x': [max(df['accelerometer_X'])],  # [df['accelerometer_X'].describe().loc['max']],\n",
    "            # 'min_x': [min(df['accelerometer_X'])],  # [df['accelerometer_X'].describe().loc['min']],\n",
    "            # 'mean_x': [df['accelerometer_X'].mean(axis=0)],  # [df['accelerometer_X'].describe().loc['mean']],\n",
    "            # 'med_x': [df['accelerometer_X'].median(axis=0)],  # median\n",
    "            # 'std_x': [df['accelerometer_X'].std(axis=0)],  # Standard deviation !!= [df['accelerometer_Y'].describe().loc['std']], \n",
    "            # 'skew_x': [df['accelerometer_X'].skew(axis=0)],  # skewness\n",
    "            # 'kurt_x': [df['accelerometer_X'].skew(axis=0)],  # kurtosis\n",
    "            # 'var_x': [df['accelerometer_X'].var(axis=0)],  # variance\n",
    "            # 'idxmax_x': [df['accelerometer_X'].idxmax(axis=0)],  # index of first occurrence of maximum over requested axis\n",
    "            # 'idxmin_x': [df['accelerometer_X'].idxmin(axis=0)],  # index of first occurrence of minimum over requested axis\n",
    "            }\n",
    "    [data.update({\n",
    "                  f'max_{col[-1]}':[max(df[col])],\n",
    "                  f'min_{col[-1]}':[min(df[col])],\n",
    "                  f'mean_{col[-1]}':[df[col].mean(axis=0)],\n",
    "                  f'med_{col[-1]}':[df[col].median(axis=0)],  # median\n",
    "                  f'std_{col[-1]}':[df[col].std(axis=0)],  # Standard deviation\n",
    "                  f'skew_{col[-1]}':[df[col].skew(axis=0)],  # skewness\n",
    "                  f'kurt_{col[-1]}':[df[col].kurt(axis=0)],  # kurtosis\n",
    "                  f'var_{col[-1]}':[df[col].var(axis=0)],  # variance\n",
    "                  f'idxmax_{col[-1]}':[df[col].idxmax(axis=0)],  # index of first occurrence of maximum over requested axis\n",
    "                  f'idxmin_{col[-1]}':[df[col].idxmin(axis=0)],  # index of first occurrence of minimum over requested axis\n",
    "                #   f'rmse_{col[-1]}':[mean_squared_error(df[col], np.array([df[col].mean(axis=0) for _ in range(df.shape[0])]), squared=False)],  # Root Mean Square Error\n",
    "                #   f'mae_{col[-1]}':[mean_absolute_error(df[col], np.array([df[col].mean(axis=0) for _ in range(df.shape[0])]))],  # mean absolute error\n",
    "                  }) \n",
    "        for col in df.columns]\n",
    "\n",
    "    [data.update({\n",
    "                #   f'rmse_{col[-1]}':[mean_squared_error(df[col], np.array([data[f'mean_{col[-1]}'] for __ in range(df.shape[0])]), squared=False)],  # variance# Root Mean Square Error\n",
    "                #   f'mae_{col[-1]}':[mean_absolute_error(df[col], np.array([data[f'mean_{col[-1]}'] for __ in range(df.shape[0])]))],  # mean absolute error\n",
    "                  f'rmse_{col[-1]}':[mean_squared_error(df[col], [data[f'mean_{col[-1]}'] for __ in range(df.shape[0])], squared=False)],  # variance# Root Mean Square Error\n",
    "                  f'mae_{col[-1]}':[mean_absolute_error(df[col], [data[f'mean_{col[-1]}'] for __ in range(df.shape[0])])],  # mean absolute error\n",
    "                  }) \n",
    "        for col in df.columns]\n",
    "    df_f = pd.DataFrame(data)\n",
    "    \n",
    "    return df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_to_dafaframe(path: Union[str, Path], df: pd.DataFrame) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    if not path.is_dir() or not path.exists():\n",
    "        return None\n",
    "    \n",
    "    for file_system_object in path.iterdir():\n",
    "        if file_system_object.is_dir():\n",
    "            df = get_data_to_dafaframe(file_system_object, df)\n",
    "            \n",
    "        elif file_system_object.suffix.lower() in ('.csv',):\n",
    "            df_add = read_from_csvfile(file_system_object)\n",
    "            df = pd.concat([df, get_statistical_features(file_system_object.stem.split('-')[0], df_add)], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prepared_data(df: pd.DataFrame, file_name: str='data1.bin') -> None:\n",
    "    with open(file_name, 'wb') as fh:\n",
    "        pickle.dump(df, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepared_data(file_name: str='data1.bin') -> pd.DataFrame:\n",
    "    with open(file_name, 'rb') as fh:\n",
    "        df = pickle.load(fh)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Path('data0.bin').is_file() and Path('data1.bin').is_file():\n",
    "    df = load_prepared_data()\n",
    "    classification_human_activity = load_prepared_data('data0.bin')\n",
    "\n",
    "else:\n",
    "    df = get_data_to_dafaframe('data', df)\n",
    "    save_prepared_data(df)\n",
    "    save_prepared_data(classification_human_activity, 'data0.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>max_X</th>\n",
       "      <th>min_X</th>\n",
       "      <th>mean_X</th>\n",
       "      <th>med_X</th>\n",
       "      <th>std_X</th>\n",
       "      <th>skew_X</th>\n",
       "      <th>kurt_X</th>\n",
       "      <th>var_X</th>\n",
       "      <th>idxmax_X</th>\n",
       "      <th>...</th>\n",
       "      <th>kurt_Z</th>\n",
       "      <th>var_Z</th>\n",
       "      <th>idxmax_Z</th>\n",
       "      <th>idxmin_Z</th>\n",
       "      <th>rmse_X</th>\n",
       "      <th>mae_X</th>\n",
       "      <th>rmse_Y</th>\n",
       "      <th>mae_Y</th>\n",
       "      <th>rmse_Z</th>\n",
       "      <th>mae_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>3</td>\n",
       "      <td>1.024718</td>\n",
       "      <td>-10.036493</td>\n",
       "      <td>-3.997519</td>\n",
       "      <td>-3.380613</td>\n",
       "      <td>3.011451</td>\n",
       "      <td>-0.338673</td>\n",
       "      <td>-0.557672</td>\n",
       "      <td>9.068838</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374707</td>\n",
       "      <td>6.062126</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>2.960835</td>\n",
       "      <td>2.408620</td>\n",
       "      <td>4.719099</td>\n",
       "      <td>3.860922</td>\n",
       "      <td>2.420755</td>\n",
       "      <td>1.881598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>3</td>\n",
       "      <td>8.398860</td>\n",
       "      <td>-6.224924</td>\n",
       "      <td>0.826638</td>\n",
       "      <td>1.244985</td>\n",
       "      <td>2.653484</td>\n",
       "      <td>-0.012359</td>\n",
       "      <td>2.275576</td>\n",
       "      <td>7.040978</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>9.031841</td>\n",
       "      <td>30.027026</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2.608884</td>\n",
       "      <td>1.942251</td>\n",
       "      <td>3.153400</td>\n",
       "      <td>2.494843</td>\n",
       "      <td>5.387590</td>\n",
       "      <td>3.226745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>3</td>\n",
       "      <td>12.196063</td>\n",
       "      <td>-6.354211</td>\n",
       "      <td>2.587334</td>\n",
       "      <td>2.506730</td>\n",
       "      <td>3.311198</td>\n",
       "      <td>-0.104480</td>\n",
       "      <td>3.238238</td>\n",
       "      <td>10.964034</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>4.507524</td>\n",
       "      <td>10.078007</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>3.255544</td>\n",
       "      <td>2.209689</td>\n",
       "      <td>5.150007</td>\n",
       "      <td>4.039338</td>\n",
       "      <td>3.121230</td>\n",
       "      <td>1.975557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>3</td>\n",
       "      <td>8.073248</td>\n",
       "      <td>-4.582502</td>\n",
       "      <td>2.830745</td>\n",
       "      <td>3.447650</td>\n",
       "      <td>3.302172</td>\n",
       "      <td>-0.492919</td>\n",
       "      <td>-0.453013</td>\n",
       "      <td>10.904337</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.758635</td>\n",
       "      <td>20.366468</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>3.246669</td>\n",
       "      <td>2.650009</td>\n",
       "      <td>4.630977</td>\n",
       "      <td>3.314692</td>\n",
       "      <td>4.437069</td>\n",
       "      <td>2.838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>3</td>\n",
       "      <td>9.035717</td>\n",
       "      <td>-6.904877</td>\n",
       "      <td>-0.025219</td>\n",
       "      <td>-0.399831</td>\n",
       "      <td>3.414785</td>\n",
       "      <td>0.284005</td>\n",
       "      <td>0.775833</td>\n",
       "      <td>11.660759</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.128289</td>\n",
       "      <td>19.916885</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.357390</td>\n",
       "      <td>2.592356</td>\n",
       "      <td>5.177956</td>\n",
       "      <td>3.986420</td>\n",
       "      <td>4.387823</td>\n",
       "      <td>2.956030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>3</td>\n",
       "      <td>8.398860</td>\n",
       "      <td>-6.224924</td>\n",
       "      <td>0.964544</td>\n",
       "      <td>1.376666</td>\n",
       "      <td>2.958615</td>\n",
       "      <td>-0.059084</td>\n",
       "      <td>0.721621</td>\n",
       "      <td>8.753403</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>4.863290</td>\n",
       "      <td>39.297190</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>2.908887</td>\n",
       "      <td>2.250614</td>\n",
       "      <td>4.252132</td>\n",
       "      <td>3.073357</td>\n",
       "      <td>6.163382</td>\n",
       "      <td>4.058800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity      max_X      min_X    mean_X     med_X     std_X    skew_X  \\\n",
       "6456         3   1.024718 -10.036493 -3.997519 -3.380613  3.011451 -0.338673   \n",
       "6457         3   8.398860  -6.224924  0.826638  1.244985  2.653484 -0.012359   \n",
       "6458         3  12.196063  -6.354211  2.587334  2.506730  3.311198 -0.104480   \n",
       "6459         3   8.073248  -4.582502  2.830745  3.447650  3.302172 -0.492919   \n",
       "6460         3   9.035717  -6.904877 -0.025219 -0.399831  3.414785  0.284005   \n",
       "6461         3   8.398860  -6.224924  0.964544  1.376666  2.958615 -0.059084   \n",
       "\n",
       "        kurt_X      var_X  idxmax_X  ...    kurt_Z      var_Z  idxmax_Z  \\\n",
       "6456 -0.557672   9.068838         5  ...  0.374707   6.062126        26   \n",
       "6457  2.275576   7.040978         8  ...  9.031841  30.027026         7   \n",
       "6458  3.238238  10.964034        16  ...  4.507524  10.078007        28   \n",
       "6459 -0.453013  10.904337        11  ...  3.758635  20.366468        27   \n",
       "6460  0.775833  11.660759         1  ...  2.128289  19.916885         1   \n",
       "6461  0.721621   8.753403        20  ...  4.863290  39.297190        19   \n",
       "\n",
       "      idxmin_Z    rmse_X     mae_X    rmse_Y     mae_Y    rmse_Z     mae_Z  \n",
       "6456        21  2.960835  2.408620  4.719099  3.860922  2.420755  1.881598  \n",
       "6457        11  2.608884  1.942251  3.153400  2.494843  5.387590  3.226745  \n",
       "6458        16  3.255544  2.209689  5.150007  4.039338  3.121230  1.975557  \n",
       "6459        29  3.246669  2.650009  4.630977  3.314692  4.437069  2.838800  \n",
       "6460        29  3.357390  2.592356  5.177956  3.986420  4.387823  2.956030  \n",
       "6461        23  2.908887  2.250614  4.252132  3.073357  6.163382  4.058800  \n",
       "\n",
       "[6 rows x 37 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walking': 0, 'running': 1, 'idle': 2, 'stairs': 3}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_human_activity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas-cYPLqW4U-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
