{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Yf4NBJUSNM"
      },
      "source": [
        "# Создание нейронной сети\n",
        "\n",
        "В этом задании мы создадим полносвязную нейронную сеть используя при этом низкоуровневые механизмы tensorflow.\n",
        "\n",
        "Архитектутра нейросети представлена на следующем рисунке. Как видите, в ней имеется один входной слой, два скрытых, а так же выходной слой. В качестве активационной функции в скрытых слоях будет использоваться сигмоида. На выходном слое мы используем softmax.\n",
        "\n",
        "Часть кода по созданию сети уже написана, от вас требуется заполнить пропуски в указанных местах."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "01rZWUu0USNQ"
      },
      "source": [
        "## Архитектура нейронной сети\n",
        "\n",
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LLvIZ705Qw_V"
      },
      "source": [
        "## О датасете MNIST\n",
        "\n",
        "Данную нейросеть мы будем обучать на датасете MNIST. Этот датасет представляет собой большое количество изображений рукописных цифр размером $28 \\times 28$ пикселей. Каждый пиксель принимает значение от 0 до 255.\n",
        "\n",
        "Как и раньше датасет будет разеделен на обучающую и тестовую выборки. При этом мы выполним нормализацию всех изображений, чтобы значения пикселей находились в промежутке от 0 до 1, разделив яркость каждого пикселя на 255.\n",
        "\n",
        "Кроме того, архитектура нейронной сети ожидает на вход вектор. В нашем же случае каждый объект выборки представляет собой матрицу. Что же делать? В этом задании мы \"растянем\" матрицу $28 \\times 28$, получив при этом вектор, состоящей из 784 элементов.\n",
        "\n",
        "![MNIST Dataset](https://www.researchgate.net/profile/Steven-Young-5/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png)\n",
        "\n",
        "Больше информации о датасете можно найти [здесь](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "il_0_5OyUSNR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-26 16:37:55.629282: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-07-26 16:37:55.631087: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-26 16:37:55.668589: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-07-26 16:37:55.669523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-26 16:37:56.385564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from typing import Optional, Union\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### O/S/E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cd-1_abTUSNS"
      },
      "outputs": [],
      "source": [
        "num_classes = 10  # общее количество классов, в нашем случае это цифры от 0 до 9\n",
        "num_features = 784  # количество атрибутов входного вектора 28 * 28 = 784\n",
        "\n",
        "learning_rate = 0.001  # скорость обучения нейронной сети\n",
        "training_steps = 3000  # максимальное число эпох\n",
        "batch_size = 256  # пересчитывать веса сети мы будем не на всей выборке, а на ее случайном подможестве из batch_size элементов\n",
        "display_step = 100  # каждые 100 итераций мы будем показывать текущее значение функции потерь и точности\n",
        "\n",
        "n_hidden_1 = 128  # количество нейронов 1-го слоя\n",
        "n_hidden_2 = 256  # количество нейронов 2-го слоя\n",
        "\n",
        "buffer_size = 5000  # This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data\n",
        "- https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat\n",
        "- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\n",
        "- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch\n",
        "- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pGTXiRyTUSNT"
      },
      "outputs": [],
      "source": [
        "# Загружаем датасет\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Преобразуем целочисленные пиксели к типу float32\n",
        "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
        "\n",
        "# Преобразуем матрицы размером 28x28 пикселей в вектор из 784 элементов\n",
        "x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])\n",
        "\n",
        "# Нормализуем значения пикселей\n",
        "x_train, x_test = x_train / 255., x_test / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Перемешаем тренировочные данные (split to batches & ...)\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(buffer_size).batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape, x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000,), (10000,))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### M"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid\n",
        "- https://www.tensorflow.org/api_docs/python/tf/random/normal\n",
        "- https://stackoverflow.com/questions/66968102/python-type-hint-can-tensorflow-data-type-be-used\n",
        "- https://www.tensorflow.org/api_docs/python/tf/nn/relu\n",
        "- https://www.tensorflow.org/api_docs/python/tf/nn/softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FkRmCQjnUSNV"
      },
      "outputs": [],
      "source": [
        "# Создадим нейронную сеть\n",
        "\n",
        "class DenseLayer(tf.Module):\n",
        "    def __init__(self, in_features: int, out_features: int, name: Optional[str]=None) -> None:\n",
        "        super().__init__(name=name)\n",
        "        self.w = tf.Variable(\n",
        "                             tf.random.normal([in_features, out_features]), \n",
        "                             name='w'\n",
        "                             )\n",
        "        # self.b = tf.Variable(tf.zeros([out_features]), name='b')  # b -> 0\n",
        "        self.b = tf.Variable(tf.random.normal([out_features]), name='b')\n",
        "\n",
        "    def __call__(self, x: tf.float32) -> tf.float32:\n",
        "        y = tf.matmul(x, self.w) + self.b\n",
        "        \n",
        "        return sigmoid(y) if self.name == 'sigmoid' else tf.nn.softmax(y) if self.name == 'softmax' else y\n",
        "\n",
        "\n",
        "class NN(tf.Module):\n",
        "  def __init__(self, name: Optional[str]=None) -> None:\n",
        "    super().__init__(name=name)\n",
        "    # Первый слой, состоящий из 128 нейронов\n",
        "    self.layer_1 = DenseLayer(in_features=num_features, out_features=n_hidden_1, name='sigmoid')\n",
        "\n",
        "    # Второй слой, состоящий из 256 нейронов\n",
        "    self.layer_2 = DenseLayer(in_features=n_hidden_1, out_features=n_hidden_2, name='sigmoid')\n",
        "\n",
        "    # Выходной слой\n",
        "    self.layer_out = DenseLayer(in_features=n_hidden_2, out_features=num_classes, name='softmax')\n",
        "\n",
        "  def __call__(self, x: tf.float32) -> tf.float32:\n",
        "    x = self.layer_1(x)\n",
        "    x = self.layer_2(x)\n",
        "\n",
        "    # Помните что для выхода нейронной сети мы применяем к выходу функцию softmax. \n",
        "    # Делаем мы это для того, чтобы\n",
        "    # выход нейронной сети принимал значения от 0 до 1 в соответствии с вероятностью \n",
        "    # принадлежности входного объекта к одному из 10 классов\n",
        "\n",
        "    x = self.layer_out(x)\n",
        "    \n",
        "    return x  # tf.nn.softmax(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- https://www.tensorflow.org/api_docs/python/tf/one_hot\n",
        "- https://www.tensorflow.org/api_docs/python/tf/clip_by_value\n",
        "- https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean\n",
        "- https://uk.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%B5%D1%85%D1%80%D0%B5%D1%81%D0%BD%D0%B0_%D0%B5%D0%BD%D1%82%D1%80%D0%BE%D0%BF%D1%96%D1%8F\n",
        "- https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/accuracy\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/metrics/categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = tf.one_hot(y_train, depth=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LIf3o7VAUSNV"
      },
      "outputs": [],
      "source": [
        "# В качестве функции ошибки в данном случае удобно взять кросс-энтропию (num_classes > 2)\n",
        "def cross_entropy(y_pred: tf.float32, y_true: np.array) -> tf.float32:\n",
        "    # Encode label to a one hot vector.\n",
        "    # y_true = to_categorical(y_true, num_classes=num_classes)\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "    \n",
        "    # Clip prediction values to avoid log(0) error. (acording to min and max value)\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "\n",
        "    # Вычисление кросс-энтропии (reduce_mean - Computes the mean of elements across dimensions of a tensor.)\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
        "\n",
        "\n",
        "# В качестве метрики качества используем точность\n",
        "def accuracy(y_pred: tf.float32, y_true: np.array) -> float:\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "    m = Accuracy()\n",
        "    m.update_state(y_true, y_pred)\n",
        "\n",
        "    return m.result().numpy()\n",
        "    # return accuracy_score(y_true, y_pred)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD\n",
        "- https://www.tensorflow.org/api_docs/python/tf/GradientTape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# num_classes = 10 # общее количество классов, в нашем случае это цифры от 0 до 9\n",
        "# num_features = 784 # количество атрибутов входного вектора 28 * 28 = 784\n",
        "\n",
        "# learning_rate = 0.001 # скорость обучения нейронной сети\n",
        "# training_steps = 3000 # максимальное число эпох\n",
        "# batch_size = 256 # пересчитывать веса сети мы будем не на всей выборке, а на ее случайном подможестве из batch_size элементов\n",
        "# display_step = 100 # каждые 100 итераций мы будем показывать текущее значение функции потерь и точности\n",
        "\n",
        "# n_hidden_1 = 128 # количество нейронов 1-го слоя\n",
        "# n_hidden_2 = 256 # количество нейронов 2-го слоя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MQeT1yatUSNW"
      },
      "outputs": [],
      "source": [
        "# Создадим экзампляр нейронной сети\n",
        "neural_net = NN(name=\"mnist\")  # alter model predict function\n",
        "\n",
        "# Функция обучения нейросети\n",
        "def train(nn, input_x, output_y, learning_rate):\n",
        "    # Для подгонки весов сети будем использовать стохастический градиентный спуск:\n",
        "    optimizer = tf.optimizers.legacy.SGD(learning_rate)  # .Adam\n",
        "\n",
        "    # Активация автоматического дифференцирования\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = nn(input_x)  # ? nn(input_x)  neural_net(input_x)\n",
        "        loss = cross_entropy(pred, output_y)\n",
        "\n",
        "        # Создадим оптимизируемых список параметров\n",
        "        # Место для вашего кода\n",
        "        # params = [nn.layer_out.w, nn.layer_out.b]\n",
        "        params = [nn.layer_1.trainable_variables, nn.layer_2.trainable_variables, nn.layer_out.trainable_variables]\n",
        "\n",
        "        # Вычислим по ним значение градиента\n",
        "        # Место для вашего кода\n",
        "        # dw, db = g.gradient(loss, params)\n",
        "        grads = g.gradient(loss, params)\n",
        "\n",
        "        # Модифицируем параметры\n",
        "        # Место для вашего кода\n",
        "        optimizer.apply_gradients(zip(grads[0], nn.layer_1.trainable_variables))\n",
        "        optimizer.apply_gradients(zip(grads[1], nn.layer_2.trainable_variables))\n",
        "        optimizer.apply_gradients(zip(grads[2], nn.layer_out.trainable_variables))\n",
        "        # nn.layer_out.w.assign_sub(learning_rate * grads[0])\n",
        "        # nn.layer_out.b.assign_sub(learning_rate * grads[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads[\u001b[39m0\u001b[39m], neural_net\u001b[39m.\u001b[39mlayer_1\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads[\u001b[39m1\u001b[39m], neural_net\u001b[39m.\u001b[39mlayer_2\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[0;32m---> 15\u001b[0m     optimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(grads[\u001b[39m2\u001b[39;49m], neural_net\u001b[39m.\u001b[39;49mlayer_out\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m     17\u001b[0m loss_history\u001b[39m.\u001b[39mappend(loss)\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/datas-cYPLqW4U-py3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:757\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m    754\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_unaggregated_gradients(\n\u001b[1;32m    755\u001b[0m         grads_and_vars\n\u001b[1;32m    756\u001b[0m     )\n\u001b[0;32m--> 757\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_gradients(grads_and_vars)\n\u001b[1;32m    758\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[1;32m    760\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39minterim\u001b[39m.\u001b[39mmaybe_merge_call(\n\u001b[1;32m    761\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    762\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distributed_apply, apply_state\u001b[39m=\u001b[39mapply_state\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    766\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m    767\u001b[0m )\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/datas-cYPLqW4U-py3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:552\u001b[0m, in \u001b[0;36mOptimizerV2._aggregate_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_aggregate_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    540\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called in `apply_gradients` to aggregate gradients across devices.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[39m    Note that user subclasses may override this, so the interface should not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39m      calls `self.gradient_aggregator`.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_aggregator(grads_and_vars)\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/datas-cYPLqW4U-py3.10/lib/python3.10/site-packages/keras/src/optimizers/utils.py:37\u001b[0m, in \u001b[0;36mall_reduce_sum_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mstrategy_supports_no_merge_call():\n\u001b[1;32m     36\u001b[0m     grads \u001b[39m=\u001b[39m [pair[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m filtered_grads_and_vars]\n\u001b[0;32m---> 37\u001b[0m     reduced \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_replica_context()\u001b[39m.\u001b[39;49mall_reduce(\n\u001b[1;32m     38\u001b[0m         tf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mReduceOp\u001b[39m.\u001b[39;49mSUM, grads\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# TODO(b/183257003): Remove this branch\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     reduced \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     43\u001b[0m         _all_reduce_sum_fn, args\u001b[39m=\u001b[39m(filtered_grads_and_vars,)\n\u001b[1;32m     44\u001b[0m     )\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/datas-cYPLqW4U-py3.10/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3624\u001b[0m, in \u001b[0;36mReplicaContextBase.all_reduce\u001b[0;34m(self, reduce_op, value, options)\u001b[0m\n\u001b[1;32m   3618\u001b[0m \u001b[39mif\u001b[39;00m has_indexed_slices:\n\u001b[1;32m   3619\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   3620\u001b[0m       value,\n\u001b[1;32m   3621\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_call(batch_all_reduce, args\u001b[39m=\u001b[39mflattened_value))\n\u001b[1;32m   3623\u001b[0m \u001b[39m@custom_gradient\u001b[39;49m\u001b[39m.\u001b[39;49mcustom_gradient\n\u001b[0;32m-> 3624\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mgrad_wrapper\u001b[39;49m(\u001b[39m*\u001b[39;49mxs):\n\u001b[1;32m   3625\u001b[0m   ys \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmerge_call(batch_all_reduce, args\u001b[39m=\u001b[39;49mxs)\n\u001b[1;32m   3626\u001b[0m   \u001b[39m# The gradient of an all-sum is itself an all-sum (all-mean, likewise).\u001b[39;49;00m\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/datas-cYPLqW4U-py3.10/lib/python3.10/site-packages/tensorflow/python/ops/custom_gradient.py:301\u001b[0m, in \u001b[0;36mcustom_gradient\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m _graph_mode_decorator(wrapped, args, kwargs)\n\u001b[0;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m tf_decorator\u001b[39m.\u001b[39;49mmake_decorator(f, decorated(f))\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/datas-cYPLqW4U-py3.10/lib/python3.10/site-packages/tensorflow/python/util/tf_decorator.py:163\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mcallable\u001b[39m(target):\n\u001b[1;32m    162\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     signature \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49msignature(target)\n\u001b[1;32m    164\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    165\u001b[0m     \u001b[39m# Certain callables such as builtins can not be inspected for signature.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:3254\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msignature\u001b[39m(obj, \u001b[39m*\u001b[39m, follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_str\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   3253\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3254\u001b[0m     \u001b[39mreturn\u001b[39;00m Signature\u001b[39m.\u001b[39;49mfrom_callable(obj, follow_wrapped\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[1;32m   3255\u001b[0m                                    \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:3002\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   2999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_callable\u001b[39m(\u001b[39mcls\u001b[39m, obj, \u001b[39m*\u001b[39m,\n\u001b[1;32m   3000\u001b[0m                   follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_str\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   3001\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3002\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m,\n\u001b[1;32m   3003\u001b[0m                                     follow_wrapper_chains\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[1;32m   3004\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:2463\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2458\u001b[0m             \u001b[39mreturn\u001b[39;00m sig\u001b[39m.\u001b[39mreplace(parameters\u001b[39m=\u001b[39mnew_params)\n\u001b[1;32m   2460\u001b[0m \u001b[39mif\u001b[39;00m isfunction(obj) \u001b[39mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2461\u001b[0m     \u001b[39m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m     \u001b[39m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2463\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[1;32m   2464\u001b[0m                                     skip_bound_arg\u001b[39m=\u001b[39;49mskip_bound_arg,\n\u001b[1;32m   2465\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n\u001b[1;32m   2467\u001b[0m \u001b[39mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2468\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2469\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39mskip_bound_arg)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:2370\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2365\u001b[0m     parameters\u001b[39m.\u001b[39mappend(Parameter(name, annotation\u001b[39m=\u001b[39mannotation,\n\u001b[1;32m   2366\u001b[0m                                 kind\u001b[39m=\u001b[39m_VAR_KEYWORD))\n\u001b[1;32m   2368\u001b[0m \u001b[39m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[1;32m   2369\u001b[0m \u001b[39m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[0;32m-> 2370\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(parameters,\n\u001b[1;32m   2371\u001b[0m            return_annotation\u001b[39m=\u001b[39;49mannotations\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mreturn\u001b[39;49m\u001b[39m'\u001b[39;49m, _empty),\n\u001b[1;32m   2372\u001b[0m            __validate_parameters__\u001b[39m=\u001b[39;49mis_duck_function)\n",
            "File \u001b[0;32m/usr/local/lib/python3.10/inspect.py:2971\u001b[0m, in \u001b[0;36mSignature.__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2969\u001b[0m         params \u001b[39m=\u001b[39m OrderedDict((param\u001b[39m.\u001b[39mname, param) \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m parameters)\n\u001b[0;32m-> 2971\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters \u001b[39m=\u001b[39m types\u001b[39m.\u001b[39;49mMappingProxyType(params)\n\u001b[1;32m   2972\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_annotation \u001b[39m=\u001b[39m return_annotation\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Alt\n",
        "params = [neural_net.layer_1.trainable_variables, neural_net.layer_2.trainable_variables, neural_net.layer_out.trainable_variables]\n",
        "loss_history = []\n",
        "optimizer = tf.optimizers.legacy.Adam(learning_rate)\n",
        "for n in range(10):\n",
        "    loss = 0\n",
        "    for batch_x, batch_y in train_data:\n",
        "        with tf.GradientTape() as g:\n",
        "            f_loss = cross_entropy(neural_net(batch_x), batch_y)\n",
        "\n",
        "        loss += f_loss\n",
        "        grads = g.gradient(f_loss, params)  # dw, db\n",
        "        optimizer.apply_gradients(zip(grads[0], neural_net.layer_1.trainable_variables))\n",
        "        optimizer.apply_gradients(zip(grads[1], neural_net.layer_2.trainable_variables))\n",
        "        optimizer.apply_gradients(zip(grads[2], neural_net.layer_out.trainable_variables))\n",
        "\n",
        "    loss_history.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fnyns9lBfpQZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 0\n",
            "loss: 2488.934814453125\n",
            "step: 1\n",
            "loss: 2302.883056640625\n",
            "step: 2\n",
            "loss: 2122.08349609375\n",
            "step: 3\n",
            "loss: 1862.6566162109375\n",
            "step: 4\n",
            "loss: 1679.664306640625\n",
            "step: 5\n",
            "loss: 1620.22705078125\n",
            "step: 6\n",
            "loss: 1608.3663330078125\n",
            "step: 7\n",
            "loss: 1716.679443359375\n",
            "step: 8\n",
            "loss: 1635.3486328125\n",
            "step: 9\n",
            "loss: 1387.468017578125\n",
            "step: 10\n",
            "loss: 1409.796875\n",
            "step: 11\n",
            "loss: 1379.225830078125\n",
            "step: 12\n",
            "loss: 1290.72705078125\n",
            "step: 13\n",
            "loss: 1083.7470703125\n",
            "step: 14\n",
            "loss: 888.9393920898438\n",
            "step: 15\n",
            "loss: 948.9260864257812\n",
            "step: 16\n",
            "loss: 824.69921875\n",
            "step: 17\n",
            "loss: 897.5557861328125\n",
            "step: 18\n",
            "loss: 906.81005859375\n",
            "step: 19\n",
            "loss: 880.0558471679688\n",
            "step: 20\n",
            "loss: 718.7722778320312\n",
            "step: 21\n",
            "loss: 671.27392578125\n",
            "step: 22\n",
            "loss: 675.6206665039062\n",
            "step: 23\n",
            "loss: 693.9805908203125\n",
            "step: 24\n",
            "loss: 757.77783203125\n",
            "step: 25\n",
            "loss: 551.8885498046875\n",
            "step: 26\n",
            "loss: 551.0462646484375\n",
            "step: 27\n",
            "loss: 537.4156494140625\n",
            "step: 28\n",
            "loss: 670.36376953125\n",
            "step: 29\n",
            "loss: 715.4151611328125\n",
            "step: 30\n",
            "loss: 480.6238098144531\n",
            "step: 31\n",
            "loss: 465.2616882324219\n",
            "step: 32\n",
            "loss: 603.24853515625\n",
            "step: 33\n",
            "loss: 581.5665283203125\n",
            "step: 34\n",
            "loss: 565.9131469726562\n",
            "step: 35\n",
            "loss: 574.3641967773438\n",
            "step: 36\n",
            "loss: 593.4094848632812\n",
            "step: 37\n",
            "loss: 614.8814086914062\n",
            "step: 38\n",
            "loss: 526.756591796875\n",
            "step: 39\n",
            "loss: 517.047607421875\n",
            "step: 40\n",
            "loss: 563.8985595703125\n",
            "step: 41\n",
            "loss: 529.5298461914062\n",
            "step: 42\n",
            "loss: 595.5592041015625\n",
            "step: 43\n",
            "loss: 443.03155517578125\n",
            "step: 44\n",
            "loss: 561.829345703125\n",
            "step: 45\n",
            "loss: 541.7283935546875\n",
            "step: 46\n",
            "loss: 432.982421875\n",
            "step: 47\n",
            "loss: 585.6328125\n",
            "step: 48\n",
            "loss: 547.7314453125\n",
            "step: 49\n",
            "loss: 508.9456481933594\n",
            "step: 50\n",
            "loss: 528.8514404296875\n",
            "step: 51\n",
            "loss: 419.4414367675781\n",
            "step: 52\n",
            "loss: 419.3265380859375\n",
            "step: 53\n",
            "loss: 516.234130859375\n",
            "step: 54\n",
            "loss: 405.5960388183594\n",
            "step: 55\n",
            "loss: 412.35980224609375\n",
            "step: 56\n",
            "loss: 467.39752197265625\n",
            "step: 57\n",
            "loss: 457.37921142578125\n",
            "step: 58\n",
            "loss: 407.89678955078125\n",
            "step: 59\n",
            "loss: 343.3009033203125\n",
            "step: 60\n",
            "loss: 407.771484375\n",
            "step: 61\n",
            "loss: 421.39898681640625\n",
            "step: 62\n",
            "loss: 391.227294921875\n",
            "step: 63\n",
            "loss: 428.3188171386719\n",
            "step: 64\n",
            "loss: 376.7223815917969\n",
            "step: 65\n",
            "loss: 406.1213073730469\n",
            "step: 66\n",
            "loss: 374.40087890625\n",
            "step: 67\n",
            "loss: 399.3097229003906\n",
            "step: 68\n",
            "loss: 286.7982482910156\n",
            "step: 69\n",
            "loss: 400.41558837890625\n",
            "step: 70\n",
            "loss: 388.29168701171875\n",
            "step: 71\n",
            "loss: 432.09490966796875\n",
            "step: 72\n",
            "loss: 369.115478515625\n",
            "step: 73\n",
            "loss: 360.70220947265625\n",
            "step: 74\n",
            "loss: 314.03369140625\n",
            "step: 75\n",
            "loss: 266.63531494140625\n",
            "step: 76\n",
            "loss: 350.26123046875\n",
            "step: 77\n",
            "loss: 375.4212951660156\n",
            "step: 78\n",
            "loss: 393.2127685546875\n",
            "step: 79\n",
            "loss: 346.3856201171875\n",
            "step: 80\n",
            "loss: 291.35888671875\n",
            "step: 81\n",
            "loss: 359.4344177246094\n",
            "step: 82\n",
            "loss: 380.30078125\n",
            "step: 83\n",
            "loss: 308.0711669921875\n",
            "step: 84\n",
            "loss: 319.78167724609375\n",
            "step: 85\n",
            "loss: 298.2735595703125\n",
            "step: 86\n",
            "loss: 363.44110107421875\n",
            "step: 87\n",
            "loss: 359.626953125\n",
            "step: 88\n",
            "loss: 345.17864990234375\n",
            "step: 89\n",
            "loss: 338.4970703125\n",
            "step: 90\n",
            "loss: 368.37896728515625\n",
            "step: 91\n",
            "loss: 366.5311584472656\n",
            "step: 92\n",
            "loss: 294.1820983886719\n",
            "step: 93\n",
            "loss: 320.5027770996094\n",
            "step: 94\n",
            "loss: 230.30532836914062\n",
            "step: 95\n",
            "loss: 303.5941162109375\n",
            "step: 96\n",
            "loss: 393.169189453125\n",
            "step: 97\n",
            "loss: 309.2042236328125\n",
            "step: 98\n",
            "loss: 278.20782470703125\n",
            "step: 99\n",
            "loss: 347.66815185546875\n",
            "step: 100\n",
            "loss: 348.767822265625\n",
            "step: 101\n",
            "loss: 291.755859375\n",
            "step: 102\n",
            "loss: 295.44061279296875\n",
            "step: 103\n",
            "loss: 369.1322937011719\n",
            "step: 104\n",
            "loss: 336.7318115234375\n",
            "step: 105\n",
            "loss: 285.9017639160156\n",
            "step: 106\n",
            "loss: 302.7205810546875\n",
            "step: 107\n",
            "loss: 356.9928283691406\n",
            "step: 108\n",
            "loss: 292.3644714355469\n",
            "step: 109\n",
            "loss: 283.3406677246094\n",
            "step: 110\n",
            "loss: 323.5819396972656\n",
            "step: 111\n",
            "loss: 319.61822509765625\n",
            "step: 112\n",
            "loss: 273.87481689453125\n",
            "step: 113\n",
            "loss: 288.5867919921875\n",
            "step: 114\n",
            "loss: 321.4532470703125\n",
            "step: 115\n",
            "loss: 350.1286315917969\n",
            "step: 116\n",
            "loss: 294.1617431640625\n",
            "step: 117\n",
            "loss: 272.8189697265625\n",
            "step: 118\n",
            "loss: 312.796630859375\n",
            "step: 119\n",
            "loss: 257.2978210449219\n",
            "step: 120\n",
            "loss: 291.42138671875\n",
            "step: 121\n",
            "loss: 387.4249267578125\n",
            "step: 122\n",
            "loss: 291.9288024902344\n",
            "step: 123\n",
            "loss: 246.05465698242188\n",
            "step: 124\n",
            "loss: 255.43356323242188\n",
            "step: 125\n",
            "loss: 304.3106689453125\n",
            "step: 126\n",
            "loss: 260.6715087890625\n",
            "step: 127\n",
            "loss: 259.29345703125\n",
            "step: 128\n",
            "loss: 267.7022705078125\n",
            "step: 129\n",
            "loss: 287.0174560546875\n",
            "step: 130\n",
            "loss: 248.34432983398438\n",
            "step: 131\n",
            "loss: 303.6338806152344\n",
            "step: 132\n",
            "loss: 230.5170135498047\n",
            "step: 133\n",
            "loss: 160.87924194335938\n",
            "step: 134\n",
            "loss: 221.87020874023438\n",
            "step: 135\n",
            "loss: 319.4735107421875\n",
            "step: 136\n",
            "loss: 223.88250732421875\n",
            "step: 137\n",
            "loss: 270.39093017578125\n",
            "step: 138\n",
            "loss: 229.42315673828125\n",
            "step: 139\n",
            "loss: 326.66265869140625\n",
            "step: 140\n",
            "loss: 257.9359130859375\n",
            "step: 141\n",
            "loss: 295.3959655761719\n",
            "step: 142\n",
            "loss: 254.87782287597656\n",
            "step: 143\n",
            "loss: 251.90907287597656\n",
            "step: 144\n",
            "loss: 279.97796630859375\n",
            "step: 145\n",
            "loss: 212.53746032714844\n",
            "step: 146\n",
            "loss: 330.8172912597656\n",
            "step: 147\n",
            "loss: 318.434814453125\n",
            "step: 148\n",
            "loss: 231.41751098632812\n",
            "step: 149\n",
            "loss: 280.2487487792969\n",
            "step: 150\n",
            "loss: 236.0758056640625\n",
            "step: 151\n",
            "loss: 250.6388397216797\n",
            "step: 152\n",
            "loss: 272.3663635253906\n",
            "step: 153\n",
            "loss: 215.94992065429688\n",
            "step: 154\n",
            "loss: 261.77215576171875\n",
            "step: 155\n",
            "loss: 277.3543701171875\n",
            "step: 156\n",
            "loss: 231.04644775390625\n",
            "step: 157\n",
            "loss: 228.33226013183594\n",
            "step: 158\n",
            "loss: 273.8575439453125\n",
            "step: 159\n",
            "loss: 233.5572509765625\n",
            "step: 160\n",
            "loss: 305.85516357421875\n",
            "step: 161\n",
            "loss: 232.00082397460938\n",
            "step: 162\n",
            "loss: 224.24237060546875\n",
            "step: 163\n",
            "loss: 237.6070556640625\n",
            "step: 164\n",
            "loss: 215.70758056640625\n",
            "step: 165\n",
            "loss: 306.08343505859375\n",
            "step: 166\n",
            "loss: 220.86373901367188\n",
            "step: 167\n",
            "loss: 274.39349365234375\n",
            "step: 168\n",
            "loss: 333.445068359375\n",
            "step: 169\n",
            "loss: 262.90069580078125\n",
            "step: 170\n",
            "loss: 238.80564880371094\n",
            "step: 171\n",
            "loss: 249.47178649902344\n",
            "step: 172\n",
            "loss: 278.49200439453125\n",
            "step: 173\n",
            "loss: 212.75640869140625\n",
            "step: 174\n",
            "loss: 278.59716796875\n",
            "step: 175\n",
            "loss: 228.21539306640625\n",
            "step: 176\n",
            "loss: 315.58465576171875\n",
            "step: 177\n",
            "loss: 226.40847778320312\n",
            "step: 178\n",
            "loss: 279.48187255859375\n",
            "step: 179\n",
            "loss: 216.77850341796875\n",
            "step: 180\n",
            "loss: 216.35696411132812\n",
            "step: 181\n",
            "loss: 209.0726318359375\n",
            "step: 182\n",
            "loss: 152.9547119140625\n",
            "step: 183\n",
            "loss: 184.1951141357422\n",
            "step: 184\n",
            "loss: 253.47357177734375\n",
            "step: 185\n",
            "loss: 253.8233642578125\n",
            "step: 186\n",
            "loss: 244.18511962890625\n",
            "step: 187\n",
            "loss: 232.82699584960938\n",
            "step: 188\n",
            "loss: 216.12979125976562\n",
            "step: 189\n",
            "loss: 229.93943786621094\n",
            "step: 190\n",
            "loss: 224.1251678466797\n",
            "step: 191\n",
            "loss: 192.48892211914062\n",
            "step: 192\n",
            "loss: 259.4329833984375\n",
            "step: 193\n",
            "loss: 210.05133056640625\n",
            "step: 194\n",
            "loss: 275.639892578125\n",
            "step: 195\n",
            "loss: 205.9034423828125\n",
            "step: 196\n",
            "loss: 227.75949096679688\n",
            "step: 197\n",
            "loss: 284.9488220214844\n",
            "step: 198\n",
            "loss: 238.17977905273438\n",
            "step: 199\n",
            "loss: 232.57765197753906\n",
            "step: 200\n",
            "loss: 195.81468200683594\n",
            "step: 201\n",
            "loss: 159.32968139648438\n",
            "step: 202\n",
            "loss: 183.06631469726562\n",
            "step: 203\n",
            "loss: 210.00494384765625\n",
            "step: 204\n",
            "loss: 157.23800659179688\n",
            "step: 205\n",
            "loss: 215.74917602539062\n",
            "step: 206\n",
            "loss: 219.20448303222656\n",
            "step: 207\n",
            "loss: 179.29908752441406\n",
            "step: 208\n",
            "loss: 231.43954467773438\n",
            "step: 209\n",
            "loss: 194.1143035888672\n",
            "step: 210\n",
            "loss: 194.29547119140625\n",
            "step: 211\n",
            "loss: 218.45974731445312\n",
            "step: 212\n",
            "loss: 159.7840118408203\n",
            "step: 213\n",
            "loss: 160.4981689453125\n",
            "step: 214\n",
            "loss: 173.3970947265625\n",
            "step: 215\n",
            "loss: 187.45697021484375\n",
            "step: 216\n",
            "loss: 221.53236389160156\n",
            "step: 217\n",
            "loss: 152.55117797851562\n",
            "step: 218\n",
            "loss: 174.80953979492188\n",
            "step: 219\n",
            "loss: 212.85360717773438\n",
            "step: 220\n",
            "loss: 195.2649688720703\n",
            "step: 221\n",
            "loss: 234.7111053466797\n",
            "step: 222\n",
            "loss: 186.41213989257812\n",
            "step: 223\n",
            "loss: 168.953857421875\n",
            "step: 224\n",
            "loss: 160.99200439453125\n",
            "step: 225\n",
            "loss: 136.13385009765625\n",
            "step: 226\n",
            "loss: 174.54010009765625\n",
            "step: 227\n",
            "loss: 196.2586669921875\n",
            "step: 228\n",
            "loss: 174.01116943359375\n",
            "step: 229\n",
            "loss: 174.02584838867188\n",
            "step: 230\n",
            "loss: 228.0555419921875\n",
            "step: 231\n",
            "loss: 186.48646545410156\n",
            "step: 232\n",
            "loss: 219.93692016601562\n",
            "step: 233\n",
            "loss: 170.98837280273438\n",
            "step: 234\n",
            "loss: 177.43392944335938\n",
            "step: 235\n",
            "loss: 186.65216064453125\n",
            "step: 236\n",
            "loss: 138.397216796875\n",
            "step: 237\n",
            "loss: 170.96218872070312\n",
            "step: 238\n",
            "loss: 146.28048706054688\n",
            "step: 239\n",
            "loss: 177.0877685546875\n",
            "step: 240\n",
            "loss: 132.70108032226562\n",
            "step: 241\n",
            "loss: 181.18603515625\n",
            "step: 242\n",
            "loss: 216.07127380371094\n",
            "step: 243\n",
            "loss: 185.09823608398438\n",
            "step: 244\n",
            "loss: 155.11192321777344\n",
            "step: 245\n",
            "loss: 143.78636169433594\n",
            "step: 246\n",
            "loss: 180.603759765625\n",
            "step: 247\n",
            "loss: 224.37094116210938\n",
            "step: 248\n",
            "loss: 167.37588500976562\n",
            "step: 249\n",
            "loss: 165.62277221679688\n",
            "step: 250\n",
            "loss: 180.74380493164062\n",
            "step: 251\n",
            "loss: 160.90504455566406\n",
            "step: 252\n",
            "loss: 184.81236267089844\n",
            "step: 253\n",
            "loss: 168.27847290039062\n",
            "step: 254\n",
            "loss: 171.22430419921875\n",
            "step: 255\n",
            "loss: 196.888916015625\n",
            "step: 256\n",
            "loss: 155.26422119140625\n",
            "step: 257\n",
            "loss: 195.52268981933594\n",
            "step: 258\n",
            "loss: 157.2857208251953\n",
            "step: 259\n",
            "loss: 170.47666931152344\n",
            "step: 260\n",
            "loss: 135.9733428955078\n",
            "step: 261\n",
            "loss: 211.2291259765625\n",
            "step: 262\n",
            "loss: 169.66192626953125\n",
            "step: 263\n",
            "loss: 163.86557006835938\n",
            "step: 264\n",
            "loss: 176.69552612304688\n",
            "step: 265\n",
            "loss: 149.93777465820312\n",
            "step: 266\n",
            "loss: 200.92572021484375\n",
            "step: 267\n",
            "loss: 205.54139709472656\n",
            "step: 268\n",
            "loss: 223.3770751953125\n",
            "step: 269\n",
            "loss: 167.92803955078125\n",
            "step: 270\n",
            "loss: 220.2368927001953\n",
            "step: 271\n",
            "loss: 172.74118041992188\n",
            "step: 272\n",
            "loss: 176.2745361328125\n",
            "step: 273\n",
            "loss: 185.53256225585938\n",
            "step: 274\n",
            "loss: 220.04168701171875\n",
            "step: 275\n",
            "loss: 198.49082946777344\n",
            "step: 276\n",
            "loss: 154.60049438476562\n",
            "step: 277\n",
            "loss: 252.65115356445312\n",
            "step: 278\n",
            "loss: 193.84837341308594\n",
            "step: 279\n",
            "loss: 187.54307556152344\n",
            "step: 280\n",
            "loss: 169.83419799804688\n",
            "step: 281\n",
            "loss: 234.44692993164062\n",
            "step: 282\n",
            "loss: 211.102294921875\n",
            "step: 283\n",
            "loss: 170.3433837890625\n",
            "step: 284\n",
            "loss: 153.0728759765625\n",
            "step: 285\n",
            "loss: 139.27792358398438\n",
            "step: 286\n",
            "loss: 181.98617553710938\n",
            "step: 287\n",
            "loss: 153.70034790039062\n",
            "step: 288\n",
            "loss: 228.53652954101562\n",
            "step: 289\n",
            "loss: 231.26220703125\n",
            "step: 290\n",
            "loss: 200.97076416015625\n",
            "step: 291\n",
            "loss: 158.54112243652344\n",
            "step: 292\n",
            "loss: 147.05142211914062\n",
            "step: 293\n",
            "loss: 170.7613983154297\n",
            "step: 294\n",
            "loss: 205.3126983642578\n",
            "step: 295\n",
            "loss: 194.4990234375\n",
            "step: 296\n",
            "loss: 186.2609405517578\n",
            "step: 297\n",
            "loss: 184.53875732421875\n",
            "step: 298\n",
            "loss: 156.87986755371094\n",
            "step: 299\n",
            "loss: 159.6297607421875\n",
            "step: 300\n",
            "loss: 190.89187622070312\n",
            "step: 301\n",
            "loss: 151.942626953125\n",
            "step: 302\n",
            "loss: 180.03790283203125\n",
            "step: 303\n",
            "loss: 176.90643310546875\n",
            "step: 304\n",
            "loss: 160.71456909179688\n",
            "step: 305\n",
            "loss: 148.293701171875\n",
            "step: 306\n",
            "loss: 202.04208374023438\n",
            "step: 307\n",
            "loss: 152.00192260742188\n",
            "step: 308\n",
            "loss: 144.42599487304688\n",
            "step: 309\n",
            "loss: 187.66297912597656\n",
            "step: 310\n",
            "loss: 155.02035522460938\n",
            "step: 311\n",
            "loss: 188.77008056640625\n",
            "step: 312\n",
            "loss: 170.68798828125\n",
            "step: 313\n",
            "loss: 172.95477294921875\n",
            "step: 314\n",
            "loss: 136.3109130859375\n",
            "step: 315\n",
            "loss: 215.67242431640625\n",
            "step: 316\n",
            "loss: 129.88714599609375\n",
            "step: 317\n",
            "loss: 153.38536071777344\n",
            "step: 318\n",
            "loss: 147.24842834472656\n",
            "step: 319\n",
            "loss: 177.86328125\n",
            "step: 320\n",
            "loss: 181.49591064453125\n",
            "step: 321\n",
            "loss: 96.13316345214844\n",
            "step: 322\n",
            "loss: 148.0412139892578\n",
            "step: 323\n",
            "loss: 184.51895141601562\n",
            "step: 324\n",
            "loss: 166.57846069335938\n",
            "step: 325\n",
            "loss: 177.12811279296875\n",
            "step: 326\n",
            "loss: 184.19223022460938\n",
            "step: 327\n",
            "loss: 148.32550048828125\n",
            "step: 328\n",
            "loss: 211.869140625\n",
            "step: 329\n",
            "loss: 196.5140380859375\n",
            "step: 330\n",
            "loss: 153.8512725830078\n",
            "step: 331\n",
            "loss: 159.19436645507812\n",
            "step: 332\n",
            "loss: 225.48886108398438\n",
            "step: 333\n",
            "loss: 144.2669677734375\n",
            "step: 334\n",
            "loss: 152.83485412597656\n",
            "step: 335\n",
            "loss: 161.83554077148438\n",
            "step: 336\n",
            "loss: 170.54022216796875\n",
            "step: 337\n",
            "loss: 171.97142028808594\n",
            "step: 338\n",
            "loss: 184.6401824951172\n",
            "step: 339\n",
            "loss: 240.04061889648438\n",
            "step: 340\n",
            "loss: 213.442138671875\n",
            "step: 341\n",
            "loss: 194.56011962890625\n",
            "step: 342\n",
            "loss: 172.8457489013672\n",
            "step: 343\n",
            "loss: 235.65866088867188\n",
            "step: 344\n",
            "loss: 189.27145385742188\n",
            "step: 345\n",
            "loss: 176.26223754882812\n",
            "step: 346\n",
            "loss: 147.47509765625\n",
            "step: 347\n",
            "loss: 152.57424926757812\n",
            "step: 348\n",
            "loss: 172.9822998046875\n",
            "step: 349\n",
            "loss: 127.23163604736328\n",
            "step: 350\n",
            "loss: 205.58187866210938\n",
            "step: 351\n",
            "loss: 148.62213134765625\n",
            "step: 352\n",
            "loss: 143.6206817626953\n",
            "step: 353\n",
            "loss: 172.2373504638672\n",
            "step: 354\n",
            "loss: 164.41473388671875\n",
            "step: 355\n",
            "loss: 204.182373046875\n",
            "step: 356\n",
            "loss: 163.7268524169922\n",
            "step: 357\n",
            "loss: 195.14358520507812\n",
            "step: 358\n",
            "loss: 164.10018920898438\n",
            "step: 359\n",
            "loss: 160.63525390625\n",
            "step: 360\n",
            "loss: 153.42526245117188\n",
            "step: 361\n",
            "loss: 166.44044494628906\n",
            "step: 362\n",
            "loss: 159.38479614257812\n",
            "step: 363\n",
            "loss: 170.9481964111328\n",
            "step: 364\n",
            "loss: 173.88568115234375\n",
            "step: 365\n",
            "loss: 146.76641845703125\n",
            "step: 366\n",
            "loss: 138.82774353027344\n",
            "step: 367\n",
            "loss: 127.58177947998047\n",
            "step: 368\n",
            "loss: 116.42533111572266\n",
            "step: 369\n",
            "loss: 213.7835235595703\n",
            "step: 370\n",
            "loss: 173.31884765625\n",
            "step: 371\n",
            "loss: 173.68490600585938\n",
            "step: 372\n",
            "loss: 150.51361083984375\n",
            "step: 373\n",
            "loss: 159.45106506347656\n",
            "step: 374\n",
            "loss: 178.1252899169922\n",
            "step: 375\n",
            "loss: 165.17445373535156\n",
            "step: 376\n",
            "loss: 184.10145568847656\n",
            "step: 377\n",
            "loss: 169.87342834472656\n",
            "step: 378\n",
            "loss: 157.77175903320312\n",
            "step: 379\n",
            "loss: 240.74978637695312\n",
            "step: 380\n",
            "loss: 152.9359588623047\n",
            "step: 381\n",
            "loss: 180.56118774414062\n",
            "step: 382\n",
            "loss: 156.9124755859375\n",
            "step: 383\n",
            "loss: 179.02947998046875\n",
            "step: 384\n",
            "loss: 169.77310180664062\n",
            "step: 385\n",
            "loss: 152.462890625\n",
            "step: 386\n",
            "loss: 218.15306091308594\n",
            "step: 387\n",
            "loss: 191.4765625\n",
            "step: 388\n",
            "loss: 184.53724670410156\n",
            "step: 389\n",
            "loss: 162.66659545898438\n",
            "step: 390\n",
            "loss: 174.02908325195312\n",
            "step: 391\n",
            "loss: 155.91436767578125\n",
            "step: 392\n",
            "loss: 153.03369140625\n",
            "step: 393\n",
            "loss: 191.56710815429688\n",
            "step: 394\n",
            "loss: 182.58334350585938\n",
            "step: 395\n",
            "loss: 149.96449279785156\n",
            "step: 396\n",
            "loss: 143.97589111328125\n",
            "step: 397\n",
            "loss: 198.6663818359375\n",
            "step: 398\n",
            "loss: 176.5939483642578\n",
            "step: 399\n",
            "loss: 147.74609375\n",
            "step: 400\n",
            "loss: 146.660400390625\n",
            "step: 401\n",
            "loss: 188.531494140625\n",
            "step: 402\n",
            "loss: 177.55308532714844\n",
            "step: 403\n",
            "loss: 176.28399658203125\n",
            "step: 404\n",
            "loss: 125.31272888183594\n",
            "step: 405\n",
            "loss: 150.51898193359375\n",
            "step: 406\n",
            "loss: 151.144287109375\n",
            "step: 407\n",
            "loss: 153.32452392578125\n",
            "step: 408\n",
            "loss: 179.0322265625\n",
            "step: 409\n",
            "loss: 159.20211791992188\n",
            "step: 410\n",
            "loss: 153.47328186035156\n",
            "step: 411\n",
            "loss: 173.438232421875\n",
            "step: 412\n",
            "loss: 199.39962768554688\n",
            "step: 413\n",
            "loss: 197.583984375\n",
            "step: 414\n",
            "loss: 129.4907684326172\n",
            "step: 415\n",
            "loss: 180.9228515625\n",
            "step: 416\n",
            "loss: 122.13671112060547\n",
            "step: 417\n",
            "loss: 172.93748474121094\n",
            "step: 418\n",
            "loss: 152.85113525390625\n",
            "step: 419\n",
            "loss: 127.9001235961914\n",
            "step: 420\n",
            "loss: 144.60110473632812\n",
            "step: 421\n",
            "loss: 136.66082763671875\n",
            "step: 422\n",
            "loss: 172.0956573486328\n",
            "step: 423\n",
            "loss: 164.84646606445312\n",
            "step: 424\n",
            "loss: 201.6820526123047\n",
            "step: 425\n",
            "loss: 191.11813354492188\n",
            "step: 426\n",
            "loss: 155.0496826171875\n",
            "step: 427\n",
            "loss: 155.12071228027344\n",
            "step: 428\n",
            "loss: 133.58535766601562\n",
            "step: 429\n",
            "loss: 164.9093017578125\n",
            "step: 430\n",
            "loss: 115.76213073730469\n",
            "step: 431\n",
            "loss: 158.78854370117188\n",
            "step: 432\n",
            "loss: 148.40008544921875\n",
            "step: 433\n",
            "loss: 157.32278442382812\n",
            "step: 434\n",
            "loss: 145.12557983398438\n",
            "step: 435\n",
            "loss: 150.79623413085938\n",
            "step: 436\n",
            "loss: 141.7545166015625\n",
            "step: 437\n",
            "loss: 159.73768615722656\n",
            "step: 438\n",
            "loss: 188.74923706054688\n",
            "step: 439\n",
            "loss: 188.40451049804688\n",
            "step: 440\n",
            "loss: 142.30157470703125\n",
            "step: 441\n",
            "loss: 143.43917846679688\n",
            "step: 442\n",
            "loss: 162.88998413085938\n",
            "step: 443\n",
            "loss: 125.3012924194336\n",
            "step: 444\n",
            "loss: 169.51246643066406\n",
            "step: 445\n",
            "loss: 125.22419738769531\n",
            "step: 446\n",
            "loss: 97.92156219482422\n",
            "step: 447\n",
            "loss: 114.99176025390625\n",
            "step: 448\n",
            "loss: 160.75155639648438\n",
            "step: 449\n",
            "loss: 127.94971466064453\n",
            "step: 450\n",
            "loss: 111.68677520751953\n",
            "step: 451\n",
            "loss: 118.50222778320312\n",
            "step: 452\n",
            "loss: 123.41592407226562\n",
            "step: 453\n",
            "loss: 100.47773742675781\n",
            "step: 454\n",
            "loss: 180.26222229003906\n",
            "step: 455\n",
            "loss: 123.75919342041016\n",
            "step: 456\n",
            "loss: 129.5682373046875\n",
            "step: 457\n",
            "loss: 111.69903564453125\n",
            "step: 458\n",
            "loss: 151.992431640625\n",
            "step: 459\n",
            "loss: 145.94773864746094\n",
            "step: 460\n",
            "loss: 130.48106384277344\n",
            "step: 461\n",
            "loss: 104.43577575683594\n",
            "step: 462\n",
            "loss: 111.92578125\n",
            "step: 463\n",
            "loss: 139.67510986328125\n",
            "step: 464\n",
            "loss: 189.40646362304688\n",
            "step: 465\n",
            "loss: 140.25506591796875\n",
            "step: 466\n",
            "loss: 184.76031494140625\n",
            "step: 467\n",
            "loss: 119.40727233886719\n",
            "step: 468\n",
            "loss: 122.70198059082031\n",
            "step: 469\n",
            "loss: 119.07803344726562\n",
            "step: 470\n",
            "loss: 125.0093994140625\n",
            "step: 471\n",
            "loss: 140.93341064453125\n",
            "step: 472\n",
            "loss: 105.56793212890625\n",
            "step: 473\n",
            "loss: 107.13880157470703\n",
            "step: 474\n",
            "loss: 130.19696044921875\n",
            "step: 475\n",
            "loss: 99.54391479492188\n",
            "step: 476\n",
            "loss: 126.00527954101562\n",
            "step: 477\n",
            "loss: 137.16094970703125\n",
            "step: 478\n",
            "loss: 124.59007263183594\n",
            "step: 479\n",
            "loss: 118.54183959960938\n",
            "step: 480\n",
            "loss: 122.97776794433594\n",
            "step: 481\n",
            "loss: 166.7811737060547\n",
            "step: 482\n",
            "loss: 111.43339538574219\n",
            "step: 483\n",
            "loss: 131.1327667236328\n",
            "step: 484\n",
            "loss: 153.24169921875\n",
            "step: 485\n",
            "loss: 131.9273223876953\n",
            "step: 486\n",
            "loss: 134.55870056152344\n",
            "step: 487\n",
            "loss: 126.24545288085938\n",
            "step: 488\n",
            "loss: 119.40249633789062\n",
            "step: 489\n",
            "loss: 155.84841918945312\n",
            "step: 490\n",
            "loss: 104.84855651855469\n",
            "step: 491\n",
            "loss: 146.76800537109375\n",
            "step: 492\n",
            "loss: 122.4937515258789\n",
            "step: 493\n",
            "loss: 154.1016845703125\n",
            "step: 494\n",
            "loss: 103.89743041992188\n",
            "step: 495\n",
            "loss: 132.9864959716797\n",
            "step: 496\n",
            "loss: 97.0084228515625\n",
            "step: 497\n",
            "loss: 102.13511657714844\n",
            "step: 498\n",
            "loss: 132.51527404785156\n",
            "step: 499\n",
            "loss: 120.22659301757812\n",
            "step: 500\n",
            "loss: 128.1087188720703\n",
            "step: 501\n",
            "loss: 162.87290954589844\n",
            "step: 502\n",
            "loss: 145.29931640625\n",
            "step: 503\n",
            "loss: 159.34275817871094\n",
            "step: 504\n",
            "loss: 137.89080810546875\n",
            "step: 505\n",
            "loss: 157.1185302734375\n",
            "step: 506\n",
            "loss: 177.08689880371094\n",
            "step: 507\n",
            "loss: 163.48866271972656\n",
            "step: 508\n",
            "loss: 161.21176147460938\n",
            "step: 509\n",
            "loss: 142.98980712890625\n",
            "step: 510\n",
            "loss: 177.6826171875\n",
            "step: 511\n",
            "loss: 173.46142578125\n",
            "step: 512\n",
            "loss: 185.49227905273438\n",
            "step: 513\n",
            "loss: 178.66754150390625\n",
            "step: 514\n",
            "loss: 139.02987670898438\n",
            "step: 515\n",
            "loss: 124.6660385131836\n",
            "step: 516\n",
            "loss: 121.39369201660156\n",
            "step: 517\n",
            "loss: 149.98243713378906\n",
            "step: 518\n",
            "loss: 152.2054443359375\n",
            "step: 519\n",
            "loss: 145.0605010986328\n",
            "step: 520\n",
            "loss: 155.3050537109375\n",
            "step: 521\n",
            "loss: 135.23936462402344\n",
            "step: 522\n",
            "loss: 135.54757690429688\n",
            "step: 523\n",
            "loss: 93.49296569824219\n",
            "step: 524\n",
            "loss: 126.62254333496094\n",
            "step: 525\n",
            "loss: 116.47166442871094\n",
            "step: 526\n",
            "loss: 148.0631103515625\n",
            "step: 527\n",
            "loss: 155.71531677246094\n",
            "step: 528\n",
            "loss: 119.83233642578125\n",
            "step: 529\n",
            "loss: 146.59768676757812\n",
            "step: 530\n",
            "loss: 148.2557373046875\n",
            "step: 531\n",
            "loss: 132.64675903320312\n",
            "step: 532\n",
            "loss: 139.03704833984375\n",
            "step: 533\n",
            "loss: 168.58837890625\n",
            "step: 534\n",
            "loss: 117.74053955078125\n",
            "step: 535\n",
            "loss: 124.41937255859375\n",
            "step: 536\n",
            "loss: 139.5388641357422\n",
            "step: 537\n",
            "loss: 133.29029846191406\n",
            "step: 538\n",
            "loss: 136.2740478515625\n",
            "step: 539\n",
            "loss: 137.03993225097656\n",
            "step: 540\n",
            "loss: 110.80087280273438\n",
            "step: 541\n",
            "loss: 127.02128601074219\n",
            "step: 542\n",
            "loss: 120.99116516113281\n",
            "step: 543\n",
            "loss: 138.95558166503906\n",
            "step: 544\n",
            "loss: 156.29859924316406\n",
            "step: 545\n",
            "loss: 124.28849792480469\n",
            "step: 546\n",
            "loss: 162.20989990234375\n",
            "step: 547\n",
            "loss: 129.69216918945312\n",
            "step: 548\n",
            "loss: 147.43927001953125\n",
            "step: 549\n",
            "loss: 111.93788146972656\n",
            "step: 550\n",
            "loss: 118.67095947265625\n",
            "step: 551\n",
            "loss: 127.64187622070312\n",
            "step: 552\n",
            "loss: 109.46815490722656\n",
            "step: 553\n",
            "loss: 124.27037048339844\n",
            "step: 554\n",
            "loss: 124.49237060546875\n",
            "step: 555\n",
            "loss: 125.6601333618164\n",
            "step: 556\n",
            "loss: 128.84039306640625\n",
            "step: 557\n",
            "loss: 101.63866424560547\n",
            "step: 558\n",
            "loss: 149.3724822998047\n",
            "step: 559\n",
            "loss: 102.04954528808594\n",
            "step: 560\n",
            "loss: 111.50733184814453\n",
            "step: 561\n",
            "loss: 141.86016845703125\n",
            "step: 562\n",
            "loss: 129.71221923828125\n",
            "step: 563\n",
            "loss: 114.9527587890625\n",
            "step: 564\n",
            "loss: 79.8040771484375\n",
            "step: 565\n",
            "loss: 160.90524291992188\n",
            "step: 566\n",
            "loss: 124.76553344726562\n",
            "step: 567\n",
            "loss: 170.27818298339844\n",
            "step: 568\n",
            "loss: 128.89010620117188\n",
            "step: 569\n",
            "loss: 122.79473876953125\n",
            "step: 570\n",
            "loss: 149.73822021484375\n",
            "step: 571\n",
            "loss: 136.7879638671875\n",
            "step: 572\n",
            "loss: 154.11029052734375\n",
            "step: 573\n",
            "loss: 186.27789306640625\n",
            "step: 574\n",
            "loss: 143.77366638183594\n",
            "step: 575\n",
            "loss: 115.90462493896484\n",
            "step: 576\n",
            "loss: 165.0821533203125\n",
            "step: 577\n",
            "loss: 148.6732635498047\n",
            "step: 578\n",
            "loss: 127.75817108154297\n",
            "step: 579\n",
            "loss: 180.5554656982422\n",
            "step: 580\n",
            "loss: 136.96295166015625\n",
            "step: 581\n",
            "loss: 165.63784790039062\n",
            "step: 582\n",
            "loss: 108.42974090576172\n",
            "step: 583\n",
            "loss: 125.06187438964844\n",
            "step: 584\n",
            "loss: 207.1143341064453\n",
            "step: 585\n",
            "loss: 132.49557495117188\n",
            "step: 586\n",
            "loss: 145.20150756835938\n",
            "step: 587\n",
            "loss: 153.73431396484375\n",
            "step: 588\n",
            "loss: 131.94886779785156\n",
            "step: 589\n",
            "loss: 134.39483642578125\n",
            "step: 590\n",
            "loss: 138.77786254882812\n",
            "step: 591\n",
            "loss: 114.01213073730469\n",
            "step: 592\n",
            "loss: 113.91264343261719\n",
            "step: 593\n",
            "loss: 119.35365295410156\n",
            "step: 594\n",
            "loss: 145.1869659423828\n",
            "step: 595\n",
            "loss: 175.3115234375\n",
            "step: 596\n",
            "loss: 171.12887573242188\n",
            "step: 597\n",
            "loss: 126.27061462402344\n",
            "step: 598\n",
            "loss: 119.60212707519531\n",
            "step: 599\n",
            "loss: 132.66311645507812\n",
            "step: 600\n",
            "loss: 106.71391296386719\n",
            "step: 601\n",
            "loss: 140.2861328125\n",
            "step: 602\n",
            "loss: 136.7835693359375\n",
            "step: 603\n",
            "loss: 95.43840789794922\n",
            "step: 604\n",
            "loss: 136.41973876953125\n",
            "step: 605\n",
            "loss: 109.37545776367188\n",
            "step: 606\n",
            "loss: 147.883544921875\n",
            "step: 607\n",
            "loss: 170.64535522460938\n",
            "step: 608\n",
            "loss: 108.36140441894531\n",
            "step: 609\n",
            "loss: 112.02708435058594\n",
            "step: 610\n",
            "loss: 105.31966400146484\n",
            "step: 611\n",
            "loss: 156.07318115234375\n",
            "step: 612\n",
            "loss: 123.98153686523438\n",
            "step: 613\n",
            "loss: 108.72469329833984\n",
            "step: 614\n",
            "loss: 134.725341796875\n",
            "step: 615\n",
            "loss: 130.1737823486328\n",
            "step: 616\n",
            "loss: 114.73045349121094\n",
            "step: 617\n",
            "loss: 145.77896118164062\n",
            "step: 618\n",
            "loss: 194.66738891601562\n",
            "step: 619\n",
            "loss: 145.98040771484375\n",
            "step: 620\n",
            "loss: 136.2845458984375\n",
            "step: 621\n",
            "loss: 147.51422119140625\n",
            "step: 622\n",
            "loss: 168.188720703125\n",
            "step: 623\n",
            "loss: 119.92474365234375\n",
            "step: 624\n",
            "loss: 139.313720703125\n",
            "step: 625\n",
            "loss: 117.40153503417969\n",
            "step: 626\n",
            "loss: 120.95479583740234\n",
            "step: 627\n",
            "loss: 176.5380401611328\n",
            "step: 628\n",
            "loss: 146.35052490234375\n",
            "step: 629\n",
            "loss: 138.6051483154297\n",
            "step: 630\n",
            "loss: 126.74696350097656\n",
            "step: 631\n",
            "loss: 149.28555297851562\n",
            "step: 632\n",
            "loss: 140.7064208984375\n",
            "step: 633\n",
            "loss: 144.2918243408203\n",
            "step: 634\n",
            "loss: 134.18634033203125\n",
            "step: 635\n",
            "loss: 169.63983154296875\n",
            "step: 636\n",
            "loss: 152.45184326171875\n",
            "step: 637\n",
            "loss: 134.9668731689453\n",
            "step: 638\n",
            "loss: 134.58953857421875\n",
            "step: 639\n",
            "loss: 139.410400390625\n",
            "step: 640\n",
            "loss: 165.21804809570312\n",
            "step: 641\n",
            "loss: 135.23318481445312\n",
            "step: 642\n",
            "loss: 127.36973571777344\n",
            "step: 643\n",
            "loss: 129.3891143798828\n",
            "step: 644\n",
            "loss: 129.45816040039062\n",
            "step: 645\n",
            "loss: 145.91680908203125\n",
            "step: 646\n",
            "loss: 129.29200744628906\n",
            "step: 647\n",
            "loss: 189.74639892578125\n",
            "step: 648\n",
            "loss: 139.82794189453125\n",
            "step: 649\n",
            "loss: 174.6905517578125\n",
            "step: 650\n",
            "loss: 131.85134887695312\n",
            "step: 651\n",
            "loss: 130.7052764892578\n",
            "step: 652\n",
            "loss: 136.41973876953125\n",
            "step: 653\n",
            "loss: 115.97644805908203\n",
            "step: 654\n",
            "loss: 133.95703125\n",
            "step: 655\n",
            "loss: 120.88137817382812\n",
            "step: 656\n",
            "loss: 121.82293701171875\n",
            "step: 657\n",
            "loss: 124.9986801147461\n",
            "step: 658\n",
            "loss: 117.08816528320312\n",
            "step: 659\n",
            "loss: 151.6851043701172\n",
            "step: 660\n",
            "loss: 111.23670196533203\n",
            "step: 661\n",
            "loss: 102.08113098144531\n",
            "step: 662\n",
            "loss: 132.404052734375\n",
            "step: 663\n",
            "loss: 87.84092712402344\n",
            "step: 664\n",
            "loss: 158.0636444091797\n",
            "step: 665\n",
            "loss: 112.19642639160156\n",
            "step: 666\n",
            "loss: 103.24861145019531\n",
            "step: 667\n",
            "loss: 157.88339233398438\n",
            "step: 668\n",
            "loss: 97.00545501708984\n",
            "step: 669\n",
            "loss: 128.09713745117188\n",
            "step: 670\n",
            "loss: 89.55592346191406\n",
            "step: 671\n",
            "loss: 118.66828918457031\n",
            "step: 672\n",
            "loss: 98.82469940185547\n",
            "step: 673\n",
            "loss: 132.5713653564453\n",
            "step: 674\n",
            "loss: 137.19189453125\n",
            "step: 675\n",
            "loss: 117.49227905273438\n",
            "step: 676\n",
            "loss: 109.48234558105469\n",
            "step: 677\n",
            "loss: 121.0263671875\n",
            "step: 678\n",
            "loss: 121.98735809326172\n",
            "step: 679\n",
            "loss: 110.41036224365234\n",
            "step: 680\n",
            "loss: 103.53144073486328\n",
            "step: 681\n",
            "loss: 66.36737060546875\n",
            "step: 682\n",
            "loss: 113.87898254394531\n",
            "step: 683\n",
            "loss: 152.13088989257812\n",
            "step: 684\n",
            "loss: 99.29193878173828\n",
            "step: 685\n",
            "loss: 63.81299591064453\n",
            "step: 686\n",
            "loss: 108.22396850585938\n",
            "step: 687\n",
            "loss: 110.83711242675781\n",
            "step: 688\n",
            "loss: 126.8720703125\n",
            "step: 689\n",
            "loss: 113.49909210205078\n",
            "step: 690\n",
            "loss: 126.8343505859375\n",
            "step: 691\n",
            "loss: 101.06825256347656\n",
            "step: 692\n",
            "loss: 111.1339111328125\n",
            "step: 693\n",
            "loss: 88.27902221679688\n",
            "step: 694\n",
            "loss: 134.42196655273438\n",
            "step: 695\n",
            "loss: 127.75819396972656\n",
            "step: 696\n",
            "loss: 117.1483154296875\n",
            "step: 697\n",
            "loss: 95.95927429199219\n",
            "step: 698\n",
            "loss: 107.32777404785156\n",
            "step: 699\n",
            "loss: 142.86587524414062\n",
            "step: 700\n",
            "loss: 122.49471282958984\n",
            "step: 701\n",
            "loss: 143.79833984375\n",
            "step: 702\n",
            "loss: 106.29698181152344\n",
            "step: 703\n",
            "loss: 87.9189453125\n",
            "step: 704\n",
            "loss: 82.22264099121094\n",
            "step: 705\n",
            "loss: 113.73497772216797\n",
            "step: 706\n",
            "loss: 101.05255126953125\n",
            "step: 707\n",
            "loss: 88.41658020019531\n",
            "step: 708\n",
            "loss: 131.0414276123047\n",
            "step: 709\n",
            "loss: 82.39137268066406\n",
            "step: 710\n",
            "loss: 139.2210693359375\n",
            "step: 711\n",
            "loss: 97.89566040039062\n",
            "step: 712\n",
            "loss: 93.03776550292969\n",
            "step: 713\n",
            "loss: 119.28758239746094\n",
            "step: 714\n",
            "loss: 136.53152465820312\n",
            "step: 715\n",
            "loss: 86.83853149414062\n",
            "step: 716\n",
            "loss: 145.8628692626953\n",
            "step: 717\n",
            "loss: 100.32402038574219\n",
            "step: 718\n",
            "loss: 93.59869384765625\n",
            "step: 719\n",
            "loss: 94.81268310546875\n",
            "step: 720\n",
            "loss: 117.14198303222656\n",
            "step: 721\n",
            "loss: 129.55035400390625\n",
            "step: 722\n",
            "loss: 96.21382141113281\n",
            "step: 723\n",
            "loss: 92.83396911621094\n",
            "step: 724\n",
            "loss: 121.44010925292969\n",
            "step: 725\n",
            "loss: 93.98560333251953\n",
            "step: 726\n",
            "loss: 136.6754913330078\n",
            "step: 727\n",
            "loss: 73.0220947265625\n",
            "step: 728\n",
            "loss: 108.76480102539062\n",
            "step: 729\n",
            "loss: 93.320068359375\n",
            "step: 730\n",
            "loss: 92.9638671875\n",
            "step: 731\n",
            "loss: 115.36439514160156\n",
            "step: 732\n",
            "loss: 115.33322143554688\n",
            "step: 733\n",
            "loss: 131.3984832763672\n",
            "step: 734\n",
            "loss: 140.44757080078125\n",
            "step: 735\n",
            "loss: 105.13619995117188\n",
            "step: 736\n",
            "loss: 108.58690643310547\n",
            "step: 737\n",
            "loss: 106.24488067626953\n",
            "step: 738\n",
            "loss: 110.12727355957031\n",
            "step: 739\n",
            "loss: 156.98623657226562\n",
            "step: 740\n",
            "loss: 97.31559753417969\n",
            "step: 741\n",
            "loss: 117.89112854003906\n",
            "step: 742\n",
            "loss: 147.91232299804688\n",
            "step: 743\n",
            "loss: 119.79714965820312\n",
            "step: 744\n",
            "loss: 124.55233001708984\n",
            "step: 745\n",
            "loss: 91.71843719482422\n",
            "step: 746\n",
            "loss: 85.6325912475586\n",
            "step: 747\n",
            "loss: 131.2523193359375\n",
            "step: 748\n",
            "loss: 135.81500244140625\n",
            "step: 749\n",
            "loss: 106.50601196289062\n",
            "step: 750\n",
            "loss: 155.98431396484375\n",
            "step: 751\n",
            "loss: 88.83906555175781\n",
            "step: 752\n",
            "loss: 136.75454711914062\n",
            "step: 753\n",
            "loss: 97.12130737304688\n",
            "step: 754\n",
            "loss: 114.55302429199219\n",
            "step: 755\n",
            "loss: 119.80966186523438\n",
            "step: 756\n",
            "loss: 118.49388122558594\n",
            "step: 757\n",
            "loss: 154.90115356445312\n",
            "step: 758\n",
            "loss: 136.98245239257812\n",
            "step: 759\n",
            "loss: 95.99409484863281\n",
            "step: 760\n",
            "loss: 118.8412094116211\n",
            "step: 761\n",
            "loss: 115.88893127441406\n",
            "step: 762\n",
            "loss: 125.58953857421875\n",
            "step: 763\n",
            "loss: 96.37853240966797\n",
            "step: 764\n",
            "loss: 129.3574676513672\n",
            "step: 765\n",
            "loss: 119.32516479492188\n",
            "step: 766\n",
            "loss: 113.24449157714844\n",
            "step: 767\n",
            "loss: 141.77801513671875\n",
            "step: 768\n",
            "loss: 119.5566177368164\n",
            "step: 769\n",
            "loss: 102.71115112304688\n",
            "step: 770\n",
            "loss: 102.8814697265625\n",
            "step: 771\n",
            "loss: 122.76394653320312\n",
            "step: 772\n",
            "loss: 100.09322357177734\n",
            "step: 773\n",
            "loss: 118.30584716796875\n",
            "step: 774\n",
            "loss: 104.200927734375\n",
            "step: 775\n",
            "loss: 93.90959167480469\n",
            "step: 776\n",
            "loss: 118.82008361816406\n",
            "step: 777\n",
            "loss: 117.88392639160156\n",
            "step: 778\n",
            "loss: 107.55209350585938\n",
            "step: 779\n",
            "loss: 103.93449401855469\n",
            "step: 780\n",
            "loss: 121.15315246582031\n",
            "step: 781\n",
            "loss: 142.52227783203125\n",
            "step: 782\n",
            "loss: 116.8616943359375\n",
            "step: 783\n",
            "loss: 91.05070495605469\n",
            "step: 784\n",
            "loss: 106.65281677246094\n",
            "step: 785\n",
            "loss: 87.31855010986328\n",
            "step: 786\n",
            "loss: 97.3759765625\n",
            "step: 787\n",
            "loss: 157.48463439941406\n",
            "step: 788\n",
            "loss: 116.46176147460938\n",
            "step: 789\n",
            "loss: 109.49588775634766\n",
            "step: 790\n",
            "loss: 99.10711669921875\n",
            "step: 791\n",
            "loss: 125.19456481933594\n",
            "step: 792\n",
            "loss: 139.8125\n",
            "step: 793\n",
            "loss: 115.84757232666016\n",
            "step: 794\n",
            "loss: 146.7209014892578\n",
            "step: 795\n",
            "loss: 110.37413024902344\n",
            "step: 796\n",
            "loss: 125.89557647705078\n",
            "step: 797\n",
            "loss: 116.49496459960938\n",
            "step: 798\n",
            "loss: 73.87693786621094\n",
            "step: 799\n",
            "loss: 121.72406768798828\n",
            "step: 800\n",
            "loss: 122.91191864013672\n",
            "step: 801\n",
            "loss: 102.07743072509766\n",
            "step: 802\n",
            "loss: 125.23939514160156\n",
            "step: 803\n",
            "loss: 108.5604019165039\n",
            "step: 804\n",
            "loss: 108.8255386352539\n",
            "step: 805\n",
            "loss: 130.77479553222656\n",
            "step: 806\n",
            "loss: 100.70541381835938\n",
            "step: 807\n",
            "loss: 113.72280883789062\n",
            "step: 808\n",
            "loss: 135.80857849121094\n",
            "step: 809\n",
            "loss: 119.16043090820312\n",
            "step: 810\n",
            "loss: 95.99932861328125\n",
            "step: 811\n",
            "loss: 137.3424072265625\n",
            "step: 812\n",
            "loss: 124.9681625366211\n",
            "step: 813\n",
            "loss: 118.28163146972656\n",
            "step: 814\n",
            "loss: 106.16096496582031\n",
            "step: 815\n",
            "loss: 117.34400177001953\n",
            "step: 816\n",
            "loss: 118.35476684570312\n",
            "step: 817\n",
            "loss: 158.54762268066406\n",
            "step: 818\n",
            "loss: 125.73822021484375\n",
            "step: 819\n",
            "loss: 129.14356994628906\n",
            "step: 820\n",
            "loss: 124.05293273925781\n",
            "step: 821\n",
            "loss: 140.49313354492188\n",
            "step: 822\n",
            "loss: 147.7890625\n",
            "step: 823\n",
            "loss: 102.7718505859375\n",
            "step: 824\n",
            "loss: 116.75595092773438\n",
            "step: 825\n",
            "loss: 160.36598205566406\n",
            "step: 826\n",
            "loss: 143.77523803710938\n",
            "step: 827\n",
            "loss: 97.98304748535156\n",
            "step: 828\n",
            "loss: 117.11961364746094\n",
            "step: 829\n",
            "loss: 122.86262512207031\n",
            "step: 830\n",
            "loss: 153.8664093017578\n",
            "step: 831\n",
            "loss: 108.72467803955078\n",
            "step: 832\n",
            "loss: 116.19994354248047\n",
            "step: 833\n",
            "loss: 139.29052734375\n",
            "step: 834\n",
            "loss: 96.96261596679688\n",
            "step: 835\n",
            "loss: 138.44451904296875\n",
            "step: 836\n",
            "loss: 113.63872528076172\n",
            "step: 837\n",
            "loss: 131.39291381835938\n",
            "step: 838\n",
            "loss: 125.32168579101562\n",
            "step: 839\n",
            "loss: 99.50888061523438\n",
            "step: 840\n",
            "loss: 128.04373168945312\n",
            "step: 841\n",
            "loss: 89.95767211914062\n",
            "step: 842\n",
            "loss: 95.59693908691406\n",
            "step: 843\n",
            "loss: 136.82302856445312\n",
            "step: 844\n",
            "loss: 98.7630615234375\n",
            "step: 845\n",
            "loss: 123.3078384399414\n",
            "step: 846\n",
            "loss: 123.0596694946289\n",
            "step: 847\n",
            "loss: 114.9168472290039\n",
            "step: 848\n",
            "loss: 116.67638397216797\n",
            "step: 849\n",
            "loss: 100.74505615234375\n",
            "step: 850\n",
            "loss: 113.00584411621094\n",
            "step: 851\n",
            "loss: 109.39007568359375\n",
            "step: 852\n",
            "loss: 112.92786407470703\n",
            "step: 853\n",
            "loss: 103.77093505859375\n",
            "step: 854\n",
            "loss: 119.69235229492188\n",
            "step: 855\n",
            "loss: 88.40264892578125\n",
            "step: 856\n",
            "loss: 122.36738586425781\n",
            "step: 857\n",
            "loss: 111.20469665527344\n",
            "step: 858\n",
            "loss: 104.23367309570312\n",
            "step: 859\n",
            "loss: 117.18624877929688\n",
            "step: 860\n",
            "loss: 133.74017333984375\n",
            "step: 861\n",
            "loss: 139.31582641601562\n",
            "step: 862\n",
            "loss: 95.627197265625\n",
            "step: 863\n",
            "loss: 83.60102081298828\n",
            "step: 864\n",
            "loss: 148.56924438476562\n",
            "step: 865\n",
            "loss: 120.54420471191406\n",
            "step: 866\n",
            "loss: 119.42008972167969\n",
            "step: 867\n",
            "loss: 110.09156036376953\n",
            "step: 868\n",
            "loss: 116.01840209960938\n",
            "step: 869\n",
            "loss: 102.6646728515625\n",
            "step: 870\n",
            "loss: 128.43142700195312\n",
            "step: 871\n",
            "loss: 127.98506164550781\n",
            "step: 872\n",
            "loss: 167.5647430419922\n",
            "step: 873\n",
            "loss: 103.80429077148438\n",
            "step: 874\n",
            "loss: 103.10584259033203\n",
            "step: 875\n",
            "loss: 98.61610412597656\n",
            "step: 876\n",
            "loss: 100.15017700195312\n",
            "step: 877\n",
            "loss: 134.3006591796875\n",
            "step: 878\n",
            "loss: 110.20220184326172\n",
            "step: 879\n",
            "loss: 120.45523071289062\n",
            "step: 880\n",
            "loss: 141.74569702148438\n",
            "step: 881\n",
            "loss: 116.35639953613281\n",
            "step: 882\n",
            "loss: 146.56753540039062\n",
            "step: 883\n",
            "loss: 89.1207046508789\n",
            "step: 884\n",
            "loss: 99.72232055664062\n",
            "step: 885\n",
            "loss: 101.62680053710938\n",
            "step: 886\n",
            "loss: 119.85395050048828\n",
            "step: 887\n",
            "loss: 138.89842224121094\n",
            "step: 888\n",
            "loss: 97.92277526855469\n",
            "step: 889\n",
            "loss: 128.64208984375\n",
            "step: 890\n",
            "loss: 115.53082275390625\n",
            "step: 891\n",
            "loss: 123.44377136230469\n",
            "step: 892\n",
            "loss: 113.25198364257812\n",
            "step: 893\n",
            "loss: 127.73883056640625\n",
            "step: 894\n",
            "loss: 104.34587097167969\n",
            "step: 895\n",
            "loss: 88.58220672607422\n",
            "step: 896\n",
            "loss: 125.27430725097656\n",
            "step: 897\n",
            "loss: 107.89643096923828\n",
            "step: 898\n",
            "loss: 97.16588592529297\n",
            "step: 899\n",
            "loss: 93.39373779296875\n",
            "step: 900\n",
            "loss: 93.803955078125\n",
            "step: 901\n",
            "loss: 129.73812866210938\n",
            "step: 902\n",
            "loss: 103.66560363769531\n",
            "step: 903\n",
            "loss: 105.0819091796875\n",
            "step: 904\n",
            "loss: 87.40885162353516\n",
            "step: 905\n",
            "loss: 99.79234313964844\n",
            "step: 906\n",
            "loss: 78.30476379394531\n",
            "step: 907\n",
            "loss: 57.56428527832031\n",
            "step: 908\n",
            "loss: 97.12184143066406\n",
            "step: 909\n",
            "loss: 94.3613052368164\n",
            "step: 910\n",
            "loss: 128.80105590820312\n",
            "step: 911\n",
            "loss: 86.83586120605469\n",
            "step: 912\n",
            "loss: 101.55746459960938\n",
            "step: 913\n",
            "loss: 98.92207336425781\n",
            "step: 914\n",
            "loss: 100.19335174560547\n",
            "step: 915\n",
            "loss: 104.74400329589844\n",
            "step: 916\n",
            "loss: 77.90910339355469\n",
            "step: 917\n",
            "loss: 120.40093994140625\n",
            "step: 918\n",
            "loss: 76.73825073242188\n",
            "step: 919\n",
            "loss: 112.00941467285156\n",
            "step: 920\n",
            "loss: 124.97016906738281\n",
            "step: 921\n",
            "loss: 79.24932861328125\n",
            "step: 922\n",
            "loss: 111.69586181640625\n",
            "step: 923\n",
            "loss: 97.10262298583984\n",
            "step: 924\n",
            "loss: 82.8670654296875\n",
            "step: 925\n",
            "loss: 109.0733413696289\n",
            "step: 926\n",
            "loss: 79.31647491455078\n",
            "step: 927\n",
            "loss: 79.30281829833984\n",
            "step: 928\n",
            "loss: 134.23081970214844\n",
            "step: 929\n",
            "loss: 66.62205505371094\n",
            "step: 930\n",
            "loss: 95.07405853271484\n",
            "step: 931\n",
            "loss: 100.8161849975586\n",
            "step: 932\n",
            "loss: 111.01190948486328\n",
            "step: 933\n",
            "loss: 76.14022064208984\n",
            "step: 934\n",
            "loss: 95.36722564697266\n",
            "step: 935\n",
            "loss: 102.57062530517578\n",
            "step: 936\n",
            "loss: 85.9919662475586\n",
            "step: 937\n",
            "loss: 97.65553283691406\n",
            "step: 938\n",
            "loss: 110.57526397705078\n",
            "step: 939\n",
            "loss: 80.15709686279297\n",
            "step: 940\n",
            "loss: 83.18415069580078\n",
            "step: 941\n",
            "loss: 82.03181457519531\n",
            "step: 942\n",
            "loss: 114.45624542236328\n",
            "step: 943\n",
            "loss: 105.44232177734375\n",
            "step: 944\n",
            "loss: 65.55081176757812\n",
            "step: 945\n",
            "loss: 94.35728454589844\n",
            "step: 946\n",
            "loss: 86.89654541015625\n",
            "step: 947\n",
            "loss: 85.09602355957031\n",
            "step: 948\n",
            "loss: 93.84353637695312\n",
            "step: 949\n",
            "loss: 98.16032409667969\n",
            "step: 950\n",
            "loss: 108.84070587158203\n",
            "step: 951\n",
            "loss: 101.00898742675781\n",
            "step: 952\n",
            "loss: 128.70416259765625\n",
            "step: 953\n",
            "loss: 95.62885284423828\n",
            "step: 954\n",
            "loss: 119.5724868774414\n",
            "step: 955\n",
            "loss: 107.37715911865234\n",
            "step: 956\n",
            "loss: 87.80024719238281\n",
            "step: 957\n",
            "loss: 103.31888580322266\n",
            "step: 958\n",
            "loss: 102.3443603515625\n",
            "step: 959\n",
            "loss: 116.14892578125\n",
            "step: 960\n",
            "loss: 139.523681640625\n",
            "step: 961\n",
            "loss: 98.43415832519531\n",
            "step: 962\n",
            "loss: 88.59228515625\n",
            "step: 963\n",
            "loss: 126.67112731933594\n",
            "step: 964\n",
            "loss: 81.3770523071289\n",
            "step: 965\n",
            "loss: 77.29000854492188\n",
            "step: 966\n",
            "loss: 128.14468383789062\n",
            "step: 967\n",
            "loss: 109.49624633789062\n",
            "step: 968\n",
            "loss: 88.90202331542969\n",
            "step: 969\n",
            "loss: 132.560546875\n",
            "step: 970\n",
            "loss: 82.31806945800781\n",
            "step: 971\n",
            "loss: 137.87269592285156\n",
            "step: 972\n",
            "loss: 94.9755859375\n",
            "step: 973\n",
            "loss: 100.02694702148438\n",
            "step: 974\n",
            "loss: 80.9466552734375\n",
            "step: 975\n",
            "loss: 84.85220336914062\n",
            "step: 976\n",
            "loss: 141.9502410888672\n",
            "step: 977\n",
            "loss: 113.14556121826172\n",
            "step: 978\n",
            "loss: 113.50279998779297\n",
            "step: 979\n",
            "loss: 115.17582702636719\n",
            "step: 980\n",
            "loss: 88.76918029785156\n",
            "step: 981\n",
            "loss: 120.33149719238281\n",
            "step: 982\n",
            "loss: 82.87171936035156\n",
            "step: 983\n",
            "loss: 120.43194580078125\n",
            "step: 984\n",
            "loss: 95.8726806640625\n",
            "step: 985\n",
            "loss: 88.42877197265625\n",
            "step: 986\n",
            "loss: 104.39925384521484\n",
            "step: 987\n",
            "loss: 70.46878051757812\n",
            "step: 988\n",
            "loss: 154.44488525390625\n",
            "step: 989\n",
            "loss: 90.64136505126953\n",
            "step: 990\n",
            "loss: 121.63731384277344\n",
            "step: 991\n",
            "loss: 111.76142883300781\n",
            "step: 992\n",
            "loss: 71.32842254638672\n",
            "step: 993\n",
            "loss: 100.69669342041016\n",
            "step: 994\n",
            "loss: 109.43276977539062\n",
            "step: 995\n",
            "loss: 82.40267944335938\n",
            "step: 996\n",
            "loss: 113.63493347167969\n",
            "step: 997\n",
            "loss: 119.88092041015625\n",
            "step: 998\n",
            "loss: 116.5163803100586\n",
            "step: 999\n",
            "loss: 93.56884002685547\n",
            "step: 1000\n",
            "loss: 125.59253692626953\n",
            "step: 1001\n",
            "loss: 128.83078002929688\n",
            "step: 1002\n",
            "loss: 78.54258728027344\n",
            "step: 1003\n",
            "loss: 93.3565673828125\n",
            "step: 1004\n",
            "loss: 93.64930725097656\n",
            "step: 1005\n",
            "loss: 150.8441162109375\n",
            "step: 1006\n",
            "loss: 76.2276611328125\n",
            "step: 1007\n",
            "loss: 122.38191223144531\n",
            "step: 1008\n",
            "loss: 88.96099853515625\n",
            "step: 1009\n",
            "loss: 120.23656463623047\n",
            "step: 1010\n",
            "loss: 90.924072265625\n",
            "step: 1011\n",
            "loss: 99.4660415649414\n",
            "step: 1012\n",
            "loss: 79.07548522949219\n",
            "step: 1013\n",
            "loss: 103.91377258300781\n",
            "step: 1014\n",
            "loss: 91.60308837890625\n",
            "step: 1015\n",
            "loss: 88.36011505126953\n",
            "step: 1016\n",
            "loss: 104.77924346923828\n",
            "step: 1017\n",
            "loss: 82.40785217285156\n",
            "step: 1018\n",
            "loss: 104.41063690185547\n",
            "step: 1019\n",
            "loss: 140.23573303222656\n",
            "step: 1020\n",
            "loss: 106.60199737548828\n",
            "step: 1021\n",
            "loss: 97.69613647460938\n",
            "step: 1022\n",
            "loss: 125.67864990234375\n",
            "step: 1023\n",
            "loss: 102.679931640625\n",
            "step: 1024\n",
            "loss: 104.60700988769531\n",
            "step: 1025\n",
            "loss: 96.06693267822266\n",
            "step: 1026\n",
            "loss: 67.56704711914062\n",
            "step: 1027\n",
            "loss: 104.48927307128906\n",
            "step: 1028\n",
            "loss: 83.26988220214844\n",
            "step: 1029\n",
            "loss: 96.0155029296875\n",
            "step: 1030\n",
            "loss: 90.92259216308594\n",
            "step: 1031\n",
            "loss: 115.83030700683594\n",
            "step: 1032\n",
            "loss: 94.32080078125\n",
            "step: 1033\n",
            "loss: 113.73241424560547\n",
            "step: 1034\n",
            "loss: 87.76359558105469\n",
            "step: 1035\n",
            "loss: 97.07881164550781\n",
            "step: 1036\n",
            "loss: 111.74287414550781\n",
            "step: 1037\n",
            "loss: 108.47933197021484\n",
            "step: 1038\n",
            "loss: 78.39552307128906\n",
            "step: 1039\n",
            "loss: 115.2712631225586\n",
            "step: 1040\n",
            "loss: 112.37958526611328\n",
            "step: 1041\n",
            "loss: 128.4375457763672\n",
            "step: 1042\n",
            "loss: 113.32396697998047\n",
            "step: 1043\n",
            "loss: 103.74100494384766\n",
            "step: 1044\n",
            "loss: 97.14091491699219\n",
            "step: 1045\n",
            "loss: 84.01268005371094\n",
            "step: 1046\n",
            "loss: 180.4873046875\n",
            "step: 1047\n",
            "loss: 95.82154846191406\n",
            "step: 1048\n",
            "loss: 100.83064270019531\n",
            "step: 1049\n",
            "loss: 127.36750793457031\n",
            "step: 1050\n",
            "loss: 99.98231506347656\n",
            "step: 1051\n",
            "loss: 88.27366638183594\n",
            "step: 1052\n",
            "loss: 114.60980987548828\n",
            "step: 1053\n",
            "loss: 110.32799530029297\n",
            "step: 1054\n",
            "loss: 90.12224578857422\n",
            "step: 1055\n",
            "loss: 112.90704345703125\n",
            "step: 1056\n",
            "loss: 126.49075317382812\n",
            "step: 1057\n",
            "loss: 90.89159393310547\n",
            "step: 1058\n",
            "loss: 133.28671264648438\n",
            "step: 1059\n",
            "loss: 90.46144104003906\n",
            "step: 1060\n",
            "loss: 82.89665222167969\n",
            "step: 1061\n",
            "loss: 117.53811645507812\n",
            "step: 1062\n",
            "loss: 99.03384399414062\n",
            "step: 1063\n",
            "loss: 92.96842193603516\n",
            "step: 1064\n",
            "loss: 139.66781616210938\n",
            "step: 1065\n",
            "loss: 111.71148681640625\n",
            "step: 1066\n",
            "loss: 73.66238403320312\n",
            "step: 1067\n",
            "loss: 101.22047424316406\n",
            "step: 1068\n",
            "loss: 49.781089782714844\n",
            "step: 1069\n",
            "loss: 84.84478759765625\n",
            "step: 1070\n",
            "loss: 109.8441162109375\n",
            "step: 1071\n",
            "loss: 92.57439422607422\n",
            "step: 1072\n",
            "loss: 78.39823913574219\n",
            "step: 1073\n",
            "loss: 131.24842834472656\n",
            "step: 1074\n",
            "loss: 71.34630584716797\n",
            "step: 1075\n",
            "loss: 134.32310485839844\n",
            "step: 1076\n",
            "loss: 96.2569808959961\n",
            "step: 1077\n",
            "loss: 116.09420776367188\n",
            "step: 1078\n",
            "loss: 78.85671997070312\n",
            "step: 1079\n",
            "loss: 94.374267578125\n",
            "step: 1080\n",
            "loss: 105.27040100097656\n",
            "step: 1081\n",
            "loss: 98.43128204345703\n",
            "step: 1082\n",
            "loss: 112.4071273803711\n",
            "step: 1083\n",
            "loss: 95.45449829101562\n",
            "step: 1084\n",
            "loss: 86.90615844726562\n",
            "step: 1085\n",
            "loss: 134.02882385253906\n",
            "step: 1086\n",
            "loss: 94.08380126953125\n",
            "step: 1087\n",
            "loss: 108.265625\n",
            "step: 1088\n",
            "loss: 114.03395080566406\n",
            "step: 1089\n",
            "loss: 81.87396240234375\n",
            "step: 1090\n",
            "loss: 105.36711883544922\n",
            "step: 1091\n",
            "loss: 132.46173095703125\n",
            "step: 1092\n",
            "loss: 85.13479614257812\n",
            "step: 1093\n",
            "loss: 120.9559097290039\n",
            "step: 1094\n",
            "loss: 115.83009338378906\n",
            "step: 1095\n",
            "loss: 109.05030822753906\n",
            "step: 1096\n",
            "loss: 93.36572265625\n",
            "step: 1097\n",
            "loss: 109.48745727539062\n",
            "step: 1098\n",
            "loss: 143.02630615234375\n",
            "step: 1099\n",
            "loss: 101.12687683105469\n",
            "step: 1100\n",
            "loss: 111.2354965209961\n",
            "step: 1101\n",
            "loss: 58.50794982910156\n",
            "step: 1102\n",
            "loss: 145.2499237060547\n",
            "step: 1103\n",
            "loss: 86.24701690673828\n",
            "step: 1104\n",
            "loss: 94.70848846435547\n",
            "step: 1105\n",
            "loss: 87.61460876464844\n",
            "step: 1106\n",
            "loss: 116.20018005371094\n",
            "step: 1107\n",
            "loss: 136.14639282226562\n",
            "step: 1108\n",
            "loss: 91.81103515625\n",
            "step: 1109\n",
            "loss: 100.04246520996094\n",
            "step: 1110\n",
            "loss: 97.16668701171875\n",
            "step: 1111\n",
            "loss: 159.62762451171875\n",
            "step: 1112\n",
            "loss: 100.45347595214844\n",
            "step: 1113\n",
            "loss: 112.45913696289062\n",
            "step: 1114\n",
            "loss: 133.74781799316406\n",
            "step: 1115\n",
            "loss: 126.37399291992188\n",
            "step: 1116\n",
            "loss: 113.14256286621094\n",
            "step: 1117\n",
            "loss: 118.06298828125\n",
            "step: 1118\n",
            "loss: 145.60313415527344\n",
            "step: 1119\n",
            "loss: 88.30854797363281\n",
            "step: 1120\n",
            "loss: 99.24207305908203\n",
            "step: 1121\n",
            "loss: 88.66389465332031\n",
            "step: 1122\n",
            "loss: 115.60576629638672\n",
            "step: 1123\n",
            "loss: 119.08296966552734\n",
            "step: 1124\n",
            "loss: 98.43711853027344\n",
            "step: 1125\n",
            "loss: 86.99751281738281\n",
            "step: 1126\n",
            "loss: 91.42141723632812\n",
            "step: 1127\n",
            "loss: 103.78172302246094\n",
            "step: 1128\n",
            "loss: 77.12397003173828\n",
            "step: 1129\n",
            "loss: 106.31181335449219\n",
            "step: 1130\n",
            "loss: 103.91050720214844\n",
            "step: 1131\n",
            "loss: 80.95932006835938\n",
            "step: 1132\n",
            "loss: 123.39581298828125\n",
            "step: 1133\n",
            "loss: 98.5563735961914\n",
            "step: 1134\n",
            "loss: 100.74795532226562\n",
            "step: 1135\n",
            "loss: 87.50489807128906\n",
            "step: 1136\n",
            "loss: 113.64419555664062\n",
            "step: 1137\n",
            "loss: 98.113525390625\n",
            "step: 1138\n",
            "loss: 107.87460327148438\n",
            "step: 1139\n",
            "loss: 84.18699645996094\n",
            "step: 1140\n",
            "loss: 91.6813735961914\n",
            "step: 1141\n",
            "loss: 91.18565368652344\n",
            "step: 1142\n",
            "loss: 91.84916687011719\n",
            "step: 1143\n",
            "loss: 89.90245056152344\n",
            "step: 1144\n",
            "loss: 81.67306518554688\n",
            "step: 1145\n",
            "loss: 107.10298156738281\n",
            "step: 1146\n",
            "loss: 47.708770751953125\n",
            "step: 1147\n",
            "loss: 97.29471588134766\n",
            "step: 1148\n",
            "loss: 80.26152038574219\n",
            "step: 1149\n",
            "loss: 92.3388671875\n",
            "step: 1150\n",
            "loss: 72.70701599121094\n",
            "step: 1151\n",
            "loss: 98.0263671875\n",
            "step: 1152\n",
            "loss: 114.64270782470703\n",
            "step: 1153\n",
            "loss: 79.91622924804688\n",
            "step: 1154\n",
            "loss: 78.6993179321289\n",
            "step: 1155\n",
            "loss: 78.24040222167969\n",
            "step: 1156\n",
            "loss: 111.86654663085938\n",
            "step: 1157\n",
            "loss: 89.79461669921875\n",
            "step: 1158\n",
            "loss: 90.8838882446289\n",
            "step: 1159\n",
            "loss: 66.48223876953125\n",
            "step: 1160\n",
            "loss: 100.61497497558594\n",
            "step: 1161\n",
            "loss: 86.40921020507812\n",
            "step: 1162\n",
            "loss: 79.83111572265625\n",
            "step: 1163\n",
            "loss: 91.42713165283203\n",
            "step: 1164\n",
            "loss: 86.36309051513672\n",
            "step: 1165\n",
            "loss: 115.95514678955078\n",
            "step: 1166\n",
            "loss: 66.22853088378906\n",
            "step: 1167\n",
            "loss: 94.00511932373047\n",
            "step: 1168\n",
            "loss: 95.83268737792969\n",
            "step: 1169\n",
            "loss: 76.96492004394531\n",
            "step: 1170\n",
            "loss: 62.38221740722656\n",
            "step: 1171\n",
            "loss: 102.48942565917969\n",
            "step: 1172\n",
            "loss: 86.56803131103516\n",
            "step: 1173\n",
            "loss: 69.33038330078125\n",
            "step: 1174\n",
            "loss: 98.71353912353516\n",
            "step: 1175\n",
            "loss: 66.63294219970703\n",
            "step: 1176\n",
            "loss: 69.08470153808594\n",
            "step: 1177\n",
            "loss: 80.5522689819336\n",
            "step: 1178\n",
            "loss: 77.51408386230469\n",
            "step: 1179\n",
            "loss: 110.79745483398438\n",
            "step: 1180\n",
            "loss: 71.96016693115234\n",
            "step: 1181\n",
            "loss: 105.77313232421875\n",
            "step: 1182\n",
            "loss: 58.675968170166016\n",
            "step: 1183\n",
            "loss: 95.16321563720703\n",
            "step: 1184\n",
            "loss: 114.51396179199219\n",
            "step: 1185\n",
            "loss: 111.23735046386719\n",
            "step: 1186\n",
            "loss: 98.23358154296875\n",
            "step: 1187\n",
            "loss: 72.05797576904297\n",
            "step: 1188\n",
            "loss: 81.71907043457031\n",
            "step: 1189\n",
            "loss: 85.38590240478516\n",
            "step: 1190\n",
            "loss: 90.53520965576172\n",
            "step: 1191\n",
            "loss: 86.62115478515625\n",
            "step: 1192\n",
            "loss: 87.65817260742188\n",
            "step: 1193\n",
            "loss: 107.15914154052734\n",
            "step: 1194\n",
            "loss: 57.80042266845703\n",
            "step: 1195\n",
            "loss: 101.91859436035156\n",
            "step: 1196\n",
            "loss: 122.695068359375\n",
            "step: 1197\n",
            "loss: 77.01898193359375\n",
            "step: 1198\n",
            "loss: 108.76130676269531\n",
            "step: 1199\n",
            "loss: 56.08427429199219\n",
            "step: 1200\n",
            "loss: 82.14947509765625\n",
            "step: 1201\n",
            "loss: 94.46398162841797\n",
            "step: 1202\n",
            "loss: 66.63490295410156\n",
            "step: 1203\n",
            "loss: 91.43714904785156\n",
            "step: 1204\n",
            "loss: 71.1747055053711\n",
            "step: 1205\n",
            "loss: 126.70142364501953\n",
            "step: 1206\n",
            "loss: 78.97828674316406\n",
            "step: 1207\n",
            "loss: 82.51649475097656\n",
            "step: 1208\n",
            "loss: 100.4140853881836\n",
            "step: 1209\n",
            "loss: 100.93316650390625\n",
            "step: 1210\n",
            "loss: 98.29478454589844\n",
            "step: 1211\n",
            "loss: 95.79658508300781\n",
            "step: 1212\n",
            "loss: 97.04792785644531\n",
            "step: 1213\n",
            "loss: 92.39851379394531\n",
            "step: 1214\n",
            "loss: 76.71531677246094\n",
            "step: 1215\n",
            "loss: 87.12104797363281\n",
            "step: 1216\n",
            "loss: 127.21324920654297\n",
            "step: 1217\n",
            "loss: 92.03073120117188\n",
            "step: 1218\n",
            "loss: 119.85025787353516\n",
            "step: 1219\n",
            "loss: 122.78482818603516\n",
            "step: 1220\n",
            "loss: 66.63776397705078\n",
            "step: 1221\n",
            "loss: 83.29969024658203\n",
            "step: 1222\n",
            "loss: 119.41276550292969\n",
            "step: 1223\n",
            "loss: 84.30050659179688\n",
            "step: 1224\n",
            "loss: 89.52337646484375\n",
            "step: 1225\n",
            "loss: 76.60833740234375\n",
            "step: 1226\n",
            "loss: 79.05776977539062\n",
            "step: 1227\n",
            "loss: 86.34210205078125\n",
            "step: 1228\n",
            "loss: 96.01318359375\n",
            "step: 1229\n",
            "loss: 74.87948608398438\n",
            "step: 1230\n",
            "loss: 88.43913269042969\n",
            "step: 1231\n",
            "loss: 66.86566162109375\n",
            "step: 1232\n",
            "loss: 125.37203979492188\n",
            "step: 1233\n",
            "loss: 88.05665588378906\n",
            "step: 1234\n",
            "loss: 105.64910125732422\n",
            "step: 1235\n",
            "loss: 104.25321960449219\n",
            "step: 1236\n",
            "loss: 114.05345153808594\n",
            "step: 1237\n",
            "loss: 84.88021087646484\n",
            "step: 1238\n",
            "loss: 98.94833374023438\n",
            "step: 1239\n",
            "loss: 67.30630493164062\n",
            "step: 1240\n",
            "loss: 108.8585205078125\n",
            "step: 1241\n",
            "loss: 59.647708892822266\n",
            "step: 1242\n",
            "loss: 126.45093536376953\n",
            "step: 1243\n",
            "loss: 98.11068725585938\n",
            "step: 1244\n",
            "loss: 75.23185729980469\n",
            "step: 1245\n",
            "loss: 86.99592590332031\n",
            "step: 1246\n",
            "loss: 86.5702133178711\n",
            "step: 1247\n",
            "loss: 86.44586181640625\n",
            "step: 1248\n",
            "loss: 96.33617401123047\n",
            "step: 1249\n",
            "loss: 92.06292724609375\n",
            "step: 1250\n",
            "loss: 92.72023010253906\n",
            "step: 1251\n",
            "loss: 97.78363037109375\n",
            "step: 1252\n",
            "loss: 86.20584106445312\n",
            "step: 1253\n",
            "loss: 82.26172637939453\n",
            "step: 1254\n",
            "loss: 87.77498626708984\n",
            "step: 1255\n",
            "loss: 77.91572570800781\n",
            "step: 1256\n",
            "loss: 116.26802062988281\n",
            "step: 1257\n",
            "loss: 87.3506088256836\n",
            "step: 1258\n",
            "loss: 90.19676208496094\n",
            "step: 1259\n",
            "loss: 89.85757446289062\n",
            "step: 1260\n",
            "loss: 70.20130920410156\n",
            "step: 1261\n",
            "loss: 117.27731323242188\n",
            "step: 1262\n",
            "loss: 108.809814453125\n",
            "step: 1263\n",
            "loss: 110.79410552978516\n",
            "step: 1264\n",
            "loss: 125.54898071289062\n",
            "step: 1265\n",
            "loss: 79.95478057861328\n",
            "step: 1266\n",
            "loss: 82.23500061035156\n",
            "step: 1267\n",
            "loss: 93.24856567382812\n",
            "step: 1268\n",
            "loss: 94.942626953125\n",
            "step: 1269\n",
            "loss: 69.66120147705078\n",
            "step: 1270\n",
            "loss: 89.69587707519531\n",
            "step: 1271\n",
            "loss: 96.73045349121094\n",
            "step: 1272\n",
            "loss: 111.11073303222656\n",
            "step: 1273\n",
            "loss: 111.36107635498047\n",
            "step: 1274\n",
            "loss: 78.2896499633789\n",
            "step: 1275\n",
            "loss: 90.25968170166016\n",
            "step: 1276\n",
            "loss: 112.992919921875\n",
            "step: 1277\n",
            "loss: 102.46166229248047\n",
            "step: 1278\n",
            "loss: 95.1126708984375\n",
            "step: 1279\n",
            "loss: 94.06088256835938\n",
            "step: 1280\n",
            "loss: 131.67808532714844\n",
            "step: 1281\n",
            "loss: 74.57888793945312\n",
            "step: 1282\n",
            "loss: 89.8255615234375\n",
            "step: 1283\n",
            "loss: 107.93753814697266\n",
            "step: 1284\n",
            "loss: 100.25575256347656\n",
            "step: 1285\n",
            "loss: 86.44833374023438\n",
            "step: 1286\n",
            "loss: 116.47627258300781\n",
            "step: 1287\n",
            "loss: 83.37200927734375\n",
            "step: 1288\n",
            "loss: 121.3739013671875\n",
            "step: 1289\n",
            "loss: 77.71157836914062\n",
            "step: 1290\n",
            "loss: 60.70263671875\n",
            "step: 1291\n",
            "loss: 127.94824981689453\n",
            "step: 1292\n",
            "loss: 88.49334716796875\n",
            "step: 1293\n",
            "loss: 110.08761596679688\n",
            "step: 1294\n",
            "loss: 95.86300659179688\n",
            "step: 1295\n",
            "loss: 92.54971313476562\n",
            "step: 1296\n",
            "loss: 103.65428161621094\n",
            "step: 1297\n",
            "loss: 82.44242858886719\n",
            "step: 1298\n",
            "loss: 96.74322509765625\n",
            "step: 1299\n",
            "loss: 70.99432373046875\n",
            "step: 1300\n",
            "loss: 101.2361068725586\n",
            "step: 1301\n",
            "loss: 113.21477508544922\n",
            "step: 1302\n",
            "loss: 61.745933532714844\n",
            "step: 1303\n",
            "loss: 108.63482666015625\n",
            "step: 1304\n",
            "loss: 100.98080444335938\n",
            "step: 1305\n",
            "loss: 115.4177474975586\n",
            "step: 1306\n",
            "loss: 83.72073364257812\n",
            "step: 1307\n",
            "loss: 91.88816833496094\n",
            "step: 1308\n",
            "loss: 68.26146697998047\n",
            "step: 1309\n",
            "loss: 111.95792388916016\n",
            "step: 1310\n",
            "loss: 112.9100341796875\n",
            "step: 1311\n",
            "loss: 82.54737854003906\n",
            "step: 1312\n",
            "loss: 87.38810729980469\n",
            "step: 1313\n",
            "loss: 99.1324234008789\n",
            "step: 1314\n",
            "loss: 103.94729614257812\n",
            "step: 1315\n",
            "loss: 104.480712890625\n",
            "step: 1316\n",
            "loss: 99.07527160644531\n",
            "step: 1317\n",
            "loss: 97.65685272216797\n",
            "step: 1318\n",
            "loss: 85.36668395996094\n",
            "step: 1319\n",
            "loss: 74.71942138671875\n",
            "step: 1320\n",
            "loss: 81.04485321044922\n",
            "step: 1321\n",
            "loss: 81.81332397460938\n",
            "step: 1322\n",
            "loss: 92.73411560058594\n",
            "step: 1323\n",
            "loss: 99.387939453125\n",
            "step: 1324\n",
            "loss: 109.72799682617188\n",
            "step: 1325\n",
            "loss: 127.87063598632812\n",
            "step: 1326\n",
            "loss: 116.88253784179688\n",
            "step: 1327\n",
            "loss: 102.53263854980469\n",
            "step: 1328\n",
            "loss: 96.70361328125\n",
            "step: 1329\n",
            "loss: 87.68951416015625\n",
            "step: 1330\n",
            "loss: 107.8150634765625\n",
            "step: 1331\n",
            "loss: 89.67218017578125\n",
            "step: 1332\n",
            "loss: 101.12643432617188\n",
            "step: 1333\n",
            "loss: 85.47391510009766\n",
            "step: 1334\n",
            "loss: 109.24363708496094\n",
            "step: 1335\n",
            "loss: 125.12124633789062\n",
            "step: 1336\n",
            "loss: 68.43626403808594\n",
            "step: 1337\n",
            "loss: 96.41169738769531\n",
            "step: 1338\n",
            "loss: 98.1256103515625\n",
            "step: 1339\n",
            "loss: 98.90313720703125\n",
            "step: 1340\n",
            "loss: 87.88865661621094\n",
            "step: 1341\n",
            "loss: 92.80023193359375\n",
            "step: 1342\n",
            "loss: 81.22419738769531\n",
            "step: 1343\n",
            "loss: 100.0439453125\n",
            "step: 1344\n",
            "loss: 75.60621643066406\n",
            "step: 1345\n",
            "loss: 117.20805358886719\n",
            "step: 1346\n",
            "loss: 91.85749053955078\n",
            "step: 1347\n",
            "loss: 109.3132095336914\n",
            "step: 1348\n",
            "loss: 86.6494140625\n",
            "step: 1349\n",
            "loss: 92.54212951660156\n",
            "step: 1350\n",
            "loss: 76.34861755371094\n",
            "step: 1351\n",
            "loss: 79.10176086425781\n",
            "step: 1352\n",
            "loss: 111.69967651367188\n",
            "step: 1353\n",
            "loss: 101.05790710449219\n",
            "step: 1354\n",
            "loss: 117.33537292480469\n",
            "step: 1355\n",
            "loss: 111.24459838867188\n",
            "step: 1356\n",
            "loss: 112.71306610107422\n",
            "step: 1357\n",
            "loss: 105.6242446899414\n",
            "step: 1358\n",
            "loss: 85.05577850341797\n",
            "step: 1359\n",
            "loss: 116.58126831054688\n",
            "step: 1360\n",
            "loss: 64.71525573730469\n",
            "step: 1361\n",
            "loss: 94.79267883300781\n",
            "step: 1362\n",
            "loss: 102.56643676757812\n",
            "step: 1363\n",
            "loss: 81.49168395996094\n",
            "step: 1364\n",
            "loss: 82.52143859863281\n",
            "step: 1365\n",
            "loss: 95.0715560913086\n",
            "step: 1366\n",
            "loss: 93.39352416992188\n",
            "step: 1367\n",
            "loss: 88.85826873779297\n",
            "step: 1368\n",
            "loss: 82.31661987304688\n",
            "step: 1369\n",
            "loss: 84.18614196777344\n",
            "step: 1370\n",
            "loss: 86.96414184570312\n",
            "step: 1371\n",
            "loss: 89.63330078125\n",
            "step: 1372\n",
            "loss: 73.83203125\n",
            "step: 1373\n",
            "loss: 103.60154724121094\n",
            "step: 1374\n",
            "loss: 106.85662841796875\n",
            "step: 1375\n",
            "loss: 88.47750854492188\n",
            "step: 1376\n",
            "loss: 83.93742370605469\n",
            "step: 1377\n",
            "loss: 88.74057006835938\n",
            "step: 1378\n",
            "loss: 75.56856536865234\n",
            "step: 1379\n",
            "loss: 92.54168701171875\n",
            "step: 1380\n",
            "loss: 69.77080535888672\n",
            "step: 1381\n",
            "loss: 79.96285247802734\n",
            "step: 1382\n",
            "loss: 105.05162811279297\n",
            "step: 1383\n",
            "loss: 77.6309585571289\n",
            "step: 1384\n",
            "loss: 64.17132568359375\n",
            "step: 1385\n",
            "loss: 62.48657989501953\n",
            "step: 1386\n",
            "loss: 68.055419921875\n",
            "step: 1387\n",
            "loss: 72.65872955322266\n",
            "step: 1388\n",
            "loss: 80.5382080078125\n",
            "step: 1389\n",
            "loss: 95.30341339111328\n",
            "step: 1390\n",
            "loss: 89.81375885009766\n",
            "step: 1391\n",
            "loss: 83.65636444091797\n",
            "step: 1392\n",
            "loss: 53.479618072509766\n",
            "step: 1393\n",
            "loss: 85.71122741699219\n",
            "step: 1394\n",
            "loss: 43.14774703979492\n",
            "step: 1395\n",
            "loss: 87.20148468017578\n",
            "step: 1396\n",
            "loss: 86.1008071899414\n",
            "step: 1397\n",
            "loss: 69.27852630615234\n",
            "step: 1398\n",
            "loss: 52.9212646484375\n",
            "step: 1399\n",
            "loss: 79.9492416381836\n",
            "step: 1400\n",
            "loss: 96.75285339355469\n",
            "step: 1401\n",
            "loss: 97.33909606933594\n",
            "step: 1402\n",
            "loss: 55.504730224609375\n",
            "step: 1403\n",
            "loss: 54.224090576171875\n",
            "step: 1404\n",
            "loss: 110.22344970703125\n",
            "step: 1405\n",
            "loss: 84.45343017578125\n",
            "step: 1406\n",
            "loss: 87.30908966064453\n",
            "step: 1407\n",
            "loss: 129.5501251220703\n",
            "step: 1408\n",
            "loss: 79.31001281738281\n",
            "step: 1409\n",
            "loss: 72.98126220703125\n",
            "step: 1410\n",
            "loss: 80.35060119628906\n",
            "step: 1411\n",
            "loss: 92.744873046875\n",
            "step: 1412\n",
            "loss: 54.96251678466797\n",
            "step: 1413\n",
            "loss: 39.05127716064453\n",
            "step: 1414\n",
            "loss: 81.31243133544922\n",
            "step: 1415\n",
            "loss: 78.72635650634766\n",
            "step: 1416\n",
            "loss: 63.70795440673828\n",
            "step: 1417\n",
            "loss: 86.15687561035156\n",
            "step: 1418\n",
            "loss: 103.8856201171875\n",
            "step: 1419\n",
            "loss: 96.27555847167969\n",
            "step: 1420\n",
            "loss: 70.27374267578125\n",
            "step: 1421\n",
            "loss: 60.941551208496094\n",
            "step: 1422\n",
            "loss: 73.71025085449219\n",
            "step: 1423\n",
            "loss: 90.81205749511719\n",
            "step: 1424\n",
            "loss: 66.54187774658203\n",
            "step: 1425\n",
            "loss: 71.56494903564453\n",
            "step: 1426\n",
            "loss: 69.55561828613281\n",
            "step: 1427\n",
            "loss: 80.3619613647461\n",
            "step: 1428\n",
            "loss: 70.89635467529297\n",
            "step: 1429\n",
            "loss: 73.7625732421875\n",
            "step: 1430\n",
            "loss: 75.56836700439453\n",
            "step: 1431\n",
            "loss: 88.6454086303711\n",
            "step: 1432\n",
            "loss: 80.23981475830078\n",
            "step: 1433\n",
            "loss: 84.7923355102539\n",
            "step: 1434\n",
            "loss: 81.7156753540039\n",
            "step: 1435\n",
            "loss: 89.89653015136719\n",
            "step: 1436\n",
            "loss: 74.82162475585938\n",
            "step: 1437\n",
            "loss: 85.06986999511719\n",
            "step: 1438\n",
            "loss: 116.433837890625\n",
            "step: 1439\n",
            "loss: 95.23885345458984\n",
            "step: 1440\n",
            "loss: 97.26182556152344\n",
            "step: 1441\n",
            "loss: 71.39134216308594\n",
            "step: 1442\n",
            "loss: 55.47788619995117\n",
            "step: 1443\n",
            "loss: 101.01427459716797\n",
            "step: 1444\n",
            "loss: 87.24388122558594\n",
            "step: 1445\n",
            "loss: 79.84444427490234\n",
            "step: 1446\n",
            "loss: 92.92059326171875\n",
            "step: 1447\n",
            "loss: 87.51265716552734\n",
            "step: 1448\n",
            "loss: 110.49339294433594\n",
            "step: 1449\n",
            "loss: 82.29553985595703\n",
            "step: 1450\n",
            "loss: 121.24737548828125\n",
            "step: 1451\n",
            "loss: 80.20761108398438\n",
            "step: 1452\n",
            "loss: 96.20028686523438\n",
            "step: 1453\n",
            "loss: 66.99955749511719\n",
            "step: 1454\n",
            "loss: 82.78533935546875\n",
            "step: 1455\n",
            "loss: 116.34088134765625\n",
            "step: 1456\n",
            "loss: 118.2829360961914\n",
            "step: 1457\n",
            "loss: 88.31266021728516\n",
            "step: 1458\n",
            "loss: 115.79521942138672\n",
            "step: 1459\n",
            "loss: 83.5726547241211\n",
            "step: 1460\n",
            "loss: 89.6061019897461\n",
            "step: 1461\n",
            "loss: 115.9389877319336\n",
            "step: 1462\n",
            "loss: 83.29576110839844\n",
            "step: 1463\n",
            "loss: 73.58273315429688\n",
            "step: 1464\n",
            "loss: 107.30024719238281\n",
            "step: 1465\n",
            "loss: 76.86937713623047\n",
            "step: 1466\n",
            "loss: 98.58943176269531\n",
            "step: 1467\n",
            "loss: 82.50293731689453\n",
            "step: 1468\n",
            "loss: 72.36845397949219\n",
            "step: 1469\n",
            "loss: 90.19973754882812\n",
            "step: 1470\n",
            "loss: 82.46957397460938\n",
            "step: 1471\n",
            "loss: 74.93716430664062\n",
            "step: 1472\n",
            "loss: 75.59556579589844\n",
            "step: 1473\n",
            "loss: 66.74137878417969\n",
            "step: 1474\n",
            "loss: 83.37166595458984\n",
            "step: 1475\n",
            "loss: 104.35636138916016\n",
            "step: 1476\n",
            "loss: 74.77628326416016\n",
            "step: 1477\n",
            "loss: 70.8801040649414\n",
            "step: 1478\n",
            "loss: 73.32075500488281\n",
            "step: 1479\n",
            "loss: 66.89634704589844\n",
            "step: 1480\n",
            "loss: 99.02151489257812\n",
            "step: 1481\n",
            "loss: 107.01817321777344\n",
            "step: 1482\n",
            "loss: 82.13685607910156\n",
            "step: 1483\n",
            "loss: 67.98065185546875\n",
            "step: 1484\n",
            "loss: 103.43051147460938\n",
            "step: 1485\n",
            "loss: 91.05070495605469\n",
            "step: 1486\n",
            "loss: 71.49201965332031\n",
            "step: 1487\n",
            "loss: 116.15751647949219\n",
            "step: 1488\n",
            "loss: 49.398948669433594\n",
            "step: 1489\n",
            "loss: 77.13777923583984\n",
            "step: 1490\n",
            "loss: 99.44869995117188\n",
            "step: 1491\n",
            "loss: 60.42140197753906\n",
            "step: 1492\n",
            "loss: 53.832481384277344\n",
            "step: 1493\n",
            "loss: 128.41387939453125\n",
            "step: 1494\n",
            "loss: 62.66484451293945\n",
            "step: 1495\n",
            "loss: 92.30747985839844\n",
            "step: 1496\n",
            "loss: 99.03167724609375\n",
            "step: 1497\n",
            "loss: 85.99049377441406\n",
            "step: 1498\n",
            "loss: 74.23060607910156\n",
            "step: 1499\n",
            "loss: 56.84202575683594\n",
            "step: 1500\n",
            "loss: 72.02018737792969\n",
            "step: 1501\n",
            "loss: 89.12112426757812\n",
            "step: 1502\n",
            "loss: 92.82389068603516\n",
            "step: 1503\n",
            "loss: 80.21330261230469\n",
            "step: 1504\n",
            "loss: 67.41429138183594\n",
            "step: 1505\n",
            "loss: 93.55113220214844\n",
            "step: 1506\n",
            "loss: 92.33116149902344\n",
            "step: 1507\n",
            "loss: 92.314697265625\n",
            "step: 1508\n",
            "loss: 115.09617614746094\n",
            "step: 1509\n",
            "loss: 88.11050415039062\n",
            "step: 1510\n",
            "loss: 75.28941345214844\n",
            "step: 1511\n",
            "loss: 97.36568450927734\n",
            "step: 1512\n",
            "loss: 114.03608703613281\n",
            "step: 1513\n",
            "loss: 96.62984466552734\n",
            "step: 1514\n",
            "loss: 87.33833312988281\n",
            "step: 1515\n",
            "loss: 132.38967895507812\n",
            "step: 1516\n",
            "loss: 107.99531555175781\n",
            "step: 1517\n",
            "loss: 104.42256164550781\n",
            "step: 1518\n",
            "loss: 87.0987548828125\n",
            "step: 1519\n",
            "loss: 95.52043151855469\n",
            "step: 1520\n",
            "loss: 90.40152740478516\n",
            "step: 1521\n",
            "loss: 63.243186950683594\n",
            "step: 1522\n",
            "loss: 92.20160675048828\n",
            "step: 1523\n",
            "loss: 91.52344512939453\n",
            "step: 1524\n",
            "loss: 86.77932739257812\n",
            "step: 1525\n",
            "loss: 94.8221435546875\n",
            "step: 1526\n",
            "loss: 56.52864074707031\n",
            "step: 1527\n",
            "loss: 125.99665069580078\n",
            "step: 1528\n",
            "loss: 66.22640991210938\n",
            "step: 1529\n",
            "loss: 53.96702575683594\n",
            "step: 1530\n",
            "loss: 87.43310546875\n",
            "step: 1531\n",
            "loss: 93.37537384033203\n",
            "step: 1532\n",
            "loss: 123.05850219726562\n",
            "step: 1533\n",
            "loss: 81.5915298461914\n",
            "step: 1534\n",
            "loss: 99.10748291015625\n",
            "step: 1535\n",
            "loss: 108.34169006347656\n",
            "step: 1536\n",
            "loss: 80.49451446533203\n",
            "step: 1537\n",
            "loss: 99.66395568847656\n",
            "step: 1538\n",
            "loss: 92.31390380859375\n",
            "step: 1539\n",
            "loss: 82.94915771484375\n",
            "step: 1540\n",
            "loss: 76.0020751953125\n",
            "step: 1541\n",
            "loss: 114.12760162353516\n",
            "step: 1542\n",
            "loss: 95.96595001220703\n",
            "step: 1543\n",
            "loss: 85.39328002929688\n",
            "step: 1544\n",
            "loss: 90.7542724609375\n",
            "step: 1545\n",
            "loss: 78.67965698242188\n",
            "step: 1546\n",
            "loss: 95.78981018066406\n",
            "step: 1547\n",
            "loss: 86.58158874511719\n",
            "step: 1548\n",
            "loss: 102.96056365966797\n",
            "step: 1549\n",
            "loss: 103.97674560546875\n",
            "step: 1550\n",
            "loss: 93.03961181640625\n",
            "step: 1551\n",
            "loss: 74.51290893554688\n",
            "step: 1552\n",
            "loss: 98.86735534667969\n",
            "step: 1553\n",
            "loss: 110.25662994384766\n",
            "step: 1554\n",
            "loss: 75.05773162841797\n",
            "step: 1555\n",
            "loss: 103.53189849853516\n",
            "step: 1556\n",
            "loss: 70.69918823242188\n",
            "step: 1557\n",
            "loss: 82.24913024902344\n",
            "step: 1558\n",
            "loss: 57.42900085449219\n",
            "step: 1559\n",
            "loss: 78.73673248291016\n",
            "step: 1560\n",
            "loss: 116.72286224365234\n",
            "step: 1561\n",
            "loss: 67.15574645996094\n",
            "step: 1562\n",
            "loss: 68.45892333984375\n",
            "step: 1563\n",
            "loss: 73.39515686035156\n",
            "step: 1564\n",
            "loss: 79.9886245727539\n",
            "step: 1565\n",
            "loss: 69.13196563720703\n",
            "step: 1566\n",
            "loss: 86.85099792480469\n",
            "step: 1567\n",
            "loss: 92.32225799560547\n",
            "step: 1568\n",
            "loss: 77.38095092773438\n",
            "step: 1569\n",
            "loss: 100.8887939453125\n",
            "step: 1570\n",
            "loss: 95.32473754882812\n",
            "step: 1571\n",
            "loss: 58.97954559326172\n",
            "step: 1572\n",
            "loss: 130.02728271484375\n",
            "step: 1573\n",
            "loss: 118.23938751220703\n",
            "step: 1574\n",
            "loss: 80.49380493164062\n",
            "step: 1575\n",
            "loss: 93.26949310302734\n",
            "step: 1576\n",
            "loss: 80.04473114013672\n",
            "step: 1577\n",
            "loss: 86.23023986816406\n",
            "step: 1578\n",
            "loss: 82.80152893066406\n",
            "step: 1579\n",
            "loss: 115.33377075195312\n",
            "step: 1580\n",
            "loss: 107.68214416503906\n",
            "step: 1581\n",
            "loss: 62.82025909423828\n",
            "step: 1582\n",
            "loss: 98.09591674804688\n",
            "step: 1583\n",
            "loss: 97.91535949707031\n",
            "step: 1584\n",
            "loss: 91.59873962402344\n",
            "step: 1585\n",
            "loss: 75.88912200927734\n",
            "step: 1586\n",
            "loss: 70.07677459716797\n",
            "step: 1587\n",
            "loss: 110.37451171875\n",
            "step: 1588\n",
            "loss: 76.82313537597656\n",
            "step: 1589\n",
            "loss: 57.51594543457031\n",
            "step: 1590\n",
            "loss: 84.6761703491211\n",
            "step: 1591\n",
            "loss: 115.7694320678711\n",
            "step: 1592\n",
            "loss: 73.68205261230469\n",
            "step: 1593\n",
            "loss: 121.49261474609375\n",
            "step: 1594\n",
            "loss: 84.4128646850586\n",
            "step: 1595\n",
            "loss: 61.237998962402344\n",
            "step: 1596\n",
            "loss: 77.96298217773438\n",
            "step: 1597\n",
            "loss: 94.20245361328125\n",
            "step: 1598\n",
            "loss: 71.75780487060547\n",
            "step: 1599\n",
            "loss: 93.99945068359375\n",
            "step: 1600\n",
            "loss: 113.73194885253906\n",
            "step: 1601\n",
            "loss: 85.34294128417969\n",
            "step: 1602\n",
            "loss: 84.47017669677734\n",
            "step: 1603\n",
            "loss: 84.33708190917969\n",
            "step: 1604\n",
            "loss: 115.7318115234375\n",
            "step: 1605\n",
            "loss: 106.47117614746094\n",
            "step: 1606\n",
            "loss: 74.35708618164062\n",
            "step: 1607\n",
            "loss: 66.79534912109375\n",
            "step: 1608\n",
            "loss: 68.92301940917969\n",
            "step: 1609\n",
            "loss: 72.84022521972656\n",
            "step: 1610\n",
            "loss: 71.495849609375\n",
            "step: 1611\n",
            "loss: 94.50605773925781\n",
            "step: 1612\n",
            "loss: 78.3304443359375\n",
            "step: 1613\n",
            "loss: 40.73836898803711\n",
            "step: 1614\n",
            "loss: 67.60102081298828\n",
            "step: 1615\n",
            "loss: 87.21511840820312\n",
            "step: 1616\n",
            "loss: 100.12911987304688\n",
            "step: 1617\n",
            "loss: 67.6801986694336\n",
            "step: 1618\n",
            "loss: 88.79114532470703\n",
            "step: 1619\n",
            "loss: 58.834754943847656\n",
            "step: 1620\n",
            "loss: 72.90919494628906\n",
            "step: 1621\n",
            "loss: 61.10341262817383\n",
            "step: 1622\n",
            "loss: 82.3349609375\n",
            "step: 1623\n",
            "loss: 53.81792068481445\n",
            "step: 1624\n",
            "loss: 58.151241302490234\n",
            "step: 1625\n",
            "loss: 104.83287048339844\n",
            "step: 1626\n",
            "loss: 121.11900329589844\n",
            "step: 1627\n",
            "loss: 69.362060546875\n",
            "step: 1628\n",
            "loss: 75.79684448242188\n",
            "step: 1629\n",
            "loss: 90.5613021850586\n",
            "step: 1630\n",
            "loss: 80.09117126464844\n",
            "step: 1631\n",
            "loss: 77.61036682128906\n",
            "step: 1632\n",
            "loss: 82.5488510131836\n",
            "step: 1633\n",
            "loss: 71.0561752319336\n",
            "step: 1634\n",
            "loss: 69.53425598144531\n",
            "step: 1635\n",
            "loss: 95.87904357910156\n",
            "step: 1636\n",
            "loss: 49.214576721191406\n",
            "step: 1637\n",
            "loss: 67.49211120605469\n",
            "step: 1638\n",
            "loss: 49.89051818847656\n",
            "step: 1639\n",
            "loss: 57.964111328125\n",
            "step: 1640\n",
            "loss: 69.69451904296875\n",
            "step: 1641\n",
            "loss: 74.14273071289062\n",
            "step: 1642\n",
            "loss: 90.08404541015625\n",
            "step: 1643\n",
            "loss: 87.97332763671875\n",
            "step: 1644\n",
            "loss: 73.08282470703125\n",
            "step: 1645\n",
            "loss: 90.04978942871094\n",
            "step: 1646\n",
            "loss: 41.136600494384766\n",
            "step: 1647\n",
            "loss: 108.280029296875\n",
            "step: 1648\n",
            "loss: 58.711280822753906\n",
            "step: 1649\n",
            "loss: 74.41500854492188\n",
            "step: 1650\n",
            "loss: 71.94925689697266\n",
            "step: 1651\n",
            "loss: 53.76637268066406\n",
            "step: 1652\n",
            "loss: 84.90821838378906\n",
            "step: 1653\n",
            "loss: 48.87029266357422\n",
            "step: 1654\n",
            "loss: 90.08110809326172\n",
            "step: 1655\n",
            "loss: 81.22274780273438\n",
            "step: 1656\n",
            "loss: 75.76216125488281\n",
            "step: 1657\n",
            "loss: 86.90982818603516\n",
            "step: 1658\n",
            "loss: 56.08190155029297\n",
            "step: 1659\n",
            "loss: 85.62226867675781\n",
            "step: 1660\n",
            "loss: 64.0443115234375\n",
            "step: 1661\n",
            "loss: 75.36791229248047\n",
            "step: 1662\n",
            "loss: 85.63642883300781\n",
            "step: 1663\n",
            "loss: 58.23295593261719\n",
            "step: 1664\n",
            "loss: 64.60043334960938\n",
            "step: 1665\n",
            "loss: 79.77627563476562\n",
            "step: 1666\n",
            "loss: 52.42091751098633\n",
            "step: 1667\n",
            "loss: 77.73068237304688\n",
            "step: 1668\n",
            "loss: 50.72222900390625\n",
            "step: 1669\n",
            "loss: 66.5398941040039\n",
            "step: 1670\n",
            "loss: 78.14176940917969\n",
            "step: 1671\n",
            "loss: 64.9156494140625\n",
            "step: 1672\n",
            "loss: 72.62626647949219\n",
            "step: 1673\n",
            "loss: 71.98544311523438\n",
            "step: 1674\n",
            "loss: 90.3115005493164\n",
            "step: 1675\n",
            "loss: 90.45950317382812\n",
            "step: 1676\n",
            "loss: 87.37604522705078\n",
            "step: 1677\n",
            "loss: 84.13575744628906\n",
            "step: 1678\n",
            "loss: 94.79150390625\n",
            "step: 1679\n",
            "loss: 65.908447265625\n",
            "step: 1680\n",
            "loss: 100.90228271484375\n",
            "step: 1681\n",
            "loss: 107.8519515991211\n",
            "step: 1682\n",
            "loss: 76.09671783447266\n",
            "step: 1683\n",
            "loss: 89.20443725585938\n",
            "step: 1684\n",
            "loss: 80.75743103027344\n",
            "step: 1685\n",
            "loss: 83.00254821777344\n",
            "step: 1686\n",
            "loss: 82.69999694824219\n",
            "step: 1687\n",
            "loss: 116.53229522705078\n",
            "step: 1688\n",
            "loss: 65.30891418457031\n",
            "step: 1689\n",
            "loss: 87.42263793945312\n",
            "step: 1690\n",
            "loss: 80.96809387207031\n",
            "step: 1691\n",
            "loss: 102.94264221191406\n",
            "step: 1692\n",
            "loss: 52.19424057006836\n",
            "step: 1693\n",
            "loss: 100.38070678710938\n",
            "step: 1694\n",
            "loss: 63.590946197509766\n",
            "step: 1695\n",
            "loss: 45.518699645996094\n",
            "step: 1696\n",
            "loss: 72.13140869140625\n",
            "step: 1697\n",
            "loss: 50.64287567138672\n",
            "step: 1698\n",
            "loss: 94.1247787475586\n",
            "step: 1699\n",
            "loss: 83.84198760986328\n",
            "step: 1700\n",
            "loss: 75.42140197753906\n",
            "step: 1701\n",
            "loss: 92.9207763671875\n",
            "step: 1702\n",
            "loss: 71.6554183959961\n",
            "step: 1703\n",
            "loss: 104.06028747558594\n",
            "step: 1704\n",
            "loss: 88.93792724609375\n",
            "step: 1705\n",
            "loss: 51.13751220703125\n",
            "step: 1706\n",
            "loss: 83.26701354980469\n",
            "step: 1707\n",
            "loss: 72.14019775390625\n",
            "step: 1708\n",
            "loss: 81.05574798583984\n",
            "step: 1709\n",
            "loss: 78.25904083251953\n",
            "step: 1710\n",
            "loss: 79.8653564453125\n",
            "step: 1711\n",
            "loss: 59.019012451171875\n",
            "step: 1712\n",
            "loss: 72.10514831542969\n",
            "step: 1713\n",
            "loss: 89.21583557128906\n",
            "step: 1714\n",
            "loss: 95.43285369873047\n",
            "step: 1715\n",
            "loss: 74.9425277709961\n",
            "step: 1716\n",
            "loss: 85.45053100585938\n",
            "step: 1717\n",
            "loss: 78.60931396484375\n",
            "step: 1718\n",
            "loss: 63.52210235595703\n",
            "step: 1719\n",
            "loss: 84.0894775390625\n",
            "step: 1720\n",
            "loss: 69.42982482910156\n",
            "step: 1721\n",
            "loss: 84.8399887084961\n",
            "step: 1722\n",
            "loss: 76.9840316772461\n",
            "step: 1723\n",
            "loss: 79.90180969238281\n",
            "step: 1724\n",
            "loss: 65.65657043457031\n",
            "step: 1725\n",
            "loss: 100.11474609375\n",
            "step: 1726\n",
            "loss: 77.14964294433594\n",
            "step: 1727\n",
            "loss: 86.4852523803711\n",
            "step: 1728\n",
            "loss: 83.18160247802734\n",
            "step: 1729\n",
            "loss: 87.03239440917969\n",
            "step: 1730\n",
            "loss: 80.748291015625\n",
            "step: 1731\n",
            "loss: 55.28652572631836\n",
            "step: 1732\n",
            "loss: 79.91786193847656\n",
            "step: 1733\n",
            "loss: 69.36468505859375\n",
            "step: 1734\n",
            "loss: 70.67070007324219\n",
            "step: 1735\n",
            "loss: 86.87155151367188\n",
            "step: 1736\n",
            "loss: 81.83724975585938\n",
            "step: 1737\n",
            "loss: 83.90670776367188\n",
            "step: 1738\n",
            "loss: 73.55458068847656\n",
            "step: 1739\n",
            "loss: 85.37964630126953\n",
            "step: 1740\n",
            "loss: 103.48523712158203\n",
            "step: 1741\n",
            "loss: 57.36393737792969\n",
            "step: 1742\n",
            "loss: 94.64065551757812\n",
            "step: 1743\n",
            "loss: 73.29041290283203\n",
            "step: 1744\n",
            "loss: 65.21987915039062\n",
            "step: 1745\n",
            "loss: 93.58065795898438\n",
            "step: 1746\n",
            "loss: 72.46397399902344\n",
            "step: 1747\n",
            "loss: 87.19180297851562\n",
            "step: 1748\n",
            "loss: 95.31932067871094\n",
            "step: 1749\n",
            "loss: 99.41481018066406\n",
            "step: 1750\n",
            "loss: 73.51890563964844\n",
            "step: 1751\n",
            "loss: 93.61762237548828\n",
            "step: 1752\n",
            "loss: 74.5\n",
            "step: 1753\n",
            "loss: 70.53718566894531\n",
            "step: 1754\n",
            "loss: 94.52269744873047\n",
            "step: 1755\n",
            "loss: 77.49755859375\n",
            "step: 1756\n",
            "loss: 70.64341735839844\n",
            "step: 1757\n",
            "loss: 86.33673095703125\n",
            "step: 1758\n",
            "loss: 57.93419647216797\n",
            "step: 1759\n",
            "loss: 92.90780639648438\n",
            "step: 1760\n",
            "loss: 86.70692443847656\n",
            "step: 1761\n",
            "loss: 66.77916717529297\n",
            "step: 1762\n",
            "loss: 95.30387115478516\n",
            "step: 1763\n",
            "loss: 57.67116165161133\n",
            "step: 1764\n",
            "loss: 77.73638916015625\n",
            "step: 1765\n",
            "loss: 84.221923828125\n",
            "step: 1766\n",
            "loss: 82.05011749267578\n",
            "step: 1767\n",
            "loss: 98.80961608886719\n",
            "step: 1768\n",
            "loss: 102.96435546875\n",
            "step: 1769\n",
            "loss: 76.14656066894531\n",
            "step: 1770\n",
            "loss: 69.1515884399414\n",
            "step: 1771\n",
            "loss: 65.47224426269531\n",
            "step: 1772\n",
            "loss: 90.13034057617188\n",
            "step: 1773\n",
            "loss: 62.991615295410156\n",
            "step: 1774\n",
            "loss: 81.04926300048828\n",
            "step: 1775\n",
            "loss: 66.58300018310547\n",
            "step: 1776\n",
            "loss: 108.63632202148438\n",
            "step: 1777\n",
            "loss: 88.87126159667969\n",
            "step: 1778\n",
            "loss: 82.40411376953125\n",
            "step: 1779\n",
            "loss: 84.63531494140625\n",
            "step: 1780\n",
            "loss: 50.31108093261719\n",
            "step: 1781\n",
            "loss: 104.11589050292969\n",
            "step: 1782\n",
            "loss: 68.91851043701172\n",
            "step: 1783\n",
            "loss: 106.06417083740234\n",
            "step: 1784\n",
            "loss: 75.74742126464844\n",
            "step: 1785\n",
            "loss: 74.5445327758789\n",
            "step: 1786\n",
            "loss: 106.50485229492188\n",
            "step: 1787\n",
            "loss: 77.646484375\n",
            "step: 1788\n",
            "loss: 65.19034576416016\n",
            "step: 1789\n",
            "loss: 107.76376342773438\n",
            "step: 1790\n",
            "loss: 80.23377990722656\n",
            "step: 1791\n",
            "loss: 84.74385833740234\n",
            "step: 1792\n",
            "loss: 71.80059051513672\n",
            "step: 1793\n",
            "loss: 79.19827270507812\n",
            "step: 1794\n",
            "loss: 80.8741226196289\n",
            "step: 1795\n",
            "loss: 51.8994140625\n",
            "step: 1796\n",
            "loss: 80.1763916015625\n",
            "step: 1797\n",
            "loss: 99.65168762207031\n",
            "step: 1798\n",
            "loss: 86.13838195800781\n",
            "step: 1799\n",
            "loss: 74.30561828613281\n",
            "step: 1800\n",
            "loss: 91.3160629272461\n",
            "step: 1801\n",
            "loss: 48.578922271728516\n",
            "step: 1802\n",
            "loss: 108.58380126953125\n",
            "step: 1803\n",
            "loss: 87.5128402709961\n",
            "step: 1804\n",
            "loss: 59.00612258911133\n",
            "step: 1805\n",
            "loss: 86.6444091796875\n",
            "step: 1806\n",
            "loss: 83.19438934326172\n",
            "step: 1807\n",
            "loss: 78.98926544189453\n",
            "step: 1808\n",
            "loss: 102.6974868774414\n",
            "step: 1809\n",
            "loss: 68.04092407226562\n",
            "step: 1810\n",
            "loss: 102.01512145996094\n",
            "step: 1811\n",
            "loss: 88.9963150024414\n",
            "step: 1812\n",
            "loss: 89.49303436279297\n",
            "step: 1813\n",
            "loss: 84.34112548828125\n",
            "step: 1814\n",
            "loss: 107.1229476928711\n",
            "step: 1815\n",
            "loss: 71.63963317871094\n",
            "step: 1816\n",
            "loss: 107.36809539794922\n",
            "step: 1817\n",
            "loss: 97.91915893554688\n",
            "step: 1818\n",
            "loss: 102.01750183105469\n",
            "step: 1819\n",
            "loss: 105.23113250732422\n",
            "step: 1820\n",
            "loss: 106.3228988647461\n",
            "step: 1821\n",
            "loss: 71.29106903076172\n",
            "step: 1822\n",
            "loss: 67.35707092285156\n",
            "step: 1823\n",
            "loss: 96.04808807373047\n",
            "step: 1824\n",
            "loss: 67.3713150024414\n",
            "step: 1825\n",
            "loss: 63.70738983154297\n",
            "step: 1826\n",
            "loss: 73.88833618164062\n",
            "step: 1827\n",
            "loss: 98.05848693847656\n",
            "step: 1828\n",
            "loss: 56.31760787963867\n",
            "step: 1829\n",
            "loss: 95.71895599365234\n",
            "step: 1830\n",
            "loss: 68.4521484375\n",
            "step: 1831\n",
            "loss: 56.41566467285156\n",
            "step: 1832\n",
            "loss: 92.34912872314453\n",
            "step: 1833\n",
            "loss: 74.75735473632812\n",
            "step: 1834\n",
            "loss: 94.50154113769531\n",
            "step: 1835\n",
            "loss: 81.19981384277344\n",
            "step: 1836\n",
            "loss: 60.58175277709961\n",
            "step: 1837\n",
            "loss: 105.61046600341797\n",
            "step: 1838\n",
            "loss: 71.7630615234375\n",
            "step: 1839\n",
            "loss: 84.23136901855469\n",
            "step: 1840\n",
            "loss: 61.335777282714844\n",
            "step: 1841\n",
            "loss: 60.655853271484375\n",
            "step: 1842\n",
            "loss: 60.91780090332031\n",
            "step: 1843\n",
            "loss: 93.8615493774414\n",
            "step: 1844\n",
            "loss: 60.494911193847656\n",
            "step: 1845\n",
            "loss: 87.63204956054688\n",
            "step: 1846\n",
            "loss: 58.21515655517578\n",
            "step: 1847\n",
            "loss: 74.8396987915039\n",
            "step: 1848\n",
            "loss: 82.02245330810547\n",
            "step: 1849\n",
            "loss: 90.37277221679688\n",
            "step: 1850\n",
            "loss: 71.97090148925781\n",
            "step: 1851\n",
            "loss: 83.83702850341797\n",
            "step: 1852\n",
            "loss: 51.82524871826172\n",
            "step: 1853\n",
            "loss: 62.079341888427734\n",
            "step: 1854\n",
            "loss: 57.75181579589844\n",
            "step: 1855\n",
            "loss: 84.18402099609375\n",
            "step: 1856\n",
            "loss: 74.1227798461914\n",
            "step: 1857\n",
            "loss: 74.59976959228516\n",
            "step: 1858\n",
            "loss: 83.34426879882812\n",
            "step: 1859\n",
            "loss: 57.19610595703125\n",
            "step: 1860\n",
            "loss: 79.35130310058594\n",
            "step: 1861\n",
            "loss: 61.009498596191406\n",
            "step: 1862\n",
            "loss: 84.00823974609375\n",
            "step: 1863\n",
            "loss: 65.6722412109375\n",
            "step: 1864\n",
            "loss: 72.65531921386719\n",
            "step: 1865\n",
            "loss: 67.33832550048828\n",
            "step: 1866\n",
            "loss: 59.45929718017578\n",
            "step: 1867\n",
            "loss: 72.994384765625\n",
            "step: 1868\n",
            "loss: 110.6612548828125\n",
            "step: 1869\n",
            "loss: 84.12605285644531\n",
            "step: 1870\n",
            "loss: 75.59074401855469\n",
            "step: 1871\n",
            "loss: 65.34152221679688\n",
            "step: 1872\n",
            "loss: 80.09654235839844\n",
            "step: 1873\n",
            "loss: 55.14347839355469\n",
            "step: 1874\n",
            "loss: 61.74089050292969\n",
            "step: 1875\n",
            "loss: 73.9415512084961\n",
            "step: 1876\n",
            "loss: 59.180171966552734\n",
            "step: 1877\n",
            "loss: 69.60861206054688\n",
            "step: 1878\n",
            "loss: 87.98706817626953\n",
            "step: 1879\n",
            "loss: 64.02539825439453\n",
            "step: 1880\n",
            "loss: 56.3841552734375\n",
            "step: 1881\n",
            "loss: 59.8980712890625\n",
            "step: 1882\n",
            "loss: 72.15599060058594\n",
            "step: 1883\n",
            "loss: 80.43224334716797\n",
            "step: 1884\n",
            "loss: 81.24272155761719\n",
            "step: 1885\n",
            "loss: 81.0714111328125\n",
            "step: 1886\n",
            "loss: 60.32958221435547\n",
            "step: 1887\n",
            "loss: 87.19434356689453\n",
            "step: 1888\n",
            "loss: 98.18865966796875\n",
            "step: 1889\n",
            "loss: 69.68743133544922\n",
            "step: 1890\n",
            "loss: 67.49615478515625\n",
            "step: 1891\n",
            "loss: 66.31900024414062\n",
            "step: 1892\n",
            "loss: 57.79082107543945\n",
            "step: 1893\n",
            "loss: 62.94486618041992\n",
            "step: 1894\n",
            "loss: 50.63302993774414\n",
            "step: 1895\n",
            "loss: 81.58154296875\n",
            "step: 1896\n",
            "loss: 93.05223083496094\n",
            "step: 1897\n",
            "loss: 64.19300842285156\n",
            "step: 1898\n",
            "loss: 81.57190704345703\n",
            "step: 1899\n",
            "loss: 46.67743682861328\n",
            "step: 1900\n",
            "loss: 42.11376190185547\n",
            "step: 1901\n",
            "loss: 108.2348861694336\n",
            "step: 1902\n",
            "loss: 68.91854095458984\n",
            "step: 1903\n",
            "loss: 59.35472869873047\n",
            "step: 1904\n",
            "loss: 75.679443359375\n",
            "step: 1905\n",
            "loss: 81.96359252929688\n",
            "step: 1906\n",
            "loss: 65.20872497558594\n",
            "step: 1907\n",
            "loss: 83.53535461425781\n",
            "step: 1908\n",
            "loss: 50.68798828125\n",
            "step: 1909\n",
            "loss: 60.066375732421875\n",
            "step: 1910\n",
            "loss: 70.39285278320312\n",
            "step: 1911\n",
            "loss: 77.7074966430664\n",
            "step: 1912\n",
            "loss: 69.35888671875\n",
            "step: 1913\n",
            "loss: 95.551025390625\n",
            "step: 1914\n",
            "loss: 70.83561706542969\n",
            "step: 1915\n",
            "loss: 48.359535217285156\n",
            "step: 1916\n",
            "loss: 72.7952880859375\n",
            "step: 1917\n",
            "loss: 88.41676330566406\n",
            "step: 1918\n",
            "loss: 83.79727172851562\n",
            "step: 1919\n",
            "loss: 75.03443908691406\n",
            "step: 1920\n",
            "loss: 93.37073516845703\n",
            "step: 1921\n",
            "loss: 94.5633316040039\n",
            "step: 1922\n",
            "loss: 79.09394836425781\n",
            "step: 1923\n",
            "loss: 57.373661041259766\n",
            "step: 1924\n",
            "loss: 78.40078735351562\n",
            "step: 1925\n",
            "loss: 78.97511291503906\n",
            "step: 1926\n",
            "loss: 57.93910598754883\n",
            "step: 1927\n",
            "loss: 76.29808807373047\n",
            "step: 1928\n",
            "loss: 80.16969299316406\n",
            "step: 1929\n",
            "loss: 80.35678100585938\n",
            "step: 1930\n",
            "loss: 88.9716567993164\n",
            "step: 1931\n",
            "loss: 81.48452758789062\n",
            "step: 1932\n",
            "loss: 69.57560729980469\n",
            "step: 1933\n",
            "loss: 88.318115234375\n",
            "step: 1934\n",
            "loss: 45.56955337524414\n",
            "step: 1935\n",
            "loss: 86.5279541015625\n",
            "step: 1936\n",
            "loss: 82.34086608886719\n",
            "step: 1937\n",
            "loss: 61.00818634033203\n",
            "step: 1938\n",
            "loss: 79.27826690673828\n",
            "step: 1939\n",
            "loss: 89.96842956542969\n",
            "step: 1940\n",
            "loss: 82.728759765625\n",
            "step: 1941\n",
            "loss: 63.49085998535156\n",
            "step: 1942\n",
            "loss: 94.176513671875\n",
            "step: 1943\n",
            "loss: 66.42520141601562\n",
            "step: 1944\n",
            "loss: 75.18882751464844\n",
            "step: 1945\n",
            "loss: 60.92352294921875\n",
            "step: 1946\n",
            "loss: 86.521484375\n",
            "step: 1947\n",
            "loss: 49.388885498046875\n",
            "step: 1948\n",
            "loss: 74.28594970703125\n",
            "step: 1949\n",
            "loss: 69.47125244140625\n",
            "step: 1950\n",
            "loss: 59.76990509033203\n",
            "step: 1951\n",
            "loss: 69.10014343261719\n",
            "step: 1952\n",
            "loss: 49.88321304321289\n",
            "step: 1953\n",
            "loss: 69.34657287597656\n",
            "step: 1954\n",
            "loss: 66.60400390625\n",
            "step: 1955\n",
            "loss: 88.81684875488281\n",
            "step: 1956\n",
            "loss: 41.733524322509766\n",
            "step: 1957\n",
            "loss: 70.92859649658203\n",
            "step: 1958\n",
            "loss: 56.801544189453125\n",
            "step: 1959\n",
            "loss: 78.64138793945312\n",
            "step: 1960\n",
            "loss: 73.542236328125\n",
            "step: 1961\n",
            "loss: 74.81655883789062\n",
            "step: 1962\n",
            "loss: 95.6401138305664\n",
            "step: 1963\n",
            "loss: 70.92970275878906\n",
            "step: 1964\n",
            "loss: 81.66162109375\n",
            "step: 1965\n",
            "loss: 91.37418365478516\n",
            "step: 1966\n",
            "loss: 60.67072296142578\n",
            "step: 1967\n",
            "loss: 56.033538818359375\n",
            "step: 1968\n",
            "loss: 70.92948913574219\n",
            "step: 1969\n",
            "loss: 75.61514282226562\n",
            "step: 1970\n",
            "loss: 69.37358856201172\n",
            "step: 1971\n",
            "loss: 68.60220336914062\n",
            "step: 1972\n",
            "loss: 93.33470153808594\n",
            "step: 1973\n",
            "loss: 67.53479766845703\n",
            "step: 1974\n",
            "loss: 90.99459075927734\n",
            "step: 1975\n",
            "loss: 132.2641143798828\n",
            "step: 1976\n",
            "loss: 86.63611602783203\n",
            "step: 1977\n",
            "loss: 85.83707427978516\n",
            "step: 1978\n",
            "loss: 103.54766845703125\n",
            "step: 1979\n",
            "loss: 85.55009460449219\n",
            "step: 1980\n",
            "loss: 78.70313262939453\n",
            "step: 1981\n",
            "loss: 85.55455780029297\n",
            "step: 1982\n",
            "loss: 97.34529113769531\n",
            "step: 1983\n",
            "loss: 64.29122924804688\n",
            "step: 1984\n",
            "loss: 81.14505004882812\n",
            "step: 1985\n",
            "loss: 63.76927947998047\n",
            "step: 1986\n",
            "loss: 52.10843276977539\n",
            "step: 1987\n",
            "loss: 79.42750549316406\n",
            "step: 1988\n",
            "loss: 74.9467544555664\n",
            "step: 1989\n",
            "loss: 106.95877075195312\n",
            "step: 1990\n",
            "loss: 67.42910766601562\n",
            "step: 1991\n",
            "loss: 60.618831634521484\n",
            "step: 1992\n",
            "loss: 86.57129669189453\n",
            "step: 1993\n",
            "loss: 68.44778442382812\n",
            "step: 1994\n",
            "loss: 63.699554443359375\n",
            "step: 1995\n",
            "loss: 131.0131072998047\n",
            "step: 1996\n",
            "loss: 55.78662872314453\n",
            "step: 1997\n",
            "loss: 97.89057922363281\n",
            "step: 1998\n",
            "loss: 60.44490051269531\n",
            "step: 1999\n",
            "loss: 79.39370727539062\n",
            "step: 2000\n",
            "loss: 80.00997161865234\n",
            "step: 2001\n",
            "loss: 82.38494873046875\n",
            "step: 2002\n",
            "loss: 65.1429443359375\n",
            "step: 2003\n",
            "loss: 50.25149917602539\n",
            "step: 2004\n",
            "loss: 89.86027526855469\n",
            "step: 2005\n",
            "loss: 78.90838623046875\n",
            "step: 2006\n",
            "loss: 83.03518676757812\n",
            "step: 2007\n",
            "loss: 64.67237854003906\n",
            "step: 2008\n",
            "loss: 104.27729797363281\n",
            "step: 2009\n",
            "loss: 67.6096420288086\n",
            "step: 2010\n",
            "loss: 75.0359115600586\n",
            "step: 2011\n",
            "loss: 65.27890014648438\n",
            "step: 2012\n",
            "loss: 67.12857055664062\n",
            "step: 2013\n",
            "loss: 76.95569610595703\n",
            "step: 2014\n",
            "loss: 83.49594116210938\n",
            "step: 2015\n",
            "loss: 85.57051086425781\n",
            "step: 2016\n",
            "loss: 67.9925537109375\n",
            "step: 2017\n",
            "loss: 73.6683120727539\n",
            "step: 2018\n",
            "loss: 89.64706420898438\n",
            "step: 2019\n",
            "loss: 92.88604736328125\n",
            "step: 2020\n",
            "loss: 71.25215911865234\n",
            "step: 2021\n",
            "loss: 65.99079132080078\n",
            "step: 2022\n",
            "loss: 65.9595718383789\n",
            "step: 2023\n",
            "loss: 83.83638000488281\n",
            "step: 2024\n",
            "loss: 88.05644226074219\n",
            "step: 2025\n",
            "loss: 77.72212982177734\n",
            "step: 2026\n",
            "loss: 78.80250549316406\n",
            "step: 2027\n",
            "loss: 102.47335815429688\n",
            "step: 2028\n",
            "loss: 70.4696044921875\n",
            "step: 2029\n",
            "loss: 107.17074584960938\n",
            "step: 2030\n",
            "loss: 65.81682586669922\n",
            "step: 2031\n",
            "loss: 73.46177673339844\n",
            "step: 2032\n",
            "loss: 66.4909896850586\n",
            "step: 2033\n",
            "loss: 68.79386138916016\n",
            "step: 2034\n",
            "loss: 62.45618438720703\n",
            "step: 2035\n",
            "loss: 91.8810806274414\n",
            "step: 2036\n",
            "loss: 111.01472473144531\n",
            "step: 2037\n",
            "loss: 96.11214447021484\n",
            "step: 2038\n",
            "loss: 107.01670837402344\n",
            "step: 2039\n",
            "loss: 51.612701416015625\n",
            "step: 2040\n",
            "loss: 87.79094696044922\n",
            "step: 2041\n",
            "loss: 89.14214324951172\n",
            "step: 2042\n",
            "loss: 57.677879333496094\n",
            "step: 2043\n",
            "loss: 73.22185516357422\n",
            "step: 2044\n",
            "loss: 74.43585205078125\n",
            "step: 2045\n",
            "loss: 77.64419555664062\n",
            "step: 2046\n",
            "loss: 99.36375427246094\n",
            "step: 2047\n",
            "loss: 85.9930419921875\n",
            "step: 2048\n",
            "loss: 69.84910583496094\n",
            "step: 2049\n",
            "loss: 108.12492370605469\n",
            "step: 2050\n",
            "loss: 56.77840042114258\n",
            "step: 2051\n",
            "loss: 74.91558837890625\n",
            "step: 2052\n",
            "loss: 107.80281066894531\n",
            "step: 2053\n",
            "loss: 62.5328369140625\n",
            "step: 2054\n",
            "loss: 66.4355239868164\n",
            "step: 2055\n",
            "loss: 52.903892517089844\n",
            "step: 2056\n",
            "loss: 102.95053100585938\n",
            "step: 2057\n",
            "loss: 114.46455383300781\n",
            "step: 2058\n",
            "loss: 65.05888366699219\n",
            "step: 2059\n",
            "loss: 70.03004455566406\n",
            "step: 2060\n",
            "loss: 46.616111755371094\n",
            "step: 2061\n",
            "loss: 82.1746597290039\n",
            "step: 2062\n",
            "loss: 40.25591278076172\n",
            "step: 2063\n",
            "loss: 77.83245849609375\n",
            "step: 2064\n",
            "loss: 55.99310302734375\n",
            "step: 2065\n",
            "loss: 69.61868286132812\n",
            "step: 2066\n",
            "loss: 87.85511779785156\n",
            "step: 2067\n",
            "loss: 61.59320831298828\n",
            "step: 2068\n",
            "loss: 78.38160705566406\n",
            "step: 2069\n",
            "loss: 70.96327209472656\n",
            "step: 2070\n",
            "loss: 44.41785430908203\n",
            "step: 2071\n",
            "loss: 52.96596908569336\n",
            "step: 2072\n",
            "loss: 74.03540802001953\n",
            "step: 2073\n",
            "loss: 76.187255859375\n",
            "step: 2074\n",
            "loss: 90.10002899169922\n",
            "step: 2075\n",
            "loss: 77.15615844726562\n",
            "step: 2076\n",
            "loss: 69.35711669921875\n",
            "step: 2077\n",
            "loss: 92.37533569335938\n",
            "step: 2078\n",
            "loss: 85.75324249267578\n",
            "step: 2079\n",
            "loss: 59.663753509521484\n",
            "step: 2080\n",
            "loss: 70.34087371826172\n",
            "step: 2081\n",
            "loss: 73.15354919433594\n",
            "step: 2082\n",
            "loss: 83.16807556152344\n",
            "step: 2083\n",
            "loss: 58.03413391113281\n",
            "step: 2084\n",
            "loss: 62.0543212890625\n",
            "step: 2085\n",
            "loss: 75.45865631103516\n",
            "step: 2086\n",
            "loss: 50.90630340576172\n",
            "step: 2087\n",
            "loss: 56.56486892700195\n",
            "step: 2088\n",
            "loss: 54.51227569580078\n",
            "step: 2089\n",
            "loss: 87.76591491699219\n",
            "step: 2090\n",
            "loss: 62.59046936035156\n",
            "step: 2091\n",
            "loss: 85.76583862304688\n",
            "step: 2092\n",
            "loss: 72.45638275146484\n",
            "step: 2093\n",
            "loss: 77.67884826660156\n",
            "step: 2094\n",
            "loss: 52.2628173828125\n",
            "step: 2095\n",
            "loss: 57.80504608154297\n",
            "step: 2096\n",
            "loss: 71.67718505859375\n",
            "step: 2097\n",
            "loss: 55.92277145385742\n",
            "step: 2098\n",
            "loss: 60.668113708496094\n",
            "step: 2099\n",
            "loss: 95.99331665039062\n",
            "step: 2100\n",
            "loss: 76.02914428710938\n",
            "step: 2101\n",
            "loss: 49.848106384277344\n",
            "step: 2102\n",
            "loss: 70.05863952636719\n",
            "step: 2103\n",
            "loss: 92.72254180908203\n",
            "step: 2104\n",
            "loss: 76.686767578125\n",
            "step: 2105\n",
            "loss: 57.72746276855469\n",
            "step: 2106\n",
            "loss: 35.94873809814453\n",
            "step: 2107\n",
            "loss: 68.23506164550781\n",
            "step: 2108\n",
            "loss: 59.500518798828125\n",
            "step: 2109\n",
            "loss: 54.152374267578125\n",
            "step: 2110\n",
            "loss: 82.11875915527344\n",
            "step: 2111\n",
            "loss: 47.08731460571289\n",
            "step: 2112\n",
            "loss: 100.06892395019531\n",
            "step: 2113\n",
            "loss: 66.23067474365234\n",
            "step: 2114\n",
            "loss: 84.97293090820312\n",
            "step: 2115\n",
            "loss: 79.8083724975586\n",
            "step: 2116\n",
            "loss: 52.254581451416016\n",
            "step: 2117\n",
            "loss: 106.8699722290039\n",
            "step: 2118\n",
            "loss: 45.41270446777344\n",
            "step: 2119\n",
            "loss: 79.15672302246094\n",
            "step: 2120\n",
            "loss: 69.39784240722656\n",
            "step: 2121\n",
            "loss: 29.616182327270508\n",
            "step: 2122\n",
            "loss: 56.84214782714844\n",
            "step: 2123\n",
            "loss: 68.68986511230469\n",
            "step: 2124\n",
            "loss: 66.14118957519531\n",
            "step: 2125\n",
            "loss: 54.12615203857422\n",
            "step: 2126\n",
            "loss: 46.30009841918945\n",
            "step: 2127\n",
            "loss: 75.32373809814453\n",
            "step: 2128\n",
            "loss: 73.9073486328125\n",
            "step: 2129\n",
            "loss: 71.34684753417969\n",
            "step: 2130\n",
            "loss: 77.23878479003906\n",
            "step: 2131\n",
            "loss: 58.321685791015625\n",
            "step: 2132\n",
            "loss: 54.37126159667969\n",
            "step: 2133\n",
            "loss: 65.3172607421875\n",
            "step: 2134\n",
            "loss: 70.11293029785156\n",
            "step: 2135\n",
            "loss: 71.34767150878906\n",
            "step: 2136\n",
            "loss: 66.37234497070312\n",
            "step: 2137\n",
            "loss: 63.11793518066406\n",
            "step: 2138\n",
            "loss: 69.71478271484375\n",
            "step: 2139\n",
            "loss: 61.62620544433594\n",
            "step: 2140\n",
            "loss: 73.39042663574219\n",
            "step: 2141\n",
            "loss: 59.867340087890625\n",
            "step: 2142\n",
            "loss: 94.36304473876953\n",
            "step: 2143\n",
            "loss: 59.694236755371094\n",
            "step: 2144\n",
            "loss: 69.40664672851562\n",
            "step: 2145\n",
            "loss: 62.93811798095703\n",
            "step: 2146\n",
            "loss: 62.60991668701172\n",
            "step: 2147\n",
            "loss: 77.65290832519531\n",
            "step: 2148\n",
            "loss: 56.25645446777344\n",
            "step: 2149\n",
            "loss: 70.09699249267578\n",
            "step: 2150\n",
            "loss: 78.3488540649414\n",
            "step: 2151\n",
            "loss: 79.38390350341797\n",
            "step: 2152\n",
            "loss: 44.915504455566406\n",
            "step: 2153\n",
            "loss: 55.748130798339844\n",
            "step: 2154\n",
            "loss: 58.856849670410156\n",
            "step: 2155\n",
            "loss: 106.94055938720703\n",
            "step: 2156\n",
            "loss: 49.240867614746094\n",
            "step: 2157\n",
            "loss: 71.50035095214844\n",
            "step: 2158\n",
            "loss: 81.07827758789062\n",
            "step: 2159\n",
            "loss: 50.327903747558594\n",
            "step: 2160\n",
            "loss: 82.80196380615234\n",
            "step: 2161\n",
            "loss: 60.293853759765625\n",
            "step: 2162\n",
            "loss: 92.92282104492188\n",
            "step: 2163\n",
            "loss: 64.76017761230469\n",
            "step: 2164\n",
            "loss: 57.16347885131836\n",
            "step: 2165\n",
            "loss: 107.4450912475586\n",
            "step: 2166\n",
            "loss: 71.63182067871094\n",
            "step: 2167\n",
            "loss: 74.85258483886719\n",
            "step: 2168\n",
            "loss: 84.31524658203125\n",
            "step: 2169\n",
            "loss: 71.2960433959961\n",
            "step: 2170\n",
            "loss: 67.96745300292969\n",
            "step: 2171\n",
            "loss: 110.12773895263672\n",
            "step: 2172\n",
            "loss: 79.37578582763672\n",
            "step: 2173\n",
            "loss: 87.68364715576172\n",
            "step: 2174\n",
            "loss: 53.380149841308594\n",
            "step: 2175\n",
            "loss: 80.6465072631836\n",
            "step: 2176\n",
            "loss: 53.08308029174805\n",
            "step: 2177\n",
            "loss: 68.32235717773438\n",
            "step: 2178\n",
            "loss: 60.607994079589844\n",
            "step: 2179\n",
            "loss: 69.98292541503906\n",
            "step: 2180\n",
            "loss: 63.0716552734375\n",
            "step: 2181\n",
            "loss: 54.61720275878906\n",
            "step: 2182\n",
            "loss: 56.54048538208008\n",
            "step: 2183\n",
            "loss: 82.58183288574219\n",
            "step: 2184\n",
            "loss: 56.554534912109375\n",
            "step: 2185\n",
            "loss: 61.11207962036133\n",
            "step: 2186\n",
            "loss: 74.54412841796875\n",
            "step: 2187\n",
            "loss: 67.20963287353516\n",
            "step: 2188\n",
            "loss: 62.08201217651367\n",
            "step: 2189\n",
            "loss: 85.29707336425781\n",
            "step: 2190\n",
            "loss: 85.89171600341797\n",
            "step: 2191\n",
            "loss: 82.04965209960938\n",
            "step: 2192\n",
            "loss: 82.68318176269531\n",
            "step: 2193\n",
            "loss: 41.72290802001953\n",
            "step: 2194\n",
            "loss: 69.08029174804688\n",
            "step: 2195\n",
            "loss: 56.78156661987305\n",
            "step: 2196\n",
            "loss: 68.337158203125\n",
            "step: 2197\n",
            "loss: 80.792724609375\n",
            "step: 2198\n",
            "loss: 30.280059814453125\n",
            "step: 2199\n",
            "loss: 70.63156127929688\n",
            "step: 2200\n",
            "loss: 77.55989074707031\n",
            "step: 2201\n",
            "loss: 47.78080749511719\n",
            "step: 2202\n",
            "loss: 65.840087890625\n",
            "step: 2203\n",
            "loss: 89.29444122314453\n",
            "step: 2204\n",
            "loss: 75.9793701171875\n",
            "step: 2205\n",
            "loss: 111.94496154785156\n",
            "step: 2206\n",
            "loss: 99.39309692382812\n",
            "step: 2207\n",
            "loss: 64.12262725830078\n",
            "step: 2208\n",
            "loss: 71.71369171142578\n",
            "step: 2209\n",
            "loss: 99.96197509765625\n",
            "step: 2210\n",
            "loss: 91.19905090332031\n",
            "step: 2211\n",
            "loss: 86.26141357421875\n",
            "step: 2212\n",
            "loss: 62.76649856567383\n",
            "step: 2213\n",
            "loss: 73.67622375488281\n",
            "step: 2214\n",
            "loss: 63.22480010986328\n",
            "step: 2215\n",
            "loss: 76.59241485595703\n",
            "step: 2216\n",
            "loss: 76.70938110351562\n",
            "step: 2217\n",
            "loss: 102.3626937866211\n",
            "step: 2218\n",
            "loss: 64.90193939208984\n",
            "step: 2219\n",
            "loss: 101.85755920410156\n",
            "step: 2220\n",
            "loss: 73.4791030883789\n",
            "step: 2221\n",
            "loss: 56.21670150756836\n",
            "step: 2222\n",
            "loss: 59.055477142333984\n",
            "step: 2223\n",
            "loss: 89.52159118652344\n",
            "step: 2224\n",
            "loss: 73.59724426269531\n",
            "step: 2225\n",
            "loss: 53.815528869628906\n",
            "step: 2226\n",
            "loss: 71.25660705566406\n",
            "step: 2227\n",
            "loss: 107.51753234863281\n",
            "step: 2228\n",
            "loss: 71.14989471435547\n",
            "step: 2229\n",
            "loss: 66.23707580566406\n",
            "step: 2230\n",
            "loss: 59.61056900024414\n",
            "step: 2231\n",
            "loss: 58.34716033935547\n",
            "step: 2232\n",
            "loss: 60.13560485839844\n",
            "step: 2233\n",
            "loss: 49.445091247558594\n",
            "step: 2234\n",
            "loss: 103.83528137207031\n",
            "step: 2235\n",
            "loss: 75.98776245117188\n",
            "step: 2236\n",
            "loss: 70.83690643310547\n",
            "step: 2237\n",
            "loss: 55.6058235168457\n",
            "step: 2238\n",
            "loss: 66.59807586669922\n",
            "step: 2239\n",
            "loss: 66.59657287597656\n",
            "step: 2240\n",
            "loss: 99.81997680664062\n",
            "step: 2241\n",
            "loss: 69.57501220703125\n",
            "step: 2242\n",
            "loss: 64.04595947265625\n",
            "step: 2243\n",
            "loss: 84.8167953491211\n",
            "step: 2244\n",
            "loss: 61.130714416503906\n",
            "step: 2245\n",
            "loss: 56.356842041015625\n",
            "step: 2246\n",
            "loss: 48.088287353515625\n",
            "step: 2247\n",
            "loss: 67.29483032226562\n",
            "step: 2248\n",
            "loss: 64.9127426147461\n",
            "step: 2249\n",
            "loss: 65.66436767578125\n",
            "step: 2250\n",
            "loss: 69.44572448730469\n",
            "step: 2251\n",
            "loss: 64.21257781982422\n",
            "step: 2252\n",
            "loss: 76.85523986816406\n",
            "step: 2253\n",
            "loss: 83.02046203613281\n",
            "step: 2254\n",
            "loss: 62.085365295410156\n",
            "step: 2255\n",
            "loss: 111.44642639160156\n",
            "step: 2256\n",
            "loss: 87.92851257324219\n",
            "step: 2257\n",
            "loss: 77.13346862792969\n",
            "step: 2258\n",
            "loss: 82.5538558959961\n",
            "step: 2259\n",
            "loss: 78.6224365234375\n",
            "step: 2260\n",
            "loss: 67.78221893310547\n",
            "step: 2261\n",
            "loss: 81.95819091796875\n",
            "step: 2262\n",
            "loss: 66.21073913574219\n",
            "step: 2263\n",
            "loss: 76.49011993408203\n",
            "step: 2264\n",
            "loss: 53.956851959228516\n",
            "step: 2265\n",
            "loss: 80.75721740722656\n",
            "step: 2266\n",
            "loss: 57.99197769165039\n",
            "step: 2267\n",
            "loss: 82.47193145751953\n",
            "step: 2268\n",
            "loss: 65.50828552246094\n",
            "step: 2269\n",
            "loss: 94.82013702392578\n",
            "step: 2270\n",
            "loss: 57.17744445800781\n",
            "step: 2271\n",
            "loss: 91.43053436279297\n",
            "step: 2272\n",
            "loss: 78.02645874023438\n",
            "step: 2273\n",
            "loss: 84.15168762207031\n",
            "step: 2274\n",
            "loss: 75.13970947265625\n",
            "step: 2275\n",
            "loss: 69.54373168945312\n",
            "step: 2276\n",
            "loss: 78.9637222290039\n",
            "step: 2277\n",
            "loss: 76.14859008789062\n",
            "step: 2278\n",
            "loss: 83.64440155029297\n",
            "step: 2279\n",
            "loss: 79.57401275634766\n",
            "step: 2280\n",
            "loss: 105.23900604248047\n",
            "step: 2281\n",
            "loss: 68.11163330078125\n",
            "step: 2282\n",
            "loss: 43.44282913208008\n",
            "step: 2283\n",
            "loss: 62.153968811035156\n",
            "step: 2284\n",
            "loss: 87.49925231933594\n",
            "step: 2285\n",
            "loss: 77.43248748779297\n",
            "step: 2286\n",
            "loss: 60.43097686767578\n",
            "step: 2287\n",
            "loss: 84.80894470214844\n",
            "step: 2288\n",
            "loss: 79.82846069335938\n",
            "step: 2289\n",
            "loss: 64.232666015625\n",
            "step: 2290\n",
            "loss: 72.15817260742188\n",
            "step: 2291\n",
            "loss: 74.65487670898438\n",
            "step: 2292\n",
            "loss: 61.253013610839844\n",
            "step: 2293\n",
            "loss: 62.03304672241211\n",
            "step: 2294\n",
            "loss: 86.73187255859375\n",
            "step: 2295\n",
            "loss: 74.04092407226562\n",
            "step: 2296\n",
            "loss: 68.02889251708984\n",
            "step: 2297\n",
            "loss: 70.39892578125\n",
            "step: 2298\n",
            "loss: 75.29637145996094\n",
            "step: 2299\n",
            "loss: 81.3557357788086\n",
            "step: 2300\n",
            "loss: 80.9036865234375\n",
            "step: 2301\n",
            "loss: 51.54480743408203\n",
            "step: 2302\n",
            "loss: 125.64209747314453\n",
            "step: 2303\n",
            "loss: 66.87913513183594\n",
            "step: 2304\n",
            "loss: 75.91108703613281\n",
            "step: 2305\n",
            "loss: 64.51485443115234\n",
            "step: 2306\n",
            "loss: 58.397727966308594\n",
            "step: 2307\n",
            "loss: 69.15957641601562\n",
            "step: 2308\n",
            "loss: 74.5830078125\n",
            "step: 2309\n",
            "loss: 62.773658752441406\n",
            "step: 2310\n",
            "loss: 50.66236877441406\n",
            "step: 2311\n",
            "loss: 64.63426208496094\n",
            "step: 2312\n",
            "loss: 81.47616577148438\n",
            "step: 2313\n",
            "loss: 58.419090270996094\n",
            "step: 2314\n",
            "loss: 63.885345458984375\n",
            "step: 2315\n",
            "loss: 64.12957763671875\n",
            "step: 2316\n",
            "loss: 60.57355499267578\n",
            "step: 2317\n",
            "loss: 71.10832977294922\n",
            "step: 2318\n",
            "loss: 53.119178771972656\n",
            "step: 2319\n",
            "loss: 60.284332275390625\n",
            "step: 2320\n",
            "loss: 51.171566009521484\n",
            "step: 2321\n",
            "loss: 72.95267486572266\n",
            "step: 2322\n",
            "loss: 96.71537780761719\n",
            "step: 2323\n",
            "loss: 61.73766326904297\n",
            "step: 2324\n",
            "loss: 60.965057373046875\n",
            "step: 2325\n",
            "loss: 73.24928283691406\n",
            "step: 2326\n",
            "loss: 57.43622589111328\n",
            "step: 2327\n",
            "loss: 91.10979461669922\n",
            "step: 2328\n",
            "loss: 45.14268493652344\n",
            "step: 2329\n",
            "loss: 82.32177734375\n",
            "step: 2330\n",
            "loss: 69.5006103515625\n",
            "step: 2331\n",
            "loss: 45.474395751953125\n",
            "step: 2332\n",
            "loss: 47.35266876220703\n",
            "step: 2333\n",
            "loss: 52.774349212646484\n",
            "step: 2334\n",
            "loss: 52.94765090942383\n",
            "step: 2335\n",
            "loss: 64.89266204833984\n",
            "step: 2336\n",
            "loss: 47.322998046875\n",
            "step: 2337\n",
            "loss: 54.225685119628906\n",
            "step: 2338\n",
            "loss: 64.34444427490234\n",
            "step: 2339\n",
            "loss: 68.17831420898438\n",
            "step: 2340\n",
            "loss: 63.94129180908203\n",
            "step: 2341\n",
            "loss: 76.61441040039062\n",
            "step: 2342\n",
            "loss: 44.02392578125\n",
            "step: 2343\n",
            "loss: 45.83748245239258\n",
            "step: 2344\n",
            "loss: 77.00096893310547\n",
            "step: 2345\n",
            "loss: 61.27924728393555\n",
            "step: 2346\n",
            "loss: 32.38213348388672\n",
            "step: 2347\n",
            "loss: 50.25546646118164\n",
            "step: 2348\n",
            "loss: 81.11518859863281\n",
            "step: 2349\n",
            "loss: 88.75070190429688\n",
            "step: 2350\n",
            "loss: 37.13520050048828\n",
            "step: 2351\n",
            "loss: 47.232444763183594\n",
            "step: 2352\n",
            "loss: 41.71885299682617\n",
            "step: 2353\n",
            "loss: 53.68488693237305\n",
            "step: 2354\n",
            "loss: 60.86003112792969\n",
            "step: 2355\n",
            "loss: 70.4189682006836\n",
            "step: 2356\n",
            "loss: 42.62714385986328\n",
            "step: 2357\n",
            "loss: 71.1026611328125\n",
            "step: 2358\n",
            "loss: 71.83346557617188\n",
            "step: 2359\n",
            "loss: 47.92765808105469\n",
            "step: 2360\n",
            "loss: 49.33189392089844\n",
            "step: 2361\n",
            "loss: 77.59742736816406\n",
            "step: 2362\n",
            "loss: 60.74668884277344\n",
            "step: 2363\n",
            "loss: 77.46936798095703\n",
            "step: 2364\n",
            "loss: 61.44819641113281\n",
            "step: 2365\n",
            "loss: 70.5285873413086\n",
            "step: 2366\n",
            "loss: 54.51093292236328\n",
            "step: 2367\n",
            "loss: 70.94500732421875\n",
            "step: 2368\n",
            "loss: 58.48344421386719\n",
            "step: 2369\n",
            "loss: 32.934173583984375\n",
            "step: 2370\n",
            "loss: 52.33113098144531\n",
            "step: 2371\n",
            "loss: 59.80583190917969\n",
            "step: 2372\n",
            "loss: 87.42633056640625\n",
            "step: 2373\n",
            "loss: 50.27249526977539\n",
            "step: 2374\n",
            "loss: 57.48031997680664\n",
            "step: 2375\n",
            "loss: 60.002906799316406\n",
            "step: 2376\n",
            "loss: 85.30690002441406\n",
            "step: 2377\n",
            "loss: 46.796871185302734\n",
            "step: 2378\n",
            "loss: 93.89488220214844\n",
            "step: 2379\n",
            "loss: 38.22951889038086\n",
            "step: 2380\n",
            "loss: 58.59546661376953\n",
            "step: 2381\n",
            "loss: 84.66325378417969\n",
            "step: 2382\n",
            "loss: 81.37024688720703\n",
            "step: 2383\n",
            "loss: 55.48716735839844\n",
            "step: 2384\n",
            "loss: 66.43022918701172\n",
            "step: 2385\n",
            "loss: 88.61683654785156\n",
            "step: 2386\n",
            "loss: 50.98857116699219\n",
            "step: 2387\n",
            "loss: 68.57522583007812\n",
            "step: 2388\n",
            "loss: 63.25587844848633\n",
            "step: 2389\n",
            "loss: 67.8094253540039\n",
            "step: 2390\n",
            "loss: 77.80836486816406\n",
            "step: 2391\n",
            "loss: 51.908203125\n",
            "step: 2392\n",
            "loss: 69.54814910888672\n",
            "step: 2393\n",
            "loss: 62.62474822998047\n",
            "step: 2394\n",
            "loss: 63.07544708251953\n",
            "step: 2395\n",
            "loss: 62.174400329589844\n",
            "step: 2396\n",
            "loss: 79.41911315917969\n",
            "step: 2397\n",
            "loss: 58.98550033569336\n",
            "step: 2398\n",
            "loss: 64.189453125\n",
            "step: 2399\n",
            "loss: 45.35285186767578\n",
            "step: 2400\n",
            "loss: 61.79042053222656\n",
            "step: 2401\n",
            "loss: 77.22331237792969\n",
            "step: 2402\n",
            "loss: 64.62931060791016\n",
            "step: 2403\n",
            "loss: 72.17158508300781\n",
            "step: 2404\n",
            "loss: 70.94141387939453\n",
            "step: 2405\n",
            "loss: 55.053470611572266\n",
            "step: 2406\n",
            "loss: 85.86738586425781\n",
            "step: 2407\n",
            "loss: 76.91874694824219\n",
            "step: 2408\n",
            "loss: 48.537330627441406\n",
            "step: 2409\n",
            "loss: 89.98387145996094\n",
            "step: 2410\n",
            "loss: 105.39093780517578\n",
            "step: 2411\n",
            "loss: 51.67567825317383\n",
            "step: 2412\n",
            "loss: 70.78359985351562\n",
            "step: 2413\n",
            "loss: 61.90309143066406\n",
            "step: 2414\n",
            "loss: 77.65557861328125\n",
            "step: 2415\n",
            "loss: 66.3918228149414\n",
            "step: 2416\n",
            "loss: 71.05663299560547\n",
            "step: 2417\n",
            "loss: 56.995155334472656\n",
            "step: 2418\n",
            "loss: 59.3680419921875\n",
            "step: 2419\n",
            "loss: 63.067623138427734\n",
            "step: 2420\n",
            "loss: 78.74443054199219\n",
            "step: 2421\n",
            "loss: 88.17967224121094\n",
            "step: 2422\n",
            "loss: 57.345638275146484\n",
            "step: 2423\n",
            "loss: 64.46165466308594\n",
            "step: 2424\n",
            "loss: 65.27998352050781\n",
            "step: 2425\n",
            "loss: 56.025672912597656\n",
            "step: 2426\n",
            "loss: 66.7376708984375\n",
            "step: 2427\n",
            "loss: 57.919158935546875\n",
            "step: 2428\n",
            "loss: 73.53016662597656\n",
            "step: 2429\n",
            "loss: 68.81163024902344\n",
            "step: 2430\n",
            "loss: 53.31890869140625\n",
            "step: 2431\n",
            "loss: 67.78672790527344\n",
            "step: 2432\n",
            "loss: 65.64326477050781\n",
            "step: 2433\n",
            "loss: 60.63938903808594\n",
            "step: 2434\n",
            "loss: 57.38288116455078\n",
            "step: 2435\n",
            "loss: 69.66387939453125\n",
            "step: 2436\n",
            "loss: 90.12760925292969\n",
            "step: 2437\n",
            "loss: 65.53713989257812\n",
            "step: 2438\n",
            "loss: 42.00439453125\n",
            "step: 2439\n",
            "loss: 75.62604522705078\n",
            "step: 2440\n",
            "loss: 80.42630767822266\n",
            "step: 2441\n",
            "loss: 66.11483001708984\n",
            "step: 2442\n",
            "loss: 95.12864685058594\n",
            "step: 2443\n",
            "loss: 57.08899688720703\n",
            "step: 2444\n",
            "loss: 61.675132751464844\n",
            "step: 2445\n",
            "loss: 82.77593231201172\n",
            "step: 2446\n",
            "loss: 69.83354949951172\n",
            "step: 2447\n",
            "loss: 81.65647888183594\n",
            "step: 2448\n",
            "loss: 88.92550659179688\n",
            "step: 2449\n",
            "loss: 81.60962677001953\n",
            "step: 2450\n",
            "loss: 81.36248779296875\n",
            "step: 2451\n",
            "loss: 97.74977111816406\n",
            "step: 2452\n",
            "loss: 67.33079528808594\n",
            "step: 2453\n",
            "loss: 50.034481048583984\n",
            "step: 2454\n",
            "loss: 93.88380432128906\n",
            "step: 2455\n",
            "loss: 68.53117370605469\n",
            "step: 2456\n",
            "loss: 59.94621276855469\n",
            "step: 2457\n",
            "loss: 49.74677276611328\n",
            "step: 2458\n",
            "loss: 63.74470520019531\n",
            "step: 2459\n",
            "loss: 81.1541976928711\n",
            "step: 2460\n",
            "loss: 63.92461395263672\n",
            "step: 2461\n",
            "loss: 64.66011047363281\n",
            "step: 2462\n",
            "loss: 55.9610595703125\n",
            "step: 2463\n",
            "loss: 81.9832763671875\n",
            "step: 2464\n",
            "loss: 57.230323791503906\n",
            "step: 2465\n",
            "loss: 70.81172943115234\n",
            "step: 2466\n",
            "loss: 86.80250549316406\n",
            "step: 2467\n",
            "loss: 72.92515563964844\n",
            "step: 2468\n",
            "loss: 71.67546081542969\n",
            "step: 2469\n",
            "loss: 71.65867614746094\n",
            "step: 2470\n",
            "loss: 89.78720092773438\n",
            "step: 2471\n",
            "loss: 88.72276306152344\n",
            "step: 2472\n",
            "loss: 59.725830078125\n",
            "step: 2473\n",
            "loss: 47.63880920410156\n",
            "step: 2474\n",
            "loss: 79.1997299194336\n",
            "step: 2475\n",
            "loss: 52.82781982421875\n",
            "step: 2476\n",
            "loss: 64.00743103027344\n",
            "step: 2477\n",
            "loss: 72.07328033447266\n",
            "step: 2478\n",
            "loss: 102.7789306640625\n",
            "step: 2479\n",
            "loss: 69.66532897949219\n",
            "step: 2480\n",
            "loss: 75.5008544921875\n",
            "step: 2481\n",
            "loss: 98.48395538330078\n",
            "step: 2482\n",
            "loss: 62.040653228759766\n",
            "step: 2483\n",
            "loss: 68.52899932861328\n",
            "step: 2484\n",
            "loss: 72.61653137207031\n",
            "step: 2485\n",
            "loss: 56.448768615722656\n",
            "step: 2486\n",
            "loss: 61.29304885864258\n",
            "step: 2487\n",
            "loss: 67.34662628173828\n",
            "step: 2488\n",
            "loss: 65.17208862304688\n",
            "step: 2489\n",
            "loss: 57.52574157714844\n",
            "step: 2490\n",
            "loss: 63.18860626220703\n",
            "step: 2491\n",
            "loss: 65.56898498535156\n",
            "step: 2492\n",
            "loss: 59.66392517089844\n",
            "step: 2493\n",
            "loss: 78.10012817382812\n",
            "step: 2494\n",
            "loss: 92.95965576171875\n",
            "step: 2495\n",
            "loss: 76.28096771240234\n",
            "step: 2496\n",
            "loss: 67.77867126464844\n",
            "step: 2497\n",
            "loss: 72.09353637695312\n",
            "step: 2498\n",
            "loss: 80.213623046875\n",
            "step: 2499\n",
            "loss: 88.72251892089844\n",
            "step: 2500\n",
            "loss: 61.946693420410156\n",
            "step: 2501\n",
            "loss: 40.522525787353516\n",
            "step: 2502\n",
            "loss: 93.9984130859375\n",
            "step: 2503\n",
            "loss: 59.374168395996094\n",
            "step: 2504\n",
            "loss: 57.99822998046875\n",
            "step: 2505\n",
            "loss: 58.00242614746094\n",
            "step: 2506\n",
            "loss: 57.07481002807617\n",
            "step: 2507\n",
            "loss: 60.88908386230469\n",
            "step: 2508\n",
            "loss: 73.505859375\n",
            "step: 2509\n",
            "loss: 96.53845977783203\n",
            "step: 2510\n",
            "loss: 65.63633728027344\n",
            "step: 2511\n",
            "loss: 55.522857666015625\n",
            "step: 2512\n",
            "loss: 73.82304382324219\n",
            "step: 2513\n",
            "loss: 72.09275817871094\n",
            "step: 2514\n",
            "loss: 67.52212524414062\n",
            "step: 2515\n",
            "loss: 82.38316345214844\n",
            "step: 2516\n",
            "loss: 85.30762481689453\n",
            "step: 2517\n",
            "loss: 58.110328674316406\n",
            "step: 2518\n",
            "loss: 88.70825958251953\n",
            "step: 2519\n",
            "loss: 66.03657531738281\n",
            "step: 2520\n",
            "loss: 77.84954833984375\n",
            "step: 2521\n",
            "loss: 61.0831298828125\n",
            "step: 2522\n",
            "loss: 77.57862854003906\n",
            "step: 2523\n",
            "loss: 85.53187561035156\n",
            "step: 2524\n",
            "loss: 47.61650466918945\n",
            "step: 2525\n",
            "loss: 59.0113410949707\n",
            "step: 2526\n",
            "loss: 68.713134765625\n",
            "step: 2527\n",
            "loss: 76.8988037109375\n",
            "step: 2528\n",
            "loss: 73.50662231445312\n",
            "step: 2529\n",
            "loss: 65.50215911865234\n",
            "step: 2530\n",
            "loss: 86.75422668457031\n",
            "step: 2531\n",
            "loss: 68.28665161132812\n",
            "step: 2532\n",
            "loss: 66.66227722167969\n",
            "step: 2533\n",
            "loss: 76.85858917236328\n",
            "step: 2534\n",
            "loss: 62.44800567626953\n",
            "step: 2535\n",
            "loss: 62.52681350708008\n",
            "step: 2536\n",
            "loss: 63.27350997924805\n",
            "step: 2537\n",
            "loss: 83.24758911132812\n",
            "step: 2538\n",
            "loss: 51.859275817871094\n",
            "step: 2539\n",
            "loss: 63.4081916809082\n",
            "step: 2540\n",
            "loss: 73.44892883300781\n",
            "step: 2541\n",
            "loss: 50.6641731262207\n",
            "step: 2542\n",
            "loss: 75.83407592773438\n",
            "step: 2543\n",
            "loss: 51.46477127075195\n",
            "step: 2544\n",
            "loss: 50.18634033203125\n",
            "step: 2545\n",
            "loss: 73.8869400024414\n",
            "step: 2546\n",
            "loss: 46.75299072265625\n",
            "step: 2547\n",
            "loss: 39.67688751220703\n",
            "step: 2548\n",
            "loss: 52.103153228759766\n",
            "step: 2549\n",
            "loss: 78.82202911376953\n",
            "step: 2550\n",
            "loss: 67.59268951416016\n",
            "step: 2551\n",
            "loss: 54.73335266113281\n",
            "step: 2552\n",
            "loss: 40.91755676269531\n",
            "step: 2553\n",
            "loss: 39.671939849853516\n",
            "step: 2554\n",
            "loss: 78.106201171875\n",
            "step: 2555\n",
            "loss: 57.482215881347656\n",
            "step: 2556\n",
            "loss: 46.03229904174805\n",
            "step: 2557\n",
            "loss: 51.473976135253906\n",
            "step: 2558\n",
            "loss: 57.53664016723633\n",
            "step: 2559\n",
            "loss: 68.1963119506836\n",
            "step: 2560\n",
            "loss: 69.64111328125\n",
            "step: 2561\n",
            "loss: 68.2198257446289\n",
            "step: 2562\n",
            "loss: 67.42375946044922\n",
            "step: 2563\n",
            "loss: 82.04481506347656\n",
            "step: 2564\n",
            "loss: 43.16361999511719\n",
            "step: 2565\n",
            "loss: 60.193992614746094\n",
            "step: 2566\n",
            "loss: 81.5897216796875\n",
            "step: 2567\n",
            "loss: 61.01647186279297\n",
            "step: 2568\n",
            "loss: 43.445289611816406\n",
            "step: 2569\n",
            "loss: 70.23702239990234\n",
            "step: 2570\n",
            "loss: 35.66900634765625\n",
            "step: 2571\n",
            "loss: 45.56789779663086\n",
            "step: 2572\n",
            "loss: 47.85627746582031\n",
            "step: 2573\n",
            "loss: 64.10212707519531\n",
            "step: 2574\n",
            "loss: 44.21138381958008\n",
            "step: 2575\n",
            "loss: 71.00245666503906\n",
            "step: 2576\n",
            "loss: 38.83802032470703\n",
            "step: 2577\n",
            "loss: 49.81453323364258\n",
            "step: 2578\n",
            "loss: 64.50699615478516\n",
            "step: 2579\n",
            "loss: 66.99190521240234\n",
            "step: 2580\n",
            "loss: 68.45387268066406\n",
            "step: 2581\n",
            "loss: 52.99372100830078\n",
            "step: 2582\n",
            "loss: 77.0110855102539\n",
            "step: 2583\n",
            "loss: 56.256046295166016\n",
            "step: 2584\n",
            "loss: 51.27916717529297\n",
            "step: 2585\n",
            "loss: 52.19031524658203\n",
            "step: 2586\n",
            "loss: 66.28954315185547\n",
            "step: 2587\n",
            "loss: 45.90815734863281\n",
            "step: 2588\n",
            "loss: 76.73149871826172\n",
            "step: 2589\n",
            "loss: 88.1542739868164\n",
            "step: 2590\n",
            "loss: 65.42568969726562\n",
            "step: 2591\n",
            "loss: 58.06712341308594\n",
            "step: 2592\n",
            "loss: 62.380916595458984\n",
            "step: 2593\n",
            "loss: 57.378028869628906\n",
            "step: 2594\n",
            "loss: 59.95963668823242\n",
            "step: 2595\n",
            "loss: 53.2818603515625\n",
            "step: 2596\n",
            "loss: 60.262428283691406\n",
            "step: 2597\n",
            "loss: 62.493553161621094\n",
            "step: 2598\n",
            "loss: 57.83411407470703\n",
            "step: 2599\n",
            "loss: 54.527130126953125\n",
            "step: 2600\n",
            "loss: 41.27680206298828\n",
            "step: 2601\n",
            "loss: 50.13142395019531\n",
            "step: 2602\n",
            "loss: 82.63198852539062\n",
            "step: 2603\n",
            "loss: 65.23786163330078\n",
            "step: 2604\n",
            "loss: 57.73914337158203\n",
            "step: 2605\n",
            "loss: 60.10560607910156\n",
            "step: 2606\n",
            "loss: 63.378623962402344\n",
            "step: 2607\n",
            "loss: 70.67509460449219\n",
            "step: 2608\n",
            "loss: 60.80376434326172\n",
            "step: 2609\n",
            "loss: 55.336814880371094\n",
            "step: 2610\n",
            "loss: 68.12538146972656\n",
            "step: 2611\n",
            "loss: 52.40777587890625\n",
            "step: 2612\n",
            "loss: 73.34654235839844\n",
            "step: 2613\n",
            "loss: 65.56590270996094\n",
            "step: 2614\n",
            "loss: 49.370338439941406\n",
            "step: 2615\n",
            "loss: 52.41070556640625\n",
            "step: 2616\n",
            "loss: 56.654296875\n",
            "step: 2617\n",
            "loss: 67.48410034179688\n",
            "step: 2618\n",
            "loss: 89.33695983886719\n",
            "step: 2619\n",
            "loss: 79.30648803710938\n",
            "step: 2620\n",
            "loss: 67.5179672241211\n",
            "step: 2621\n",
            "loss: 68.91166687011719\n",
            "step: 2622\n",
            "loss: 75.39913940429688\n",
            "step: 2623\n",
            "loss: 80.10411071777344\n",
            "step: 2624\n",
            "loss: 42.35605239868164\n",
            "step: 2625\n",
            "loss: 77.22239685058594\n",
            "step: 2626\n",
            "loss: 86.5128173828125\n",
            "step: 2627\n",
            "loss: 54.79762649536133\n",
            "step: 2628\n",
            "loss: 58.84219741821289\n",
            "step: 2629\n",
            "loss: 63.69804000854492\n",
            "step: 2630\n",
            "loss: 66.1743392944336\n",
            "step: 2631\n",
            "loss: 75.84993743896484\n",
            "step: 2632\n",
            "loss: 68.64092254638672\n",
            "step: 2633\n",
            "loss: 49.44164276123047\n",
            "step: 2634\n",
            "loss: 85.2214584350586\n",
            "step: 2635\n",
            "loss: 101.52761840820312\n",
            "step: 2636\n",
            "loss: 57.3677864074707\n",
            "step: 2637\n",
            "loss: 42.06685256958008\n",
            "step: 2638\n",
            "loss: 67.48137664794922\n",
            "step: 2639\n",
            "loss: 40.466468811035156\n",
            "step: 2640\n",
            "loss: 76.20616149902344\n",
            "step: 2641\n",
            "loss: 46.78112030029297\n",
            "step: 2642\n",
            "loss: 66.61505889892578\n",
            "step: 2643\n",
            "loss: 64.47515869140625\n",
            "step: 2644\n",
            "loss: 66.29203033447266\n",
            "step: 2645\n",
            "loss: 61.13958740234375\n",
            "step: 2646\n",
            "loss: 60.02671813964844\n",
            "step: 2647\n",
            "loss: 57.76897430419922\n",
            "step: 2648\n",
            "loss: 48.846771240234375\n",
            "step: 2649\n",
            "loss: 42.595279693603516\n",
            "step: 2650\n",
            "loss: 60.258846282958984\n",
            "step: 2651\n",
            "loss: 56.32463836669922\n",
            "step: 2652\n",
            "loss: 56.58409118652344\n",
            "step: 2653\n",
            "loss: 58.5093994140625\n",
            "step: 2654\n",
            "loss: 71.37940979003906\n",
            "step: 2655\n",
            "loss: 65.09547424316406\n",
            "step: 2656\n",
            "loss: 48.54600524902344\n",
            "step: 2657\n",
            "loss: 72.03089904785156\n",
            "step: 2658\n",
            "loss: 82.68499755859375\n",
            "step: 2659\n",
            "loss: 52.03943634033203\n",
            "step: 2660\n",
            "loss: 56.62651062011719\n",
            "step: 2661\n",
            "loss: 55.2159423828125\n",
            "step: 2662\n",
            "loss: 57.538475036621094\n",
            "step: 2663\n",
            "loss: 71.97349548339844\n",
            "step: 2664\n",
            "loss: 55.68267822265625\n",
            "step: 2665\n",
            "loss: 60.377593994140625\n",
            "step: 2666\n",
            "loss: 62.4815673828125\n",
            "step: 2667\n",
            "loss: 66.14502716064453\n",
            "step: 2668\n",
            "loss: 49.527584075927734\n",
            "step: 2669\n",
            "loss: 57.81761169433594\n",
            "step: 2670\n",
            "loss: 80.3482894897461\n",
            "step: 2671\n",
            "loss: 93.45904541015625\n",
            "step: 2672\n",
            "loss: 58.82708740234375\n",
            "step: 2673\n",
            "loss: 88.14068603515625\n",
            "step: 2674\n",
            "loss: 60.68793487548828\n",
            "step: 2675\n",
            "loss: 70.0716552734375\n",
            "step: 2676\n",
            "loss: 52.01351547241211\n",
            "step: 2677\n",
            "loss: 74.72366333007812\n",
            "step: 2678\n",
            "loss: 60.0960693359375\n",
            "step: 2679\n",
            "loss: 52.475616455078125\n",
            "step: 2680\n",
            "loss: 60.705440521240234\n",
            "step: 2681\n",
            "loss: 58.13744354248047\n",
            "step: 2682\n",
            "loss: 78.82048034667969\n",
            "step: 2683\n",
            "loss: 84.5790023803711\n",
            "step: 2684\n",
            "loss: 74.70340728759766\n",
            "step: 2685\n",
            "loss: 103.57664489746094\n",
            "step: 2686\n",
            "loss: 76.698974609375\n",
            "step: 2687\n",
            "loss: 78.76741027832031\n",
            "step: 2688\n",
            "loss: 74.04536437988281\n",
            "step: 2689\n",
            "loss: 57.36486053466797\n",
            "step: 2690\n",
            "loss: 60.835235595703125\n",
            "step: 2691\n",
            "loss: 63.258270263671875\n",
            "step: 2692\n",
            "loss: 84.28871154785156\n",
            "step: 2693\n",
            "loss: 56.64613723754883\n",
            "step: 2694\n",
            "loss: 47.60939025878906\n",
            "step: 2695\n",
            "loss: 43.989009857177734\n",
            "step: 2696\n",
            "loss: 56.2774543762207\n",
            "step: 2697\n",
            "loss: 67.0435791015625\n",
            "step: 2698\n",
            "loss: 61.21621322631836\n",
            "step: 2699\n",
            "loss: 59.80339813232422\n",
            "step: 2700\n",
            "loss: 78.81317138671875\n",
            "step: 2701\n",
            "loss: 93.97860717773438\n",
            "step: 2702\n",
            "loss: 94.16574096679688\n",
            "step: 2703\n",
            "loss: 64.70482635498047\n",
            "step: 2704\n",
            "loss: 60.198238372802734\n",
            "step: 2705\n",
            "loss: 33.976627349853516\n",
            "step: 2706\n",
            "loss: 79.32229614257812\n",
            "step: 2707\n",
            "loss: 62.942588806152344\n",
            "step: 2708\n",
            "loss: 51.22835159301758\n",
            "step: 2709\n",
            "loss: 78.305908203125\n",
            "step: 2710\n",
            "loss: 57.41889953613281\n",
            "step: 2711\n",
            "loss: 61.469139099121094\n",
            "step: 2712\n",
            "loss: 49.98494338989258\n",
            "step: 2713\n",
            "loss: 77.93653869628906\n",
            "step: 2714\n",
            "loss: 68.74349975585938\n",
            "step: 2715\n",
            "loss: 50.176597595214844\n",
            "step: 2716\n",
            "loss: 59.424007415771484\n",
            "step: 2717\n",
            "loss: 62.447914123535156\n",
            "step: 2718\n",
            "loss: 75.82376861572266\n",
            "step: 2719\n",
            "loss: 62.026798248291016\n",
            "step: 2720\n",
            "loss: 80.11404418945312\n",
            "step: 2721\n",
            "loss: 48.90864562988281\n",
            "step: 2722\n",
            "loss: 62.3707160949707\n",
            "step: 2723\n",
            "loss: 39.32524490356445\n",
            "step: 2724\n",
            "loss: 63.496910095214844\n",
            "step: 2725\n",
            "loss: 54.64692306518555\n",
            "step: 2726\n",
            "loss: 88.1970443725586\n",
            "step: 2727\n",
            "loss: 67.6113052368164\n",
            "step: 2728\n",
            "loss: 78.20769500732422\n",
            "step: 2729\n",
            "loss: 69.503173828125\n",
            "step: 2730\n",
            "loss: 62.14020919799805\n",
            "step: 2731\n",
            "loss: 92.44023132324219\n",
            "step: 2732\n",
            "loss: 66.22311401367188\n",
            "step: 2733\n",
            "loss: 63.836883544921875\n",
            "step: 2734\n",
            "loss: 48.18665313720703\n",
            "step: 2735\n",
            "loss: 94.56216430664062\n",
            "step: 2736\n",
            "loss: 66.9373779296875\n",
            "step: 2737\n",
            "loss: 72.7786636352539\n",
            "step: 2738\n",
            "loss: 69.50154876708984\n",
            "step: 2739\n",
            "loss: 65.51356506347656\n",
            "step: 2740\n",
            "loss: 90.8413314819336\n",
            "step: 2741\n",
            "loss: 74.33341979980469\n",
            "step: 2742\n",
            "loss: 47.71372604370117\n",
            "step: 2743\n",
            "loss: 60.32908248901367\n",
            "step: 2744\n",
            "loss: 61.27097702026367\n",
            "step: 2745\n",
            "loss: 67.30115509033203\n",
            "step: 2746\n",
            "loss: 82.74129486083984\n",
            "step: 2747\n",
            "loss: 68.90087890625\n",
            "step: 2748\n",
            "loss: 70.55931091308594\n",
            "step: 2749\n",
            "loss: 54.927040100097656\n",
            "step: 2750\n",
            "loss: 77.53953552246094\n",
            "step: 2751\n",
            "loss: 71.05647277832031\n",
            "step: 2752\n",
            "loss: 61.51857376098633\n",
            "step: 2753\n",
            "loss: 45.57963180541992\n",
            "step: 2754\n",
            "loss: 84.92903900146484\n",
            "step: 2755\n",
            "loss: 79.57152557373047\n",
            "step: 2756\n",
            "loss: 73.44110107421875\n",
            "step: 2757\n",
            "loss: 82.61141967773438\n",
            "step: 2758\n",
            "loss: 73.93782806396484\n",
            "step: 2759\n",
            "loss: 70.48532104492188\n",
            "step: 2760\n",
            "loss: 56.255958557128906\n",
            "step: 2761\n",
            "loss: 59.119407653808594\n",
            "step: 2762\n",
            "loss: 89.31985473632812\n",
            "step: 2763\n",
            "loss: 61.321624755859375\n",
            "step: 2764\n",
            "loss: 69.76795959472656\n",
            "step: 2765\n",
            "loss: 56.14900588989258\n",
            "step: 2766\n",
            "loss: 60.15038299560547\n",
            "step: 2767\n",
            "loss: 35.970245361328125\n",
            "step: 2768\n",
            "loss: 50.36833953857422\n",
            "step: 2769\n",
            "loss: 59.18524169921875\n",
            "step: 2770\n",
            "loss: 52.276954650878906\n",
            "step: 2771\n",
            "loss: 96.74549865722656\n",
            "step: 2772\n",
            "loss: 46.150146484375\n",
            "step: 2773\n",
            "loss: 51.61389923095703\n",
            "step: 2774\n",
            "loss: 64.77999114990234\n",
            "step: 2775\n",
            "loss: 51.890785217285156\n",
            "step: 2776\n",
            "loss: 61.71464157104492\n",
            "step: 2777\n",
            "loss: 47.18830108642578\n",
            "step: 2778\n",
            "loss: 71.81368255615234\n",
            "step: 2779\n",
            "loss: 55.05251693725586\n",
            "step: 2780\n",
            "loss: 75.35848236083984\n",
            "step: 2781\n",
            "loss: 81.48666381835938\n",
            "step: 2782\n",
            "loss: 51.761817932128906\n",
            "step: 2783\n",
            "loss: 44.27128601074219\n",
            "step: 2784\n",
            "loss: 51.673797607421875\n",
            "step: 2785\n",
            "loss: 41.473018646240234\n",
            "step: 2786\n",
            "loss: 66.99824523925781\n",
            "step: 2787\n",
            "loss: 40.65345764160156\n",
            "step: 2788\n",
            "loss: 64.16032409667969\n",
            "step: 2789\n",
            "loss: 49.86347961425781\n",
            "step: 2790\n",
            "loss: 61.80525588989258\n",
            "step: 2791\n",
            "loss: 51.863304138183594\n",
            "step: 2792\n",
            "loss: 62.318145751953125\n",
            "step: 2793\n",
            "loss: 70.99383544921875\n",
            "step: 2794\n",
            "loss: 60.716983795166016\n",
            "step: 2795\n",
            "loss: 73.86884307861328\n",
            "step: 2796\n",
            "loss: 68.89392852783203\n",
            "step: 2797\n",
            "loss: 77.8097152709961\n",
            "step: 2798\n",
            "loss: 56.14622116088867\n",
            "step: 2799\n",
            "loss: 48.96484375\n",
            "step: 2800\n",
            "loss: 45.201393127441406\n",
            "step: 2801\n",
            "loss: 75.25104522705078\n",
            "step: 2802\n",
            "loss: 44.31517028808594\n",
            "step: 2803\n",
            "loss: 47.89137268066406\n",
            "step: 2804\n",
            "loss: 45.87014389038086\n",
            "step: 2805\n",
            "loss: 74.05419921875\n",
            "step: 2806\n",
            "loss: 81.70416259765625\n",
            "step: 2807\n",
            "loss: 66.27861022949219\n",
            "step: 2808\n",
            "loss: 82.87750244140625\n",
            "step: 2809\n",
            "loss: 57.752708435058594\n",
            "step: 2810\n",
            "loss: 58.34975814819336\n",
            "step: 2811\n",
            "loss: 54.57884216308594\n",
            "step: 2812\n",
            "loss: 61.593849182128906\n",
            "step: 2813\n",
            "loss: 43.47782897949219\n",
            "step: 2814\n",
            "loss: 50.694068908691406\n",
            "step: 2815\n",
            "loss: 78.71206665039062\n",
            "step: 2816\n",
            "loss: 61.38008499145508\n",
            "step: 2817\n",
            "loss: 78.27811431884766\n",
            "step: 2818\n",
            "loss: 46.625030517578125\n",
            "step: 2819\n",
            "loss: 59.157691955566406\n",
            "step: 2820\n",
            "loss: 56.42325210571289\n",
            "step: 2821\n",
            "loss: 65.38202667236328\n",
            "step: 2822\n",
            "loss: 55.047176361083984\n",
            "step: 2823\n",
            "loss: 66.5059814453125\n",
            "step: 2824\n",
            "loss: 41.80510711669922\n",
            "step: 2825\n",
            "loss: 70.72349548339844\n",
            "step: 2826\n",
            "loss: 48.14908981323242\n",
            "step: 2827\n",
            "loss: 47.100242614746094\n",
            "step: 2828\n",
            "loss: 49.15025329589844\n",
            "step: 2829\n",
            "loss: 80.38690948486328\n",
            "step: 2830\n",
            "loss: 56.46582794189453\n",
            "step: 2831\n",
            "loss: 71.08077239990234\n",
            "step: 2832\n",
            "loss: 39.354339599609375\n",
            "step: 2833\n",
            "loss: 79.83377075195312\n",
            "step: 2834\n",
            "loss: 52.810707092285156\n",
            "step: 2835\n",
            "loss: 45.63910675048828\n",
            "step: 2836\n",
            "loss: 65.82209777832031\n",
            "step: 2837\n",
            "loss: 55.43055725097656\n",
            "step: 2838\n",
            "loss: 49.08656692504883\n",
            "step: 2839\n",
            "loss: 69.53128051757812\n",
            "step: 2840\n",
            "loss: 56.4482307434082\n",
            "step: 2841\n",
            "loss: 49.48041534423828\n",
            "step: 2842\n",
            "loss: 71.22183227539062\n",
            "step: 2843\n",
            "loss: 49.696685791015625\n",
            "step: 2844\n",
            "loss: 50.835365295410156\n",
            "step: 2845\n",
            "loss: 42.20792007446289\n",
            "step: 2846\n",
            "loss: 54.23716735839844\n",
            "step: 2847\n",
            "loss: 48.843841552734375\n",
            "step: 2848\n",
            "loss: 71.63612365722656\n",
            "step: 2849\n",
            "loss: 64.7701416015625\n",
            "step: 2850\n",
            "loss: 56.28345489501953\n",
            "step: 2851\n",
            "loss: 60.39505386352539\n",
            "step: 2852\n",
            "loss: 41.49312210083008\n",
            "step: 2853\n",
            "loss: 53.393882751464844\n",
            "step: 2854\n",
            "loss: 72.34449768066406\n",
            "step: 2855\n",
            "loss: 57.37725830078125\n",
            "step: 2856\n",
            "loss: 68.17594909667969\n",
            "step: 2857\n",
            "loss: 62.56312561035156\n",
            "step: 2858\n",
            "loss: 97.64701080322266\n",
            "step: 2859\n",
            "loss: 39.424137115478516\n",
            "step: 2860\n",
            "loss: 74.43946838378906\n",
            "step: 2861\n",
            "loss: 49.9591064453125\n",
            "step: 2862\n",
            "loss: 74.43157958984375\n",
            "step: 2863\n",
            "loss: 57.55150604248047\n",
            "step: 2864\n",
            "loss: 42.073219299316406\n",
            "step: 2865\n",
            "loss: 85.05540466308594\n",
            "step: 2866\n",
            "loss: 36.990814208984375\n",
            "step: 2867\n",
            "loss: 53.836700439453125\n",
            "step: 2868\n",
            "loss: 47.29039001464844\n",
            "step: 2869\n",
            "loss: 50.51336669921875\n",
            "step: 2870\n",
            "loss: 70.01305389404297\n",
            "step: 2871\n",
            "loss: 71.31968688964844\n",
            "step: 2872\n",
            "loss: 45.91447067260742\n",
            "step: 2873\n",
            "loss: 61.52606201171875\n",
            "step: 2874\n",
            "loss: 64.21941375732422\n",
            "step: 2875\n",
            "loss: 51.533912658691406\n",
            "step: 2876\n",
            "loss: 61.25787353515625\n",
            "step: 2877\n",
            "loss: 74.3536376953125\n",
            "step: 2878\n",
            "loss: 51.72626876831055\n",
            "step: 2879\n",
            "loss: 47.00634765625\n",
            "step: 2880\n",
            "loss: 65.80921173095703\n",
            "step: 2881\n",
            "loss: 76.29927062988281\n",
            "step: 2882\n",
            "loss: 65.6719741821289\n",
            "step: 2883\n",
            "loss: 66.35520935058594\n",
            "step: 2884\n",
            "loss: 45.861751556396484\n",
            "step: 2885\n",
            "loss: 47.312232971191406\n",
            "step: 2886\n",
            "loss: 77.40182495117188\n",
            "step: 2887\n",
            "loss: 58.005859375\n",
            "step: 2888\n",
            "loss: 57.778785705566406\n",
            "step: 2889\n",
            "loss: 84.7832260131836\n",
            "step: 2890\n",
            "loss: 69.6461181640625\n",
            "step: 2891\n",
            "loss: 30.34503173828125\n",
            "step: 2892\n",
            "loss: 48.396217346191406\n",
            "step: 2893\n",
            "loss: 51.296714782714844\n",
            "step: 2894\n",
            "loss: 53.50117492675781\n",
            "step: 2895\n",
            "loss: 70.79368591308594\n",
            "step: 2896\n",
            "loss: 64.469970703125\n",
            "step: 2897\n",
            "loss: 67.17143249511719\n",
            "step: 2898\n",
            "loss: 89.3066177368164\n",
            "step: 2899\n",
            "loss: 46.276649475097656\n",
            "step: 2900\n",
            "loss: 105.2652816772461\n",
            "step: 2901\n",
            "loss: 80.29067993164062\n",
            "step: 2902\n",
            "loss: 30.263229370117188\n",
            "step: 2903\n",
            "loss: 54.56678009033203\n",
            "step: 2904\n",
            "loss: 61.50211715698242\n",
            "step: 2905\n",
            "loss: 47.19816589355469\n",
            "step: 2906\n",
            "loss: 46.77549743652344\n",
            "step: 2907\n",
            "loss: 50.26543426513672\n",
            "step: 2908\n",
            "loss: 60.8077507019043\n",
            "step: 2909\n",
            "loss: 81.06228637695312\n",
            "step: 2910\n",
            "loss: 47.06785202026367\n",
            "step: 2911\n",
            "loss: 56.52012252807617\n",
            "step: 2912\n",
            "loss: 65.66365051269531\n",
            "step: 2913\n",
            "loss: 63.38886642456055\n",
            "step: 2914\n",
            "loss: 65.91024017333984\n",
            "step: 2915\n",
            "loss: 55.891441345214844\n",
            "step: 2916\n",
            "loss: 87.30209350585938\n",
            "step: 2917\n",
            "loss: 64.41735076904297\n",
            "step: 2918\n",
            "loss: 83.13839721679688\n",
            "step: 2919\n",
            "loss: 62.99522399902344\n",
            "step: 2920\n",
            "loss: 64.97230529785156\n",
            "step: 2921\n",
            "loss: 67.4526138305664\n",
            "step: 2922\n",
            "loss: 76.63333892822266\n",
            "step: 2923\n",
            "loss: 66.9810562133789\n",
            "step: 2924\n",
            "loss: 83.59487915039062\n",
            "step: 2925\n",
            "loss: 72.79876708984375\n",
            "step: 2926\n",
            "loss: 50.83478546142578\n",
            "step: 2927\n",
            "loss: 69.02916717529297\n",
            "step: 2928\n",
            "loss: 53.8969841003418\n",
            "step: 2929\n",
            "loss: 59.74303436279297\n",
            "step: 2930\n",
            "loss: 57.553993225097656\n",
            "step: 2931\n",
            "loss: 72.13334655761719\n",
            "step: 2932\n",
            "loss: 60.85953903198242\n",
            "step: 2933\n",
            "loss: 59.020599365234375\n",
            "step: 2934\n",
            "loss: 49.82318115234375\n",
            "step: 2935\n",
            "loss: 60.59325408935547\n",
            "step: 2936\n",
            "loss: 39.572322845458984\n",
            "step: 2937\n",
            "loss: 71.53660583496094\n",
            "step: 2938\n",
            "loss: 43.29296112060547\n",
            "step: 2939\n",
            "loss: 71.92153930664062\n",
            "step: 2940\n",
            "loss: 73.99073791503906\n",
            "step: 2941\n",
            "loss: 42.38890075683594\n",
            "step: 2942\n",
            "loss: 48.490478515625\n",
            "step: 2943\n",
            "loss: 59.41315460205078\n",
            "step: 2944\n",
            "loss: 61.20882034301758\n",
            "step: 2945\n",
            "loss: 57.57628631591797\n",
            "step: 2946\n",
            "loss: 63.61020278930664\n",
            "step: 2947\n",
            "loss: 66.5150146484375\n",
            "step: 2948\n",
            "loss: 69.57987976074219\n",
            "step: 2949\n",
            "loss: 45.07799530029297\n",
            "step: 2950\n",
            "loss: 30.14811134338379\n",
            "step: 2951\n",
            "loss: 47.582435607910156\n",
            "step: 2952\n",
            "loss: 62.40215301513672\n",
            "step: 2953\n",
            "loss: 65.80763244628906\n",
            "step: 2954\n",
            "loss: 60.26513671875\n",
            "step: 2955\n",
            "loss: 81.02764892578125\n",
            "step: 2956\n",
            "loss: 62.31297302246094\n",
            "step: 2957\n",
            "loss: 38.515769958496094\n",
            "step: 2958\n",
            "loss: 62.558502197265625\n",
            "step: 2959\n",
            "loss: 42.483428955078125\n",
            "step: 2960\n",
            "loss: 68.52816772460938\n",
            "step: 2961\n",
            "loss: 58.305503845214844\n",
            "step: 2962\n",
            "loss: 76.36542510986328\n",
            "step: 2963\n",
            "loss: 98.14912414550781\n",
            "step: 2964\n",
            "loss: 43.59076690673828\n",
            "step: 2965\n",
            "loss: 78.44482421875\n",
            "step: 2966\n",
            "loss: 58.4550666809082\n",
            "step: 2967\n",
            "loss: 57.91534423828125\n",
            "step: 2968\n",
            "loss: 50.101566314697266\n",
            "step: 2969\n",
            "loss: 54.2050666809082\n",
            "step: 2970\n",
            "loss: 78.21817016601562\n",
            "step: 2971\n",
            "loss: 77.75886535644531\n",
            "step: 2972\n",
            "loss: 74.1479721069336\n",
            "step: 2973\n",
            "loss: 53.74461364746094\n",
            "step: 2974\n",
            "loss: 75.934814453125\n",
            "step: 2975\n",
            "loss: 79.00187683105469\n",
            "step: 2976\n",
            "loss: 86.28021240234375\n",
            "step: 2977\n",
            "loss: 72.841796875\n",
            "step: 2978\n",
            "loss: 63.12522506713867\n",
            "step: 2979\n",
            "loss: 76.93856048583984\n",
            "step: 2980\n",
            "loss: 80.52205657958984\n",
            "step: 2981\n",
            "loss: 78.95777130126953\n",
            "step: 2982\n",
            "loss: 52.45079040527344\n",
            "step: 2983\n",
            "loss: 64.39134216308594\n",
            "step: 2984\n",
            "loss: 62.16785430908203\n",
            "step: 2985\n",
            "loss: 69.5807113647461\n",
            "step: 2986\n",
            "loss: 53.684722900390625\n",
            "step: 2987\n",
            "loss: 63.1562614440918\n",
            "step: 2988\n",
            "loss: 57.22956466674805\n",
            "step: 2989\n",
            "loss: 62.007843017578125\n",
            "step: 2990\n",
            "loss: 58.139686584472656\n",
            "step: 2991\n",
            "loss: 99.67728424072266\n",
            "step: 2992\n",
            "loss: 53.84672546386719\n",
            "step: 2993\n",
            "loss: 49.35984802246094\n",
            "step: 2994\n",
            "loss: 61.324073791503906\n",
            "step: 2995\n",
            "loss: 43.6798095703125\n",
            "step: 2996\n",
            "loss: 52.56678771972656\n",
            "step: 2997\n",
            "loss: 66.60737609863281\n",
            "step: 2998\n",
            "loss: 47.051300048828125\n",
            "step: 2999\n",
            "loss: 38.59576416015625\n",
            "step: 3000\n",
            "loss: 89.57416534423828\n",
            "step: 3001\n",
            "loss: 85.83103942871094\n",
            "step: 3002\n",
            "loss: 57.676185607910156\n",
            "step: 3003\n",
            "loss: 43.91425704956055\n",
            "step: 3004\n",
            "loss: 82.61274719238281\n",
            "step: 3005\n",
            "loss: 66.44766998291016\n",
            "step: 3006\n",
            "loss: 48.91787338256836\n",
            "step: 3007\n",
            "loss: 71.3554458618164\n",
            "step: 3008\n",
            "loss: 81.76347351074219\n",
            "step: 3009\n",
            "loss: 54.78959655761719\n",
            "step: 3010\n",
            "loss: 62.64027404785156\n",
            "step: 3011\n",
            "loss: 72.64728546142578\n",
            "step: 3012\n",
            "loss: 91.16078186035156\n",
            "step: 3013\n",
            "loss: 42.57080841064453\n",
            "step: 3014\n",
            "loss: 76.09780883789062\n",
            "step: 3015\n",
            "loss: 64.52931213378906\n",
            "step: 3016\n",
            "loss: 47.912750244140625\n",
            "step: 3017\n",
            "loss: 52.20356369018555\n",
            "step: 3018\n",
            "loss: 37.733680725097656\n",
            "step: 3019\n",
            "loss: 54.1611328125\n",
            "step: 3020\n",
            "loss: 46.002166748046875\n",
            "step: 3021\n",
            "loss: 70.58609008789062\n",
            "step: 3022\n",
            "loss: 66.31497192382812\n",
            "step: 3023\n",
            "loss: 57.09840774536133\n",
            "step: 3024\n",
            "loss: 42.80744934082031\n",
            "step: 3025\n",
            "loss: 50.05583953857422\n",
            "step: 3026\n",
            "loss: 44.06072235107422\n",
            "step: 3027\n",
            "loss: 57.47500228881836\n",
            "step: 3028\n",
            "loss: 43.572181701660156\n",
            "step: 3029\n",
            "loss: 42.71717071533203\n",
            "step: 3030\n",
            "loss: 56.94198989868164\n",
            "step: 3031\n",
            "loss: 49.077980041503906\n",
            "step: 3032\n",
            "loss: 44.055755615234375\n",
            "step: 3033\n",
            "loss: 69.81507873535156\n",
            "step: 3034\n",
            "loss: 66.0849838256836\n",
            "step: 3035\n",
            "loss: 61.3754768371582\n",
            "step: 3036\n",
            "loss: 61.49565887451172\n",
            "step: 3037\n",
            "loss: 57.01310348510742\n",
            "step: 3038\n",
            "loss: 44.71332931518555\n",
            "step: 3039\n",
            "loss: 55.78271484375\n",
            "step: 3040\n",
            "loss: 62.87214660644531\n",
            "step: 3041\n",
            "loss: 58.47563552856445\n",
            "step: 3042\n",
            "loss: 71.04937744140625\n",
            "step: 3043\n",
            "loss: 55.96635818481445\n",
            "step: 3044\n",
            "loss: 66.44905090332031\n",
            "step: 3045\n",
            "loss: 44.57379913330078\n",
            "step: 3046\n",
            "loss: 29.515483856201172\n",
            "step: 3047\n",
            "loss: 41.20343780517578\n",
            "step: 3048\n",
            "loss: 51.12260055541992\n",
            "step: 3049\n",
            "loss: 60.861080169677734\n",
            "step: 3050\n",
            "loss: 54.706398010253906\n",
            "step: 3051\n",
            "loss: 54.50934600830078\n",
            "step: 3052\n",
            "loss: 33.70710754394531\n",
            "step: 3053\n",
            "loss: 60.81538009643555\n",
            "step: 3054\n",
            "loss: 41.508872985839844\n",
            "step: 3055\n",
            "loss: 82.94654846191406\n",
            "step: 3056\n",
            "loss: 40.174903869628906\n",
            "step: 3057\n",
            "loss: 51.70808410644531\n",
            "step: 3058\n",
            "loss: 66.45490264892578\n",
            "step: 3059\n",
            "loss: 51.252723693847656\n",
            "step: 3060\n",
            "loss: 49.8325080871582\n",
            "step: 3061\n",
            "loss: 75.5030517578125\n",
            "step: 3062\n",
            "loss: 56.36867141723633\n",
            "step: 3063\n",
            "loss: 64.82989501953125\n",
            "step: 3064\n",
            "loss: 64.92858123779297\n",
            "step: 3065\n",
            "loss: 44.59949493408203\n",
            "step: 3066\n",
            "loss: 63.67279052734375\n",
            "step: 3067\n",
            "loss: 66.07662963867188\n",
            "step: 3068\n",
            "loss: 56.46398162841797\n",
            "step: 3069\n",
            "loss: 52.98240661621094\n",
            "step: 3070\n",
            "loss: 58.046016693115234\n",
            "step: 3071\n",
            "loss: 65.08370971679688\n",
            "step: 3072\n",
            "loss: 44.428165435791016\n",
            "step: 3073\n",
            "loss: 64.2223892211914\n",
            "step: 3074\n",
            "loss: 49.0814094543457\n",
            "step: 3075\n",
            "loss: 37.647403717041016\n",
            "step: 3076\n",
            "loss: 63.08204650878906\n",
            "step: 3077\n",
            "loss: 62.65281677246094\n",
            "step: 3078\n",
            "loss: 49.88753890991211\n",
            "step: 3079\n",
            "loss: 53.46105194091797\n",
            "step: 3080\n",
            "loss: 59.146453857421875\n",
            "step: 3081\n",
            "loss: 49.251258850097656\n",
            "step: 3082\n",
            "loss: 51.82862854003906\n",
            "step: 3083\n",
            "loss: 48.07323455810547\n",
            "step: 3084\n",
            "loss: 46.946014404296875\n",
            "step: 3085\n",
            "loss: 73.38070678710938\n",
            "step: 3086\n",
            "loss: 55.105342864990234\n",
            "step: 3087\n",
            "loss: 55.21617889404297\n",
            "step: 3088\n",
            "loss: 58.209739685058594\n",
            "step: 3089\n",
            "loss: 46.65176010131836\n",
            "step: 3090\n",
            "loss: 44.312530517578125\n",
            "step: 3091\n",
            "loss: 47.685665130615234\n",
            "step: 3092\n",
            "loss: 68.00367736816406\n",
            "step: 3093\n",
            "loss: 82.94163513183594\n",
            "step: 3094\n",
            "loss: 81.81563568115234\n",
            "step: 3095\n",
            "loss: 44.964691162109375\n",
            "step: 3096\n",
            "loss: 65.96054077148438\n",
            "step: 3097\n",
            "loss: 64.42318725585938\n",
            "step: 3098\n",
            "loss: 46.87455749511719\n",
            "step: 3099\n",
            "loss: 54.21928405761719\n",
            "step: 3100\n",
            "loss: 66.78230285644531\n",
            "step: 3101\n",
            "loss: 41.28075408935547\n",
            "step: 3102\n",
            "loss: 64.65144348144531\n",
            "step: 3103\n",
            "loss: 47.1695556640625\n",
            "step: 3104\n",
            "loss: 61.48521423339844\n",
            "step: 3105\n",
            "loss: 58.60406494140625\n",
            "step: 3106\n",
            "loss: 68.31681060791016\n",
            "step: 3107\n",
            "loss: 74.97026062011719\n",
            "step: 3108\n",
            "loss: 64.99239349365234\n",
            "step: 3109\n",
            "loss: 66.1390380859375\n",
            "step: 3110\n",
            "loss: 40.190277099609375\n",
            "step: 3111\n",
            "loss: 69.5877685546875\n",
            "step: 3112\n",
            "loss: 44.46525573730469\n",
            "step: 3113\n",
            "loss: 49.235904693603516\n",
            "step: 3114\n",
            "loss: 66.36026000976562\n",
            "step: 3115\n",
            "loss: 62.432491302490234\n",
            "step: 3116\n",
            "loss: 58.50470733642578\n",
            "step: 3117\n",
            "loss: 67.35716247558594\n",
            "step: 3118\n",
            "loss: 79.8017578125\n",
            "step: 3119\n",
            "loss: 67.51922607421875\n",
            "step: 3120\n",
            "loss: 44.763160705566406\n",
            "step: 3121\n",
            "loss: 62.54823303222656\n",
            "step: 3122\n",
            "loss: 62.8578987121582\n",
            "step: 3123\n",
            "loss: 52.82240295410156\n",
            "step: 3124\n",
            "loss: 63.864776611328125\n",
            "step: 3125\n",
            "loss: 38.113243103027344\n",
            "step: 3126\n",
            "loss: 82.38578033447266\n",
            "step: 3127\n",
            "loss: 82.43440246582031\n",
            "step: 3128\n",
            "loss: 44.903648376464844\n",
            "step: 3129\n",
            "loss: 62.870853424072266\n",
            "step: 3130\n",
            "loss: 53.99310302734375\n",
            "step: 3131\n",
            "loss: 58.17574691772461\n",
            "step: 3132\n",
            "loss: 52.81543731689453\n",
            "step: 3133\n",
            "loss: 57.121761322021484\n",
            "step: 3134\n",
            "loss: 72.41627502441406\n",
            "step: 3135\n",
            "loss: 46.14223098754883\n",
            "step: 3136\n",
            "loss: 62.92586135864258\n",
            "step: 3137\n",
            "loss: 54.75490188598633\n",
            "step: 3138\n",
            "loss: 63.648895263671875\n",
            "step: 3139\n",
            "loss: 56.50337600708008\n",
            "step: 3140\n",
            "loss: 58.543819427490234\n",
            "step: 3141\n",
            "loss: 65.19477844238281\n",
            "step: 3142\n",
            "loss: 69.40254974365234\n",
            "step: 3143\n",
            "loss: 66.52091979980469\n",
            "step: 3144\n",
            "loss: 58.81568145751953\n",
            "step: 3145\n",
            "loss: 61.360572814941406\n",
            "step: 3146\n",
            "loss: 53.97633361816406\n",
            "step: 3147\n",
            "loss: 57.279991149902344\n",
            "step: 3148\n",
            "loss: 73.20655822753906\n",
            "step: 3149\n",
            "loss: 85.47612762451172\n",
            "step: 3150\n",
            "loss: 51.36663055419922\n",
            "step: 3151\n",
            "loss: 69.75105285644531\n",
            "step: 3152\n",
            "loss: 79.21626281738281\n",
            "step: 3153\n",
            "loss: 64.24345397949219\n",
            "step: 3154\n",
            "loss: 54.53839111328125\n",
            "step: 3155\n",
            "loss: 70.24386596679688\n",
            "step: 3156\n",
            "loss: 50.78465270996094\n",
            "step: 3157\n",
            "loss: 63.66215896606445\n",
            "step: 3158\n",
            "loss: 55.70811462402344\n",
            "step: 3159\n",
            "loss: 83.32270812988281\n",
            "step: 3160\n",
            "loss: 61.985809326171875\n",
            "step: 3161\n",
            "loss: 60.688602447509766\n",
            "step: 3162\n",
            "loss: 62.80194854736328\n",
            "step: 3163\n",
            "loss: 42.057167053222656\n",
            "step: 3164\n",
            "loss: 57.42378234863281\n",
            "step: 3165\n",
            "loss: 57.868896484375\n",
            "step: 3166\n",
            "loss: 50.622650146484375\n",
            "step: 3167\n",
            "loss: 38.840118408203125\n",
            "step: 3168\n",
            "loss: 60.24364471435547\n",
            "step: 3169\n",
            "loss: 57.284080505371094\n",
            "step: 3170\n",
            "loss: 57.28240966796875\n",
            "step: 3171\n",
            "loss: 31.89298439025879\n",
            "step: 3172\n",
            "loss: 63.807369232177734\n",
            "step: 3173\n",
            "loss: 60.780487060546875\n",
            "step: 3174\n",
            "loss: 62.84477996826172\n",
            "step: 3175\n",
            "loss: 59.94386291503906\n",
            "step: 3176\n",
            "loss: 69.68734741210938\n",
            "step: 3177\n",
            "loss: 55.899139404296875\n",
            "step: 3178\n",
            "loss: 59.04533004760742\n",
            "step: 3179\n",
            "loss: 53.01884078979492\n",
            "step: 3180\n",
            "loss: 70.85344696044922\n",
            "step: 3181\n",
            "loss: 49.95597839355469\n",
            "step: 3182\n",
            "loss: 59.11215591430664\n",
            "step: 3183\n",
            "loss: 47.44001770019531\n",
            "step: 3184\n",
            "loss: 37.1419677734375\n",
            "step: 3185\n",
            "loss: 75.06145477294922\n",
            "step: 3186\n",
            "loss: 50.78234100341797\n",
            "step: 3187\n",
            "loss: 65.55134582519531\n",
            "step: 3188\n",
            "loss: 69.27232360839844\n",
            "step: 3189\n",
            "loss: 74.08869171142578\n",
            "step: 3190\n",
            "loss: 77.88113403320312\n",
            "step: 3191\n",
            "loss: 50.645050048828125\n",
            "step: 3192\n",
            "loss: 53.34415817260742\n",
            "step: 3193\n",
            "loss: 57.767024993896484\n",
            "step: 3194\n",
            "loss: 45.594764709472656\n",
            "step: 3195\n",
            "loss: 87.30704498291016\n",
            "step: 3196\n",
            "loss: 64.8829574584961\n",
            "step: 3197\n",
            "loss: 51.667236328125\n",
            "step: 3198\n",
            "loss: 69.03623962402344\n",
            "step: 3199\n",
            "loss: 70.86033630371094\n",
            "step: 3200\n",
            "loss: 63.68254852294922\n",
            "step: 3201\n",
            "loss: 68.60039520263672\n",
            "step: 3202\n",
            "loss: 61.478763580322266\n",
            "step: 3203\n",
            "loss: 87.87982177734375\n",
            "step: 3204\n",
            "loss: 54.63458251953125\n",
            "step: 3205\n",
            "loss: 79.70775604248047\n",
            "step: 3206\n",
            "loss: 57.81679916381836\n",
            "step: 3207\n",
            "loss: 67.53927612304688\n",
            "step: 3208\n",
            "loss: 59.11906814575195\n",
            "step: 3209\n",
            "loss: 60.803993225097656\n",
            "step: 3210\n",
            "loss: 59.128231048583984\n",
            "step: 3211\n",
            "loss: 58.54659652709961\n",
            "step: 3212\n",
            "loss: 42.49065017700195\n",
            "step: 3213\n",
            "loss: 80.47318267822266\n",
            "step: 3214\n",
            "loss: 73.62850952148438\n",
            "step: 3215\n",
            "loss: 55.75339889526367\n",
            "step: 3216\n",
            "loss: 75.76017761230469\n",
            "step: 3217\n",
            "loss: 67.05381774902344\n",
            "step: 3218\n",
            "loss: 41.06636047363281\n",
            "step: 3219\n",
            "loss: 90.53466033935547\n",
            "step: 3220\n",
            "loss: 79.88995361328125\n",
            "step: 3221\n",
            "loss: 46.08931350708008\n",
            "step: 3222\n",
            "loss: 39.234352111816406\n",
            "step: 3223\n",
            "loss: 44.98326873779297\n",
            "step: 3224\n",
            "loss: 59.45465087890625\n",
            "step: 3225\n",
            "loss: 45.36501693725586\n",
            "step: 3226\n",
            "loss: 54.63022994995117\n",
            "step: 3227\n",
            "loss: 59.106197357177734\n",
            "step: 3228\n",
            "loss: 58.74652099609375\n",
            "step: 3229\n",
            "loss: 50.378746032714844\n",
            "step: 3230\n",
            "loss: 67.22396850585938\n",
            "step: 3231\n",
            "loss: 63.51536560058594\n",
            "step: 3232\n",
            "loss: 62.57543182373047\n",
            "step: 3233\n",
            "loss: 60.24443817138672\n",
            "step: 3234\n",
            "loss: 83.26399993896484\n",
            "step: 3235\n",
            "loss: 79.91004943847656\n",
            "step: 3236\n",
            "loss: 72.5611343383789\n",
            "step: 3237\n",
            "loss: 61.742958068847656\n",
            "step: 3238\n",
            "loss: 63.77695846557617\n",
            "step: 3239\n",
            "loss: 55.59107208251953\n",
            "step: 3240\n",
            "loss: 71.62835693359375\n",
            "step: 3241\n",
            "loss: 60.047969818115234\n",
            "step: 3242\n",
            "loss: 47.8297119140625\n",
            "step: 3243\n",
            "loss: 58.96758270263672\n",
            "step: 3244\n",
            "loss: 62.524051666259766\n",
            "step: 3245\n",
            "loss: 65.91817474365234\n",
            "step: 3246\n",
            "loss: 92.5458984375\n",
            "step: 3247\n",
            "loss: 60.38030242919922\n",
            "step: 3248\n",
            "loss: 49.544776916503906\n",
            "step: 3249\n",
            "loss: 48.447357177734375\n",
            "step: 3250\n",
            "loss: 59.580360412597656\n",
            "step: 3251\n",
            "loss: 47.73310852050781\n",
            "step: 3252\n",
            "loss: 32.683475494384766\n",
            "step: 3253\n",
            "loss: 58.89029312133789\n",
            "step: 3254\n",
            "loss: 58.06867980957031\n",
            "step: 3255\n",
            "loss: 36.84546661376953\n",
            "step: 3256\n",
            "loss: 48.57720947265625\n",
            "step: 3257\n",
            "loss: 40.38863754272461\n",
            "step: 3258\n",
            "loss: 46.85582733154297\n",
            "step: 3259\n",
            "loss: 47.317108154296875\n",
            "step: 3260\n",
            "loss: 63.140689849853516\n",
            "step: 3261\n",
            "loss: 59.54633331298828\n",
            "step: 3262\n",
            "loss: 57.64542007446289\n",
            "step: 3263\n",
            "loss: 39.89707946777344\n",
            "step: 3264\n",
            "loss: 55.44308090209961\n",
            "step: 3265\n",
            "loss: 55.23310852050781\n",
            "step: 3266\n",
            "loss: 31.43494987487793\n",
            "step: 3267\n",
            "loss: 46.237518310546875\n",
            "step: 3268\n",
            "loss: 55.03392791748047\n",
            "step: 3269\n",
            "loss: 54.88689041137695\n",
            "step: 3270\n",
            "loss: 67.45856475830078\n",
            "step: 3271\n",
            "loss: 47.39790344238281\n",
            "step: 3272\n",
            "loss: 40.02049255371094\n",
            "step: 3273\n",
            "loss: 81.28117370605469\n",
            "step: 3274\n",
            "loss: 59.62042236328125\n",
            "step: 3275\n",
            "loss: 56.33344268798828\n",
            "step: 3276\n",
            "loss: 66.82453918457031\n",
            "step: 3277\n",
            "loss: 59.696258544921875\n",
            "step: 3278\n",
            "loss: 50.098236083984375\n",
            "step: 3279\n",
            "loss: 53.29059600830078\n",
            "step: 3280\n",
            "loss: 76.62825012207031\n",
            "step: 3281\n",
            "loss: 73.89653015136719\n",
            "step: 3282\n",
            "loss: 62.239891052246094\n",
            "step: 3283\n",
            "loss: 48.554195404052734\n",
            "step: 3284\n",
            "loss: 42.77970504760742\n",
            "step: 3285\n",
            "loss: 66.11768341064453\n",
            "step: 3286\n",
            "loss: 60.133201599121094\n",
            "step: 3287\n",
            "loss: 39.80052947998047\n",
            "step: 3288\n",
            "loss: 32.90831756591797\n",
            "step: 3289\n",
            "loss: 53.035221099853516\n",
            "step: 3290\n",
            "loss: 35.4829216003418\n",
            "step: 3291\n",
            "loss: 58.5590934753418\n",
            "step: 3292\n",
            "loss: 50.66680145263672\n",
            "step: 3293\n",
            "loss: 57.0648078918457\n",
            "step: 3294\n",
            "loss: 45.42266082763672\n",
            "step: 3295\n",
            "loss: 37.552490234375\n",
            "step: 3296\n",
            "loss: 57.41516876220703\n",
            "step: 3297\n",
            "loss: 59.3385009765625\n",
            "step: 3298\n",
            "loss: 74.22520446777344\n",
            "step: 3299\n",
            "loss: 55.579261779785156\n",
            "step: 3300\n",
            "loss: 50.311805725097656\n",
            "step: 3301\n",
            "loss: 49.56641387939453\n",
            "step: 3302\n",
            "loss: 61.543479919433594\n",
            "step: 3303\n",
            "loss: 35.20613098144531\n",
            "step: 3304\n",
            "loss: 33.49225997924805\n",
            "step: 3305\n",
            "loss: 62.778202056884766\n",
            "step: 3306\n",
            "loss: 56.65211486816406\n",
            "step: 3307\n",
            "loss: 50.77055358886719\n",
            "step: 3308\n",
            "loss: 45.061859130859375\n",
            "step: 3309\n",
            "loss: 53.034263610839844\n",
            "step: 3310\n",
            "loss: 59.180946350097656\n",
            "step: 3311\n",
            "loss: 60.24052047729492\n",
            "step: 3312\n",
            "loss: 40.664024353027344\n",
            "step: 3313\n",
            "loss: 66.13400268554688\n",
            "step: 3314\n",
            "loss: 49.2452507019043\n",
            "step: 3315\n",
            "loss: 59.84138488769531\n",
            "step: 3316\n",
            "loss: 40.8455810546875\n",
            "step: 3317\n",
            "loss: 52.9936408996582\n",
            "step: 3318\n",
            "loss: 58.18549728393555\n",
            "step: 3319\n",
            "loss: 66.19721984863281\n",
            "step: 3320\n",
            "loss: 43.50929260253906\n",
            "step: 3321\n",
            "loss: 57.90831756591797\n",
            "step: 3322\n",
            "loss: 44.170387268066406\n",
            "step: 3323\n",
            "loss: 58.83538818359375\n",
            "step: 3324\n",
            "loss: 72.97612762451172\n",
            "step: 3325\n",
            "loss: 72.20179748535156\n",
            "step: 3326\n",
            "loss: 71.64842224121094\n",
            "step: 3327\n",
            "loss: 49.92510986328125\n",
            "step: 3328\n",
            "loss: 55.53252410888672\n",
            "step: 3329\n",
            "loss: 64.06026458740234\n",
            "step: 3330\n",
            "loss: 45.42136001586914\n",
            "step: 3331\n",
            "loss: 48.67048263549805\n",
            "step: 3332\n",
            "loss: 73.2237319946289\n",
            "step: 3333\n",
            "loss: 44.63916015625\n",
            "step: 3334\n",
            "loss: 50.2914924621582\n",
            "step: 3335\n",
            "loss: 56.875091552734375\n",
            "step: 3336\n",
            "loss: 42.02153396606445\n",
            "step: 3337\n",
            "loss: 51.21087646484375\n",
            "step: 3338\n",
            "loss: 49.836692810058594\n",
            "step: 3339\n",
            "loss: 51.45579528808594\n",
            "step: 3340\n",
            "loss: 57.44524383544922\n",
            "step: 3341\n",
            "loss: 42.84083557128906\n",
            "step: 3342\n",
            "loss: 61.76103591918945\n",
            "step: 3343\n",
            "loss: 59.490299224853516\n",
            "step: 3344\n",
            "loss: 38.818180084228516\n",
            "step: 3345\n",
            "loss: 53.950016021728516\n",
            "step: 3346\n",
            "loss: 56.646461486816406\n",
            "step: 3347\n",
            "loss: 55.30375671386719\n",
            "step: 3348\n",
            "loss: 42.17631149291992\n",
            "step: 3349\n",
            "loss: 57.90377426147461\n",
            "step: 3350\n",
            "loss: 57.6915168762207\n",
            "step: 3351\n",
            "loss: 38.93299865722656\n",
            "step: 3352\n",
            "loss: 51.52604675292969\n",
            "step: 3353\n",
            "loss: 62.50297927856445\n",
            "step: 3354\n",
            "loss: 57.506412506103516\n",
            "step: 3355\n",
            "loss: 41.94114685058594\n",
            "step: 3356\n",
            "loss: 36.164398193359375\n",
            "step: 3357\n",
            "loss: 86.66653442382812\n",
            "step: 3358\n",
            "loss: 45.167335510253906\n",
            "step: 3359\n",
            "loss: 51.26264953613281\n",
            "step: 3360\n",
            "loss: 58.09101104736328\n",
            "step: 3361\n",
            "loss: 58.60730743408203\n",
            "step: 3362\n",
            "loss: 90.37416076660156\n",
            "step: 3363\n",
            "loss: 50.876441955566406\n",
            "step: 3364\n",
            "loss: 53.59555435180664\n",
            "step: 3365\n",
            "loss: 56.22609329223633\n",
            "step: 3366\n",
            "loss: 51.0498161315918\n",
            "step: 3367\n",
            "loss: 83.67303466796875\n",
            "step: 3368\n",
            "loss: 51.23624801635742\n",
            "step: 3369\n",
            "loss: 64.97564697265625\n",
            "step: 3370\n",
            "loss: 80.71334838867188\n",
            "step: 3371\n",
            "loss: 56.504146575927734\n",
            "step: 3372\n",
            "loss: 43.328189849853516\n",
            "step: 3373\n",
            "loss: 68.13707733154297\n",
            "step: 3374\n",
            "loss: 47.19575500488281\n",
            "step: 3375\n",
            "loss: 70.84255981445312\n",
            "step: 3376\n",
            "loss: 44.55541229248047\n",
            "step: 3377\n",
            "loss: 59.25191879272461\n",
            "step: 3378\n",
            "loss: 60.01013946533203\n",
            "step: 3379\n",
            "loss: 53.55528259277344\n",
            "step: 3380\n",
            "loss: 43.531272888183594\n",
            "step: 3381\n",
            "loss: 38.33509063720703\n",
            "step: 3382\n",
            "loss: 58.58979797363281\n",
            "step: 3383\n",
            "loss: 81.06034851074219\n",
            "step: 3384\n",
            "loss: 73.01583099365234\n",
            "step: 3385\n",
            "loss: 70.00300598144531\n",
            "step: 3386\n",
            "loss: 45.20222473144531\n",
            "step: 3387\n",
            "loss: 82.7998046875\n",
            "step: 3388\n",
            "loss: 77.64248657226562\n",
            "step: 3389\n",
            "loss: 62.60491943359375\n",
            "step: 3390\n",
            "loss: 60.800071716308594\n",
            "step: 3391\n",
            "loss: 80.37844848632812\n",
            "step: 3392\n",
            "loss: 45.87478256225586\n",
            "step: 3393\n",
            "loss: 67.25741577148438\n",
            "step: 3394\n",
            "loss: 41.62802505493164\n",
            "step: 3395\n",
            "loss: 29.552799224853516\n",
            "step: 3396\n",
            "loss: 66.98931121826172\n",
            "step: 3397\n",
            "loss: 58.620391845703125\n",
            "step: 3398\n",
            "loss: 46.37203598022461\n",
            "step: 3399\n",
            "loss: 81.92408752441406\n",
            "step: 3400\n",
            "loss: 60.74332809448242\n",
            "step: 3401\n",
            "loss: 57.582801818847656\n",
            "step: 3402\n",
            "loss: 63.11994934082031\n",
            "step: 3403\n",
            "loss: 78.88993072509766\n",
            "step: 3404\n",
            "loss: 66.25764465332031\n",
            "step: 3405\n",
            "loss: 53.508888244628906\n",
            "step: 3406\n",
            "loss: 69.55131530761719\n",
            "step: 3407\n",
            "loss: 65.10904693603516\n",
            "step: 3408\n",
            "loss: 53.52284240722656\n",
            "step: 3409\n",
            "loss: 54.93885040283203\n",
            "step: 3410\n",
            "loss: 46.258277893066406\n",
            "step: 3411\n",
            "loss: 53.72855758666992\n",
            "step: 3412\n",
            "loss: 62.05264663696289\n",
            "step: 3413\n",
            "loss: 46.14099884033203\n",
            "step: 3414\n",
            "loss: 76.07862854003906\n",
            "step: 3415\n",
            "loss: 56.588531494140625\n",
            "step: 3416\n",
            "loss: 76.13694763183594\n",
            "step: 3417\n",
            "loss: 56.28038787841797\n",
            "step: 3418\n",
            "loss: 67.4339599609375\n",
            "step: 3419\n",
            "loss: 54.860206604003906\n",
            "step: 3420\n",
            "loss: 47.03495788574219\n",
            "step: 3421\n",
            "loss: 43.0494384765625\n",
            "step: 3422\n",
            "loss: 39.4964599609375\n",
            "step: 3423\n",
            "loss: 37.80567169189453\n",
            "step: 3424\n",
            "loss: 41.670921325683594\n",
            "step: 3425\n",
            "loss: 60.3389778137207\n",
            "step: 3426\n",
            "loss: 67.1480712890625\n",
            "step: 3427\n",
            "loss: 70.66233825683594\n",
            "step: 3428\n",
            "loss: 45.35470199584961\n",
            "step: 3429\n",
            "loss: 54.27246856689453\n",
            "step: 3430\n",
            "loss: 81.28441619873047\n",
            "step: 3431\n",
            "loss: 63.92720413208008\n",
            "step: 3432\n",
            "loss: 60.8342170715332\n",
            "step: 3433\n",
            "loss: 48.138458251953125\n",
            "step: 3434\n",
            "loss: 65.14424133300781\n",
            "step: 3435\n",
            "loss: 36.60221481323242\n",
            "step: 3436\n",
            "loss: 59.21626281738281\n",
            "step: 3437\n",
            "loss: 64.85240936279297\n",
            "step: 3438\n",
            "loss: 68.67168426513672\n",
            "step: 3439\n",
            "loss: 52.07869338989258\n",
            "step: 3440\n",
            "loss: 53.49723815917969\n",
            "step: 3441\n",
            "loss: 83.54420471191406\n",
            "step: 3442\n",
            "loss: 68.45039367675781\n",
            "step: 3443\n",
            "loss: 37.79358673095703\n",
            "step: 3444\n",
            "loss: 58.66527557373047\n",
            "step: 3445\n",
            "loss: 76.33396911621094\n",
            "step: 3446\n",
            "loss: 59.166831970214844\n",
            "step: 3447\n",
            "loss: 41.93589782714844\n",
            "step: 3448\n",
            "loss: 52.56736755371094\n",
            "step: 3449\n",
            "loss: 68.69772338867188\n",
            "step: 3450\n",
            "loss: 77.42720794677734\n",
            "step: 3451\n",
            "loss: 59.983978271484375\n",
            "step: 3452\n",
            "loss: 67.7619400024414\n",
            "step: 3453\n",
            "loss: 56.58177185058594\n",
            "step: 3454\n",
            "loss: 45.097373962402344\n",
            "step: 3455\n",
            "loss: 58.91651153564453\n",
            "step: 3456\n",
            "loss: 69.017822265625\n",
            "step: 3457\n",
            "loss: 50.44218444824219\n",
            "step: 3458\n",
            "loss: 61.40961837768555\n",
            "step: 3459\n",
            "loss: 79.3231201171875\n",
            "step: 3460\n",
            "loss: 70.17155456542969\n",
            "step: 3461\n",
            "loss: 78.67719268798828\n",
            "step: 3462\n",
            "loss: 40.69879150390625\n",
            "step: 3463\n",
            "loss: 59.42195510864258\n",
            "step: 3464\n",
            "loss: 73.11616516113281\n",
            "step: 3465\n",
            "loss: 69.31275939941406\n",
            "step: 3466\n",
            "loss: 62.20859146118164\n",
            "step: 3467\n",
            "loss: 56.327117919921875\n",
            "step: 3468\n",
            "loss: 35.478904724121094\n",
            "step: 3469\n",
            "loss: 61.86389923095703\n",
            "step: 3470\n",
            "loss: 53.119239807128906\n",
            "step: 3471\n",
            "loss: 64.23185729980469\n",
            "step: 3472\n",
            "loss: 50.039344787597656\n",
            "step: 3473\n",
            "loss: 67.21536254882812\n",
            "step: 3474\n",
            "loss: 69.56497955322266\n",
            "step: 3475\n",
            "loss: 71.57371520996094\n",
            "step: 3476\n",
            "loss: 35.9092903137207\n",
            "step: 3477\n",
            "loss: 70.05874633789062\n",
            "step: 3478\n",
            "loss: 60.41685485839844\n",
            "step: 3479\n",
            "loss: 68.80538940429688\n",
            "step: 3480\n",
            "loss: 35.765682220458984\n",
            "step: 3481\n",
            "loss: 49.559654235839844\n",
            "step: 3482\n",
            "loss: 49.51423645019531\n",
            "step: 3483\n",
            "loss: 49.02672576904297\n",
            "step: 3484\n",
            "loss: 55.724422454833984\n",
            "step: 3485\n",
            "loss: 57.33747863769531\n",
            "step: 3486\n",
            "loss: 59.55011749267578\n",
            "step: 3487\n",
            "loss: 45.1873664855957\n",
            "step: 3488\n",
            "loss: 63.70033264160156\n",
            "step: 3489\n",
            "loss: 58.331485748291016\n",
            "step: 3490\n",
            "loss: 40.533103942871094\n",
            "step: 3491\n",
            "loss: 41.6743278503418\n",
            "step: 3492\n",
            "loss: 46.62860107421875\n",
            "step: 3493\n",
            "loss: 45.85129165649414\n",
            "step: 3494\n",
            "loss: 47.485504150390625\n",
            "step: 3495\n",
            "loss: 59.309383392333984\n",
            "step: 3496\n",
            "loss: 56.428367614746094\n",
            "step: 3497\n",
            "loss: 58.382774353027344\n",
            "step: 3498\n",
            "loss: 59.34743118286133\n",
            "step: 3499\n",
            "loss: 65.845458984375\n",
            "step: 3500\n",
            "loss: 40.23335647583008\n",
            "step: 3501\n",
            "loss: 64.30076599121094\n",
            "step: 3502\n",
            "loss: 56.37415313720703\n",
            "step: 3503\n",
            "loss: 37.57098388671875\n",
            "step: 3504\n",
            "loss: 44.80038833618164\n",
            "step: 3505\n",
            "loss: 54.769920349121094\n",
            "step: 3506\n",
            "loss: 33.66022491455078\n",
            "step: 3507\n",
            "loss: 41.49773406982422\n",
            "step: 3508\n",
            "loss: 42.623470306396484\n",
            "step: 3509\n",
            "loss: 41.134986877441406\n",
            "step: 3510\n",
            "loss: 52.375789642333984\n",
            "step: 3511\n",
            "loss: 69.33616638183594\n",
            "step: 3512\n",
            "loss: 67.35852813720703\n",
            "step: 3513\n",
            "loss: 43.3316650390625\n",
            "step: 3514\n",
            "loss: 43.41807556152344\n",
            "step: 3515\n",
            "loss: 76.13551330566406\n",
            "step: 3516\n",
            "loss: 52.43905258178711\n",
            "step: 3517\n",
            "loss: 56.210391998291016\n",
            "step: 3518\n",
            "loss: 35.43461990356445\n",
            "step: 3519\n",
            "loss: 42.42228698730469\n",
            "step: 3520\n",
            "loss: 57.149383544921875\n",
            "step: 3521\n",
            "loss: 53.65534973144531\n",
            "step: 3522\n",
            "loss: 46.72459030151367\n",
            "step: 3523\n",
            "loss: 49.60169219970703\n",
            "step: 3524\n",
            "loss: 40.135826110839844\n",
            "step: 3525\n",
            "loss: 39.16363525390625\n",
            "step: 3526\n",
            "loss: 59.359832763671875\n",
            "step: 3527\n",
            "loss: 68.78500366210938\n",
            "step: 3528\n",
            "loss: 36.530311584472656\n",
            "step: 3529\n",
            "loss: 41.67112350463867\n",
            "step: 3530\n",
            "loss: 48.607032775878906\n",
            "step: 3531\n",
            "loss: 82.39053344726562\n",
            "step: 3532\n",
            "loss: 37.539161682128906\n",
            "step: 3533\n",
            "loss: 55.21095275878906\n",
            "step: 3534\n",
            "loss: 61.018375396728516\n",
            "step: 3535\n",
            "loss: 50.78491973876953\n",
            "step: 3536\n",
            "loss: 63.58605194091797\n",
            "step: 3537\n",
            "loss: 50.693946838378906\n",
            "step: 3538\n",
            "loss: 66.84912109375\n",
            "step: 3539\n",
            "loss: 42.95935821533203\n",
            "step: 3540\n",
            "loss: 35.86626052856445\n",
            "step: 3541\n",
            "loss: 51.29679870605469\n",
            "step: 3542\n",
            "loss: 76.75318908691406\n",
            "step: 3543\n",
            "loss: 42.320682525634766\n",
            "step: 3544\n",
            "loss: 36.03060531616211\n",
            "step: 3545\n",
            "loss: 53.89866256713867\n",
            "step: 3546\n",
            "loss: 44.935665130615234\n",
            "step: 3547\n",
            "loss: 56.391693115234375\n",
            "step: 3548\n",
            "loss: 45.17643737792969\n",
            "step: 3549\n",
            "loss: 50.53425979614258\n",
            "step: 3550\n",
            "loss: 31.795610427856445\n",
            "step: 3551\n",
            "loss: 77.44906616210938\n",
            "step: 3552\n",
            "loss: 52.50193786621094\n",
            "step: 3553\n",
            "loss: 53.73031997680664\n",
            "step: 3554\n",
            "loss: 65.10368347167969\n",
            "step: 3555\n",
            "loss: 47.65605545043945\n",
            "step: 3556\n",
            "loss: 45.603248596191406\n",
            "step: 3557\n",
            "loss: 58.70921325683594\n",
            "step: 3558\n",
            "loss: 58.53496551513672\n",
            "step: 3559\n",
            "loss: 49.51626968383789\n",
            "step: 3560\n",
            "loss: 38.52007293701172\n",
            "step: 3561\n",
            "loss: 55.84746551513672\n",
            "step: 3562\n",
            "loss: 47.96405792236328\n",
            "step: 3563\n",
            "loss: 51.052734375\n",
            "step: 3564\n",
            "loss: 48.042293548583984\n",
            "step: 3565\n",
            "loss: 35.4560546875\n",
            "step: 3566\n",
            "loss: 82.93583679199219\n",
            "step: 3567\n",
            "loss: 41.08979797363281\n",
            "step: 3568\n",
            "loss: 49.66707229614258\n",
            "step: 3569\n",
            "loss: 49.55475616455078\n",
            "step: 3570\n",
            "loss: 51.27735137939453\n",
            "step: 3571\n",
            "loss: 43.956092834472656\n",
            "step: 3572\n",
            "loss: 52.91118621826172\n",
            "step: 3573\n",
            "loss: 50.33002471923828\n",
            "step: 3574\n",
            "loss: 66.6844482421875\n",
            "step: 3575\n",
            "loss: 64.99751281738281\n",
            "step: 3576\n",
            "loss: 63.30193328857422\n",
            "step: 3577\n",
            "loss: 53.70397186279297\n",
            "step: 3578\n",
            "loss: 58.698150634765625\n",
            "step: 3579\n",
            "loss: 65.7940673828125\n",
            "step: 3580\n",
            "loss: 71.58847045898438\n",
            "step: 3581\n",
            "loss: 42.833106994628906\n",
            "step: 3582\n",
            "loss: 37.28578186035156\n",
            "step: 3583\n",
            "loss: 62.238834381103516\n",
            "step: 3584\n",
            "loss: 38.108680725097656\n",
            "step: 3585\n",
            "loss: 68.04978942871094\n",
            "step: 3586\n",
            "loss: 42.2515754699707\n",
            "step: 3587\n",
            "loss: 58.690185546875\n",
            "step: 3588\n",
            "loss: 48.8331298828125\n",
            "step: 3589\n",
            "loss: 41.21997833251953\n",
            "step: 3590\n",
            "loss: 34.040748596191406\n",
            "step: 3591\n",
            "loss: 48.86042022705078\n",
            "step: 3592\n",
            "loss: 76.44275665283203\n",
            "step: 3593\n",
            "loss: 51.85376739501953\n",
            "step: 3594\n",
            "loss: 68.2703628540039\n",
            "step: 3595\n",
            "loss: 74.66438293457031\n",
            "step: 3596\n",
            "loss: 42.63420867919922\n",
            "step: 3597\n",
            "loss: 58.90470504760742\n",
            "step: 3598\n",
            "loss: 54.453765869140625\n",
            "step: 3599\n",
            "loss: 51.36180114746094\n",
            "step: 3600\n",
            "loss: 36.9801025390625\n",
            "step: 3601\n",
            "loss: 59.95240020751953\n",
            "step: 3602\n",
            "loss: 46.10633087158203\n",
            "step: 3603\n",
            "loss: 45.14860534667969\n",
            "step: 3604\n",
            "loss: 82.74336242675781\n",
            "step: 3605\n",
            "loss: 35.076297760009766\n",
            "step: 3606\n",
            "loss: 69.40348815917969\n",
            "step: 3607\n",
            "loss: 49.10901641845703\n",
            "step: 3608\n",
            "loss: 63.73482894897461\n",
            "step: 3609\n",
            "loss: 51.100223541259766\n",
            "step: 3610\n",
            "loss: 51.53279495239258\n",
            "step: 3611\n",
            "loss: 75.7562255859375\n",
            "step: 3612\n",
            "loss: 46.24943542480469\n",
            "step: 3613\n",
            "loss: 55.870391845703125\n",
            "step: 3614\n",
            "loss: 53.68260955810547\n",
            "step: 3615\n",
            "loss: 62.894432067871094\n",
            "step: 3616\n",
            "loss: 49.347557067871094\n",
            "step: 3617\n",
            "loss: 64.62905883789062\n",
            "step: 3618\n",
            "loss: 50.183170318603516\n",
            "step: 3619\n",
            "loss: 58.30850601196289\n",
            "step: 3620\n",
            "loss: 44.166542053222656\n",
            "step: 3621\n",
            "loss: 69.670166015625\n",
            "step: 3622\n",
            "loss: 41.20026397705078\n",
            "step: 3623\n",
            "loss: 60.629051208496094\n",
            "step: 3624\n",
            "loss: 83.66116333007812\n",
            "step: 3625\n",
            "loss: 62.91795349121094\n",
            "step: 3626\n",
            "loss: 55.9542236328125\n",
            "step: 3627\n",
            "loss: 47.6041374206543\n",
            "step: 3628\n",
            "loss: 39.95335388183594\n",
            "step: 3629\n",
            "loss: 59.87451171875\n",
            "step: 3630\n",
            "loss: 50.60103225708008\n",
            "step: 3631\n",
            "loss: 91.9473648071289\n",
            "step: 3632\n",
            "loss: 57.3748893737793\n",
            "step: 3633\n",
            "loss: 49.007568359375\n",
            "step: 3634\n",
            "loss: 43.97272491455078\n",
            "step: 3635\n",
            "loss: 46.806644439697266\n",
            "step: 3636\n",
            "loss: 60.49862289428711\n",
            "step: 3637\n",
            "loss: 63.45008850097656\n",
            "step: 3638\n",
            "loss: 45.45189666748047\n",
            "step: 3639\n",
            "loss: 41.252113342285156\n",
            "step: 3640\n",
            "loss: 34.28704071044922\n",
            "step: 3641\n",
            "loss: 58.760826110839844\n",
            "step: 3642\n",
            "loss: 44.81782150268555\n",
            "step: 3643\n",
            "loss: 59.58370590209961\n",
            "step: 3644\n",
            "loss: 59.23255920410156\n",
            "step: 3645\n",
            "loss: 49.66437911987305\n",
            "step: 3646\n",
            "loss: 48.06741714477539\n",
            "step: 3647\n",
            "loss: 66.58404541015625\n",
            "step: 3648\n",
            "loss: 83.1919174194336\n",
            "step: 3649\n",
            "loss: 46.7099494934082\n",
            "step: 3650\n",
            "loss: 48.591880798339844\n",
            "step: 3651\n",
            "loss: 45.460289001464844\n",
            "step: 3652\n",
            "loss: 49.549949645996094\n",
            "step: 3653\n",
            "loss: 45.974056243896484\n",
            "step: 3654\n",
            "loss: 42.2890625\n",
            "step: 3655\n",
            "loss: 34.18511199951172\n",
            "step: 3656\n",
            "loss: 46.589603424072266\n",
            "step: 3657\n",
            "loss: 56.79447937011719\n",
            "step: 3658\n",
            "loss: 70.00869750976562\n",
            "step: 3659\n",
            "loss: 62.666969299316406\n",
            "step: 3660\n",
            "loss: 58.292335510253906\n",
            "step: 3661\n",
            "loss: 50.34020233154297\n",
            "step: 3662\n",
            "loss: 58.189239501953125\n",
            "step: 3663\n",
            "loss: 47.64637756347656\n",
            "step: 3664\n",
            "loss: 56.66618347167969\n",
            "step: 3665\n",
            "loss: 61.35904312133789\n",
            "step: 3666\n",
            "loss: 34.84758758544922\n",
            "step: 3667\n",
            "loss: 78.77437591552734\n",
            "step: 3668\n",
            "loss: 54.01707458496094\n",
            "step: 3669\n",
            "loss: 50.689064025878906\n",
            "step: 3670\n",
            "loss: 70.0362777709961\n",
            "step: 3671\n",
            "loss: 56.30203628540039\n",
            "step: 3672\n",
            "loss: 46.14216995239258\n",
            "step: 3673\n",
            "loss: 43.04048156738281\n",
            "step: 3674\n",
            "loss: 70.97415161132812\n",
            "step: 3675\n",
            "loss: 56.10017013549805\n",
            "step: 3676\n",
            "loss: 48.620323181152344\n",
            "step: 3677\n",
            "loss: 71.82087707519531\n",
            "step: 3678\n",
            "loss: 77.64802551269531\n",
            "step: 3679\n",
            "loss: 48.74970245361328\n",
            "step: 3680\n",
            "loss: 66.29496765136719\n",
            "step: 3681\n",
            "loss: 61.901649475097656\n",
            "step: 3682\n",
            "loss: 42.09211730957031\n",
            "step: 3683\n",
            "loss: 57.15196990966797\n",
            "step: 3684\n",
            "loss: 56.002906799316406\n",
            "step: 3685\n",
            "loss: 48.476715087890625\n",
            "step: 3686\n",
            "loss: 60.7752571105957\n",
            "step: 3687\n",
            "loss: 42.8318977355957\n",
            "step: 3688\n",
            "loss: 68.7817611694336\n",
            "step: 3689\n",
            "loss: 52.32371520996094\n",
            "step: 3690\n",
            "loss: 58.000083923339844\n",
            "step: 3691\n",
            "loss: 61.04454040527344\n",
            "step: 3692\n",
            "loss: 56.83958435058594\n",
            "step: 3693\n",
            "loss: 78.5343017578125\n",
            "step: 3694\n",
            "loss: 61.98163604736328\n",
            "step: 3695\n",
            "loss: 76.78237915039062\n",
            "step: 3696\n",
            "loss: 65.5784912109375\n",
            "step: 3697\n",
            "loss: 72.18798065185547\n",
            "step: 3698\n",
            "loss: 57.94917678833008\n",
            "step: 3699\n",
            "loss: 50.96186065673828\n",
            "step: 3700\n",
            "loss: 62.92632293701172\n",
            "step: 3701\n",
            "loss: 43.02790832519531\n",
            "step: 3702\n",
            "loss: 54.27062225341797\n",
            "step: 3703\n",
            "loss: 54.047996520996094\n",
            "step: 3704\n",
            "loss: 42.10662841796875\n",
            "step: 3705\n",
            "loss: 70.12266540527344\n",
            "step: 3706\n",
            "loss: 75.63529968261719\n",
            "step: 3707\n",
            "loss: 55.652626037597656\n",
            "step: 3708\n",
            "loss: 88.30674743652344\n",
            "step: 3709\n",
            "loss: 26.97175407409668\n",
            "step: 3710\n",
            "loss: 28.26182746887207\n",
            "step: 3711\n",
            "loss: 62.519256591796875\n",
            "step: 3712\n",
            "loss: 44.97111511230469\n",
            "step: 3713\n",
            "loss: 55.894142150878906\n",
            "step: 3714\n",
            "loss: 74.31874084472656\n",
            "step: 3715\n",
            "loss: 52.02195739746094\n",
            "step: 3716\n",
            "loss: 49.2011833190918\n",
            "step: 3717\n",
            "loss: 49.46483612060547\n",
            "step: 3718\n",
            "loss: 42.81074142456055\n",
            "step: 3719\n",
            "loss: 55.00360107421875\n",
            "step: 3720\n",
            "loss: 77.07742309570312\n",
            "step: 3721\n",
            "loss: 45.94053649902344\n",
            "step: 3722\n",
            "loss: 61.59507751464844\n",
            "step: 3723\n",
            "loss: 45.87421798706055\n",
            "step: 3724\n",
            "loss: 57.68940734863281\n",
            "step: 3725\n",
            "loss: 44.95232009887695\n",
            "step: 3726\n",
            "loss: 41.91115951538086\n",
            "step: 3727\n",
            "loss: 32.59085464477539\n",
            "step: 3728\n",
            "loss: 45.162017822265625\n",
            "step: 3729\n",
            "loss: 49.480621337890625\n",
            "step: 3730\n",
            "loss: 52.389163970947266\n",
            "step: 3731\n",
            "loss: 45.64725875854492\n",
            "step: 3732\n",
            "loss: 37.089927673339844\n",
            "step: 3733\n",
            "loss: 29.352622985839844\n",
            "step: 3734\n",
            "loss: 60.915321350097656\n",
            "step: 3735\n",
            "loss: 69.09642791748047\n",
            "step: 3736\n",
            "loss: 60.61592102050781\n",
            "step: 3737\n",
            "loss: 54.495269775390625\n",
            "step: 3738\n",
            "loss: 40.95454025268555\n",
            "step: 3739\n",
            "loss: 53.51019287109375\n",
            "step: 3740\n",
            "loss: 43.147037506103516\n",
            "step: 3741\n",
            "loss: 70.12818908691406\n",
            "step: 3742\n",
            "loss: 40.02206039428711\n",
            "step: 3743\n",
            "loss: 40.47367858886719\n",
            "step: 3744\n",
            "loss: 54.78896713256836\n",
            "step: 3745\n",
            "loss: 38.844722747802734\n",
            "step: 3746\n",
            "loss: 42.45283508300781\n",
            "step: 3747\n",
            "loss: 54.896724700927734\n",
            "step: 3748\n",
            "loss: 50.405784606933594\n",
            "step: 3749\n",
            "loss: 43.22930145263672\n",
            "step: 3750\n",
            "loss: 41.020111083984375\n",
            "step: 3751\n",
            "loss: 36.469154357910156\n",
            "step: 3752\n",
            "loss: 44.154232025146484\n",
            "step: 3753\n",
            "loss: 60.64514923095703\n",
            "step: 3754\n",
            "loss: 33.4588508605957\n",
            "step: 3755\n",
            "loss: 47.87799835205078\n",
            "step: 3756\n",
            "loss: 42.63333511352539\n",
            "step: 3757\n",
            "loss: 46.95606994628906\n",
            "step: 3758\n",
            "loss: 39.01251983642578\n",
            "step: 3759\n",
            "loss: 59.2081298828125\n",
            "step: 3760\n",
            "loss: 42.319480895996094\n",
            "step: 3761\n",
            "loss: 54.98424530029297\n",
            "step: 3762\n",
            "loss: 46.57421112060547\n",
            "step: 3763\n",
            "loss: 63.47705841064453\n",
            "step: 3764\n",
            "loss: 65.84646606445312\n",
            "step: 3765\n",
            "loss: 56.09988784790039\n",
            "step: 3766\n",
            "loss: 77.08856964111328\n",
            "step: 3767\n",
            "loss: 74.14544677734375\n",
            "step: 3768\n",
            "loss: 43.64201354980469\n",
            "step: 3769\n",
            "loss: 48.48617172241211\n",
            "step: 3770\n",
            "loss: 49.8189697265625\n",
            "step: 3771\n",
            "loss: 43.58174514770508\n",
            "step: 3772\n",
            "loss: 48.683616638183594\n",
            "step: 3773\n",
            "loss: 42.30961990356445\n",
            "step: 3774\n",
            "loss: 39.42706298828125\n",
            "step: 3775\n",
            "loss: 63.01829528808594\n",
            "step: 3776\n",
            "loss: 57.22686767578125\n",
            "step: 3777\n",
            "loss: 57.60982131958008\n",
            "step: 3778\n",
            "loss: 42.57316207885742\n",
            "step: 3779\n",
            "loss: 41.92493438720703\n",
            "step: 3780\n",
            "loss: 36.18267822265625\n",
            "step: 3781\n",
            "loss: 42.034488677978516\n",
            "step: 3782\n",
            "loss: 57.39257049560547\n",
            "step: 3783\n",
            "loss: 51.86997985839844\n",
            "step: 3784\n",
            "loss: 63.356903076171875\n",
            "step: 3785\n",
            "loss: 69.16859436035156\n",
            "step: 3786\n",
            "loss: 65.95303344726562\n",
            "step: 3787\n",
            "loss: 33.11254119873047\n",
            "step: 3788\n",
            "loss: 50.395263671875\n",
            "step: 3789\n",
            "loss: 65.65830993652344\n",
            "step: 3790\n",
            "loss: 44.71784210205078\n",
            "step: 3791\n",
            "loss: 68.35591125488281\n",
            "step: 3792\n",
            "loss: 50.953338623046875\n",
            "step: 3793\n",
            "loss: 58.57062911987305\n",
            "step: 3794\n",
            "loss: 39.269222259521484\n",
            "step: 3795\n",
            "loss: 77.76301574707031\n",
            "step: 3796\n",
            "loss: 41.51033020019531\n",
            "step: 3797\n",
            "loss: 37.3482666015625\n",
            "step: 3798\n",
            "loss: 44.58220672607422\n",
            "step: 3799\n",
            "loss: 35.08403778076172\n",
            "step: 3800\n",
            "loss: 56.47695541381836\n",
            "step: 3801\n",
            "loss: 47.65638732910156\n",
            "step: 3802\n",
            "loss: 49.37456512451172\n",
            "step: 3803\n",
            "loss: 61.80196762084961\n",
            "step: 3804\n",
            "loss: 49.89091491699219\n",
            "step: 3805\n",
            "loss: 64.466796875\n",
            "step: 3806\n",
            "loss: 50.95313262939453\n",
            "step: 3807\n",
            "loss: 32.69097900390625\n",
            "step: 3808\n",
            "loss: 35.46347427368164\n",
            "step: 3809\n",
            "loss: 59.0828971862793\n",
            "step: 3810\n",
            "loss: 38.027767181396484\n",
            "step: 3811\n",
            "loss: 29.861589431762695\n",
            "step: 3812\n",
            "loss: 29.37834930419922\n",
            "step: 3813\n",
            "loss: 64.7784652709961\n",
            "step: 3814\n",
            "loss: 48.396942138671875\n",
            "step: 3815\n",
            "loss: 60.35447692871094\n",
            "step: 3816\n",
            "loss: 62.496299743652344\n",
            "step: 3817\n",
            "loss: 37.56935119628906\n",
            "step: 3818\n",
            "loss: 54.004852294921875\n",
            "step: 3819\n",
            "loss: 42.67451477050781\n",
            "step: 3820\n",
            "loss: 33.322105407714844\n",
            "step: 3821\n",
            "loss: 63.66485595703125\n",
            "step: 3822\n",
            "loss: 54.86697006225586\n",
            "step: 3823\n",
            "loss: 42.812232971191406\n",
            "step: 3824\n",
            "loss: 50.45995330810547\n",
            "step: 3825\n",
            "loss: 64.640380859375\n",
            "step: 3826\n",
            "loss: 49.368167877197266\n",
            "step: 3827\n",
            "loss: 54.11077117919922\n",
            "step: 3828\n",
            "loss: 58.03504943847656\n",
            "step: 3829\n",
            "loss: 44.11103439331055\n",
            "step: 3830\n",
            "loss: 53.35771179199219\n",
            "step: 3831\n",
            "loss: 52.610755920410156\n",
            "step: 3832\n",
            "loss: 67.74527740478516\n",
            "step: 3833\n",
            "loss: 60.02335739135742\n",
            "step: 3834\n",
            "loss: 40.801822662353516\n",
            "step: 3835\n",
            "loss: 54.65102005004883\n",
            "step: 3836\n",
            "loss: 41.63138198852539\n",
            "step: 3837\n",
            "loss: 65.59058380126953\n",
            "step: 3838\n",
            "loss: 83.15626525878906\n",
            "step: 3839\n",
            "loss: 43.411014556884766\n",
            "step: 3840\n",
            "loss: 74.94096374511719\n",
            "step: 3841\n",
            "loss: 43.20086669921875\n",
            "step: 3842\n",
            "loss: 75.46399688720703\n",
            "step: 3843\n",
            "loss: 64.99849700927734\n",
            "step: 3844\n",
            "loss: 64.31116485595703\n",
            "step: 3845\n",
            "loss: 37.08904266357422\n",
            "step: 3846\n",
            "loss: 49.3826789855957\n",
            "step: 3847\n",
            "loss: 28.68575668334961\n",
            "step: 3848\n",
            "loss: 54.184844970703125\n",
            "step: 3849\n",
            "loss: 42.393272399902344\n",
            "step: 3850\n",
            "loss: 41.98234939575195\n",
            "step: 3851\n",
            "loss: 53.83163833618164\n",
            "step: 3852\n",
            "loss: 53.015682220458984\n",
            "step: 3853\n",
            "loss: 73.26699829101562\n",
            "step: 3854\n",
            "loss: 51.803260803222656\n",
            "step: 3855\n",
            "loss: 56.21769332885742\n",
            "step: 3856\n",
            "loss: 67.482177734375\n",
            "step: 3857\n",
            "loss: 63.79132843017578\n",
            "step: 3858\n",
            "loss: 74.83248901367188\n",
            "step: 3859\n",
            "loss: 67.32455444335938\n",
            "step: 3860\n",
            "loss: 36.985618591308594\n",
            "step: 3861\n",
            "loss: 51.037879943847656\n",
            "step: 3862\n",
            "loss: 40.525718688964844\n",
            "step: 3863\n",
            "loss: 67.00432586669922\n",
            "step: 3864\n",
            "loss: 64.84170532226562\n",
            "step: 3865\n",
            "loss: 43.79866027832031\n",
            "step: 3866\n",
            "loss: 43.68983459472656\n",
            "step: 3867\n",
            "loss: 75.33016967773438\n",
            "step: 3868\n",
            "loss: 65.85276794433594\n",
            "step: 3869\n",
            "loss: 44.4523811340332\n",
            "step: 3870\n",
            "loss: 50.20862579345703\n",
            "step: 3871\n",
            "loss: 49.75107955932617\n",
            "step: 3872\n",
            "loss: 64.30216979980469\n",
            "step: 3873\n",
            "loss: 60.14448547363281\n",
            "step: 3874\n",
            "loss: 36.71595764160156\n",
            "step: 3875\n",
            "loss: 69.10275268554688\n",
            "step: 3876\n",
            "loss: 34.2225227355957\n",
            "step: 3877\n",
            "loss: 63.42604446411133\n",
            "step: 3878\n",
            "loss: 32.80006790161133\n",
            "step: 3879\n",
            "loss: 70.65943908691406\n",
            "step: 3880\n",
            "loss: 71.41908264160156\n",
            "step: 3881\n",
            "loss: 57.07412338256836\n",
            "step: 3882\n",
            "loss: 44.158531188964844\n",
            "step: 3883\n",
            "loss: 55.269203186035156\n",
            "step: 3884\n",
            "loss: 64.31639862060547\n",
            "step: 3885\n",
            "loss: 51.1303596496582\n",
            "step: 3886\n",
            "loss: 61.97347640991211\n",
            "step: 3887\n",
            "loss: 58.145713806152344\n",
            "step: 3888\n",
            "loss: 57.71910858154297\n",
            "step: 3889\n",
            "loss: 75.40690612792969\n",
            "step: 3890\n",
            "loss: 55.48475646972656\n",
            "step: 3891\n",
            "loss: 65.96847534179688\n",
            "step: 3892\n",
            "loss: 48.156494140625\n",
            "step: 3893\n",
            "loss: 73.66512298583984\n",
            "step: 3894\n",
            "loss: 45.30666732788086\n",
            "step: 3895\n",
            "loss: 55.0362548828125\n",
            "step: 3896\n",
            "loss: 49.787628173828125\n",
            "step: 3897\n",
            "loss: 63.958946228027344\n",
            "step: 3898\n",
            "loss: 44.00713348388672\n",
            "step: 3899\n",
            "loss: 77.17823791503906\n",
            "step: 3900\n",
            "loss: 56.02407455444336\n",
            "step: 3901\n",
            "loss: 34.85798645019531\n",
            "step: 3902\n",
            "loss: 64.63997650146484\n",
            "step: 3903\n",
            "loss: 73.26536560058594\n",
            "step: 3904\n",
            "loss: 37.54205322265625\n",
            "step: 3905\n",
            "loss: 64.04238891601562\n",
            "step: 3906\n",
            "loss: 42.241519927978516\n",
            "step: 3907\n",
            "loss: 34.76499557495117\n",
            "step: 3908\n",
            "loss: 42.08940124511719\n",
            "step: 3909\n",
            "loss: 71.74725341796875\n",
            "step: 3910\n",
            "loss: 58.55424499511719\n",
            "step: 3911\n",
            "loss: 66.5467300415039\n",
            "step: 3912\n",
            "loss: 52.937896728515625\n",
            "step: 3913\n",
            "loss: 50.01457214355469\n",
            "step: 3914\n",
            "loss: 56.60784912109375\n",
            "step: 3915\n",
            "loss: 43.72118377685547\n",
            "step: 3916\n",
            "loss: 65.927001953125\n",
            "step: 3917\n",
            "loss: 51.425079345703125\n",
            "step: 3918\n",
            "loss: 58.615509033203125\n",
            "step: 3919\n",
            "loss: 63.8439826965332\n",
            "step: 3920\n",
            "loss: 59.61796569824219\n",
            "step: 3921\n",
            "loss: 48.00981903076172\n",
            "step: 3922\n",
            "loss: 49.36869812011719\n",
            "step: 3923\n",
            "loss: 37.57695770263672\n",
            "step: 3924\n",
            "loss: 63.39381408691406\n",
            "step: 3925\n",
            "loss: 53.11482238769531\n",
            "step: 3926\n",
            "loss: 65.49713897705078\n",
            "step: 3927\n",
            "loss: 51.19671630859375\n",
            "step: 3928\n",
            "loss: 56.01648712158203\n",
            "step: 3929\n",
            "loss: 45.736881256103516\n",
            "step: 3930\n",
            "loss: 62.40793991088867\n",
            "step: 3931\n",
            "loss: 77.49214935302734\n",
            "step: 3932\n",
            "loss: 47.94437789916992\n",
            "step: 3933\n",
            "loss: 67.64524841308594\n",
            "step: 3934\n",
            "loss: 35.44961166381836\n",
            "step: 3935\n",
            "loss: 31.25237464904785\n",
            "step: 3936\n",
            "loss: 35.209228515625\n",
            "step: 3937\n",
            "loss: 63.99974060058594\n",
            "step: 3938\n",
            "loss: 53.452117919921875\n",
            "step: 3939\n",
            "loss: 68.41263580322266\n",
            "step: 3940\n",
            "loss: 70.1084213256836\n",
            "step: 3941\n",
            "loss: 61.03247833251953\n",
            "step: 3942\n",
            "loss: 63.68252944946289\n",
            "step: 3943\n",
            "loss: 44.38445281982422\n",
            "step: 3944\n",
            "loss: 63.886566162109375\n",
            "step: 3945\n",
            "loss: 50.626808166503906\n",
            "step: 3946\n",
            "loss: 42.223690032958984\n",
            "step: 3947\n",
            "loss: 59.76902770996094\n",
            "step: 3948\n",
            "loss: 49.976348876953125\n",
            "step: 3949\n",
            "loss: 60.50396728515625\n",
            "step: 3950\n",
            "loss: 56.910518646240234\n",
            "step: 3951\n",
            "loss: 47.11082077026367\n",
            "step: 3952\n",
            "loss: 38.98423767089844\n",
            "step: 3953\n",
            "loss: 49.93850326538086\n",
            "step: 3954\n",
            "loss: 62.24824142456055\n",
            "step: 3955\n",
            "loss: 57.302024841308594\n",
            "step: 3956\n",
            "loss: 46.253536224365234\n",
            "step: 3957\n",
            "loss: 46.544647216796875\n",
            "step: 3958\n",
            "loss: 55.177555084228516\n",
            "step: 3959\n",
            "loss: 37.99543762207031\n",
            "step: 3960\n",
            "loss: 42.700233459472656\n",
            "step: 3961\n",
            "loss: 25.897953033447266\n",
            "step: 3962\n",
            "loss: 36.684486389160156\n",
            "step: 3963\n",
            "loss: 45.403358459472656\n",
            "step: 3964\n",
            "loss: 51.12913513183594\n",
            "step: 3965\n",
            "loss: 46.68879699707031\n",
            "step: 3966\n",
            "loss: 58.039955139160156\n",
            "step: 3967\n",
            "loss: 63.078880310058594\n",
            "step: 3968\n",
            "loss: 36.26776123046875\n",
            "step: 3969\n",
            "loss: 53.23207473754883\n",
            "step: 3970\n",
            "loss: 25.018218994140625\n",
            "step: 3971\n",
            "loss: 30.203691482543945\n",
            "step: 3972\n",
            "loss: 35.295413970947266\n",
            "step: 3973\n",
            "loss: 48.673316955566406\n",
            "step: 3974\n",
            "loss: 39.27775573730469\n",
            "step: 3975\n",
            "loss: 70.69607543945312\n",
            "step: 3976\n",
            "loss: 65.95227813720703\n",
            "step: 3977\n",
            "loss: 38.94465637207031\n",
            "step: 3978\n",
            "loss: 51.3531608581543\n",
            "step: 3979\n",
            "loss: 59.555076599121094\n",
            "step: 3980\n",
            "loss: 49.555519104003906\n",
            "step: 3981\n",
            "loss: 50.444602966308594\n",
            "step: 3982\n",
            "loss: 35.287818908691406\n",
            "step: 3983\n",
            "loss: 44.59318923950195\n",
            "step: 3984\n",
            "loss: 47.41314697265625\n",
            "step: 3985\n",
            "loss: 54.37250518798828\n",
            "step: 3986\n",
            "loss: 68.27391052246094\n",
            "step: 3987\n",
            "loss: 36.305843353271484\n",
            "step: 3988\n",
            "loss: 75.89102172851562\n",
            "step: 3989\n",
            "loss: 31.992385864257812\n",
            "step: 3990\n",
            "loss: 37.5560188293457\n",
            "step: 3991\n",
            "loss: 36.0966911315918\n",
            "step: 3992\n",
            "loss: 36.86402130126953\n",
            "step: 3993\n",
            "loss: 47.745174407958984\n",
            "step: 3994\n",
            "loss: 36.37244415283203\n",
            "step: 3995\n",
            "loss: 39.58000183105469\n",
            "step: 3996\n",
            "loss: 39.67082977294922\n",
            "step: 3997\n",
            "loss: 57.55113220214844\n",
            "step: 3998\n",
            "loss: 35.97153091430664\n",
            "step: 3999\n",
            "loss: 76.85371398925781\n",
            "step: 4000\n",
            "loss: 61.66217041015625\n",
            "step: 4001\n",
            "loss: 30.597095489501953\n",
            "step: 4002\n",
            "loss: 49.219539642333984\n",
            "step: 4003\n",
            "loss: 47.083641052246094\n",
            "step: 4004\n",
            "loss: 45.57642364501953\n",
            "step: 4005\n",
            "loss: 56.00841522216797\n",
            "step: 4006\n",
            "loss: 50.74470520019531\n",
            "step: 4007\n",
            "loss: 32.67796325683594\n",
            "step: 4008\n",
            "loss: 58.96123504638672\n",
            "step: 4009\n",
            "loss: 45.667335510253906\n",
            "step: 4010\n",
            "loss: 46.624786376953125\n",
            "step: 4011\n",
            "loss: 43.50767517089844\n",
            "step: 4012\n",
            "loss: 59.08580780029297\n",
            "step: 4013\n",
            "loss: 42.65008544921875\n",
            "step: 4014\n",
            "loss: 54.44725036621094\n",
            "step: 4015\n",
            "loss: 41.158660888671875\n",
            "step: 4016\n",
            "loss: 54.33916473388672\n",
            "step: 4017\n",
            "loss: 45.4986457824707\n",
            "step: 4018\n",
            "loss: 44.4537353515625\n",
            "step: 4019\n",
            "loss: 58.869503021240234\n",
            "step: 4020\n",
            "loss: 42.28874206542969\n",
            "step: 4021\n",
            "loss: 66.80231475830078\n",
            "step: 4022\n",
            "loss: 46.92962646484375\n",
            "step: 4023\n",
            "loss: 51.788780212402344\n",
            "step: 4024\n",
            "loss: 55.006568908691406\n",
            "step: 4025\n",
            "loss: 38.80126953125\n",
            "step: 4026\n",
            "loss: 60.592185974121094\n",
            "step: 4027\n",
            "loss: 53.99367904663086\n",
            "step: 4028\n",
            "loss: 38.14663314819336\n",
            "step: 4029\n",
            "loss: 39.476966857910156\n",
            "step: 4030\n",
            "loss: 42.34342956542969\n",
            "step: 4031\n",
            "loss: 60.21393966674805\n",
            "step: 4032\n",
            "loss: 40.61309814453125\n",
            "step: 4033\n",
            "loss: 39.86913299560547\n",
            "step: 4034\n",
            "loss: 74.41581726074219\n",
            "step: 4035\n",
            "loss: 62.19329071044922\n",
            "step: 4036\n",
            "loss: 53.730010986328125\n",
            "step: 4037\n",
            "loss: 41.951759338378906\n",
            "step: 4038\n",
            "loss: 49.97642135620117\n",
            "step: 4039\n",
            "loss: 66.65308380126953\n",
            "step: 4040\n",
            "loss: 70.72103881835938\n",
            "step: 4041\n",
            "loss: 46.828250885009766\n",
            "step: 4042\n",
            "loss: 54.4097900390625\n",
            "step: 4043\n",
            "loss: 55.97212219238281\n",
            "step: 4044\n",
            "loss: 37.51036071777344\n",
            "step: 4045\n",
            "loss: 46.60663986206055\n",
            "step: 4046\n",
            "loss: 31.820083618164062\n",
            "step: 4047\n",
            "loss: 63.08432388305664\n",
            "step: 4048\n",
            "loss: 56.94751739501953\n",
            "step: 4049\n",
            "loss: 46.484161376953125\n",
            "step: 4050\n",
            "loss: 39.74317169189453\n",
            "step: 4051\n",
            "loss: 45.02831268310547\n",
            "step: 4052\n",
            "loss: 41.26804733276367\n",
            "step: 4053\n",
            "loss: 40.535953521728516\n",
            "step: 4054\n",
            "loss: 55.305240631103516\n",
            "step: 4055\n",
            "loss: 60.41725158691406\n",
            "step: 4056\n",
            "loss: 57.59107208251953\n",
            "step: 4057\n",
            "loss: 49.40302276611328\n",
            "step: 4058\n",
            "loss: 56.809871673583984\n",
            "step: 4059\n",
            "loss: 41.444801330566406\n",
            "step: 4060\n",
            "loss: 36.03828430175781\n",
            "step: 4061\n",
            "loss: 57.513465881347656\n",
            "step: 4062\n",
            "loss: 59.39399337768555\n",
            "step: 4063\n",
            "loss: 38.383827209472656\n",
            "step: 4064\n",
            "loss: 69.46623229980469\n",
            "step: 4065\n",
            "loss: 46.56025314331055\n",
            "step: 4066\n",
            "loss: 57.141136169433594\n",
            "step: 4067\n",
            "loss: 44.3597297668457\n",
            "step: 4068\n",
            "loss: 37.68031692504883\n",
            "step: 4069\n",
            "loss: 39.691593170166016\n",
            "step: 4070\n",
            "loss: 57.323020935058594\n",
            "step: 4071\n",
            "loss: 49.8635139465332\n",
            "step: 4072\n",
            "loss: 40.38824462890625\n",
            "step: 4073\n",
            "loss: 46.61150360107422\n",
            "step: 4074\n",
            "loss: 49.6553840637207\n",
            "step: 4075\n",
            "loss: 54.210655212402344\n",
            "step: 4076\n",
            "loss: 40.74503707885742\n",
            "step: 4077\n",
            "loss: 51.717002868652344\n",
            "step: 4078\n",
            "loss: 45.243621826171875\n",
            "step: 4079\n",
            "loss: 53.08601379394531\n",
            "step: 4080\n",
            "loss: 71.68476104736328\n",
            "step: 4081\n",
            "loss: 53.19623565673828\n",
            "step: 4082\n",
            "loss: 54.9223747253418\n",
            "step: 4083\n",
            "loss: 29.891353607177734\n",
            "step: 4084\n",
            "loss: 44.025333404541016\n",
            "step: 4085\n",
            "loss: 51.89073944091797\n",
            "step: 4086\n",
            "loss: 60.30973434448242\n",
            "step: 4087\n",
            "loss: 71.93035888671875\n",
            "step: 4088\n",
            "loss: 42.40900421142578\n",
            "step: 4089\n",
            "loss: 64.56829833984375\n",
            "step: 4090\n",
            "loss: 52.9300537109375\n",
            "step: 4091\n",
            "loss: 40.780845642089844\n",
            "step: 4092\n",
            "loss: 42.45783615112305\n",
            "step: 4093\n",
            "loss: 72.77326965332031\n",
            "step: 4094\n",
            "loss: 46.16722106933594\n",
            "step: 4095\n",
            "loss: 56.52661895751953\n",
            "step: 4096\n",
            "loss: 55.185848236083984\n",
            "step: 4097\n",
            "loss: 53.92523193359375\n",
            "step: 4098\n",
            "loss: 41.533233642578125\n",
            "step: 4099\n",
            "loss: 57.587303161621094\n",
            "step: 4100\n",
            "loss: 39.511810302734375\n",
            "step: 4101\n",
            "loss: 60.94078063964844\n",
            "step: 4102\n",
            "loss: 45.624900817871094\n",
            "step: 4103\n",
            "loss: 58.36412048339844\n",
            "step: 4104\n",
            "loss: 39.79887771606445\n",
            "step: 4105\n",
            "loss: 49.93563461303711\n",
            "step: 4106\n",
            "loss: 38.235023498535156\n",
            "step: 4107\n",
            "loss: 65.4274673461914\n",
            "step: 4108\n",
            "loss: 64.93736267089844\n",
            "step: 4109\n",
            "loss: 61.55532455444336\n",
            "step: 4110\n",
            "loss: 69.75802612304688\n",
            "step: 4111\n",
            "loss: 56.52664566040039\n",
            "step: 4112\n",
            "loss: 45.61286163330078\n",
            "step: 4113\n",
            "loss: 52.92759704589844\n",
            "step: 4114\n",
            "loss: 58.056846618652344\n",
            "step: 4115\n",
            "loss: 52.54252243041992\n",
            "step: 4116\n",
            "loss: 42.19822692871094\n",
            "step: 4117\n",
            "loss: 60.537391662597656\n",
            "step: 4118\n",
            "loss: 49.33828353881836\n",
            "step: 4119\n",
            "loss: 56.911808013916016\n",
            "step: 4120\n",
            "loss: 38.79070281982422\n",
            "step: 4121\n",
            "loss: 61.97882080078125\n",
            "step: 4122\n",
            "loss: 52.20824432373047\n",
            "step: 4123\n",
            "loss: 49.64315414428711\n",
            "step: 4124\n",
            "loss: 36.65052795410156\n",
            "step: 4125\n",
            "loss: 34.139747619628906\n",
            "step: 4126\n",
            "loss: 39.26972198486328\n",
            "step: 4127\n",
            "loss: 70.69241333007812\n",
            "step: 4128\n",
            "loss: 65.48251342773438\n",
            "step: 4129\n",
            "loss: 55.09416961669922\n",
            "step: 4130\n",
            "loss: 48.64236831665039\n",
            "step: 4131\n",
            "loss: 58.05046463012695\n",
            "step: 4132\n",
            "loss: 59.32585906982422\n",
            "step: 4133\n",
            "loss: 64.41136169433594\n",
            "step: 4134\n",
            "loss: 48.2652587890625\n",
            "step: 4135\n",
            "loss: 73.8006362915039\n",
            "step: 4136\n",
            "loss: 67.20039367675781\n",
            "step: 4137\n",
            "loss: 40.48529815673828\n",
            "step: 4138\n",
            "loss: 57.72026824951172\n",
            "step: 4139\n",
            "loss: 46.06791687011719\n",
            "step: 4140\n",
            "loss: 51.576507568359375\n",
            "step: 4141\n",
            "loss: 51.010589599609375\n",
            "step: 4142\n",
            "loss: 37.120914459228516\n",
            "step: 4143\n",
            "loss: 45.40409851074219\n",
            "step: 4144\n",
            "loss: 75.75180053710938\n",
            "step: 4145\n",
            "loss: 54.80013656616211\n",
            "step: 4146\n",
            "loss: 40.23622512817383\n",
            "step: 4147\n",
            "loss: 55.607635498046875\n",
            "step: 4148\n",
            "loss: 105.6611328125\n",
            "step: 4149\n",
            "loss: 67.53602600097656\n",
            "step: 4150\n",
            "loss: 47.82347106933594\n",
            "step: 4151\n",
            "loss: 39.55924987792969\n",
            "step: 4152\n",
            "loss: 57.98045349121094\n",
            "step: 4153\n",
            "loss: 39.139129638671875\n",
            "step: 4154\n",
            "loss: 31.234474182128906\n",
            "step: 4155\n",
            "loss: 43.38185501098633\n",
            "step: 4156\n",
            "loss: 54.362125396728516\n",
            "step: 4157\n",
            "loss: 73.50450897216797\n",
            "step: 4158\n",
            "loss: 61.500213623046875\n",
            "step: 4159\n",
            "loss: 40.11048126220703\n",
            "step: 4160\n",
            "loss: 60.61256408691406\n",
            "step: 4161\n",
            "loss: 52.05427551269531\n",
            "step: 4162\n",
            "loss: 76.49475860595703\n",
            "step: 4163\n",
            "loss: 52.07592010498047\n",
            "step: 4164\n",
            "loss: 57.32593536376953\n",
            "step: 4165\n",
            "loss: 34.22309112548828\n",
            "step: 4166\n",
            "loss: 65.91227722167969\n",
            "step: 4167\n",
            "loss: 54.72467803955078\n",
            "step: 4168\n",
            "loss: 42.69874954223633\n",
            "step: 4169\n",
            "loss: 70.64273834228516\n",
            "step: 4170\n",
            "loss: 50.58183288574219\n",
            "step: 4171\n",
            "loss: 50.24665069580078\n",
            "step: 4172\n",
            "loss: 77.11494445800781\n",
            "step: 4173\n",
            "loss: 34.91926574707031\n",
            "step: 4174\n",
            "loss: 56.0015983581543\n",
            "step: 4175\n",
            "loss: 37.48528289794922\n",
            "step: 4176\n",
            "loss: 61.596717834472656\n",
            "step: 4177\n",
            "loss: 60.606197357177734\n",
            "step: 4178\n",
            "loss: 41.08460235595703\n",
            "step: 4179\n",
            "loss: 44.51388931274414\n",
            "step: 4180\n",
            "loss: 63.131202697753906\n",
            "step: 4181\n",
            "loss: 47.37696075439453\n",
            "step: 4182\n",
            "loss: 39.5450439453125\n",
            "step: 4183\n",
            "loss: 54.882991790771484\n",
            "step: 4184\n",
            "loss: 44.066009521484375\n",
            "step: 4185\n",
            "loss: 46.06598663330078\n",
            "step: 4186\n",
            "loss: 49.72123718261719\n",
            "step: 4187\n",
            "loss: 40.719200134277344\n",
            "step: 4188\n",
            "loss: 41.24249267578125\n",
            "step: 4189\n",
            "loss: 28.92487144470215\n",
            "step: 4190\n",
            "loss: 60.020599365234375\n",
            "step: 4191\n",
            "loss: 53.55847930908203\n",
            "step: 4192\n",
            "loss: 46.4306640625\n",
            "step: 4193\n",
            "loss: 65.29993438720703\n",
            "step: 4194\n",
            "loss: 30.40149688720703\n",
            "step: 4195\n",
            "loss: 54.10483169555664\n",
            "step: 4196\n",
            "loss: 43.36005401611328\n",
            "step: 4197\n",
            "loss: 53.79338073730469\n",
            "step: 4198\n",
            "loss: 51.224185943603516\n",
            "step: 4199\n",
            "loss: 55.98140335083008\n",
            "step: 4200\n",
            "loss: 32.10328674316406\n",
            "step: 4201\n",
            "loss: 40.382728576660156\n",
            "step: 4202\n",
            "loss: 44.66277313232422\n",
            "step: 4203\n",
            "loss: 48.653419494628906\n",
            "step: 4204\n",
            "loss: 41.69652557373047\n",
            "step: 4205\n",
            "loss: 85.5201187133789\n",
            "step: 4206\n",
            "loss: 45.184818267822266\n",
            "step: 4207\n",
            "loss: 38.18214797973633\n",
            "step: 4208\n",
            "loss: 50.06504440307617\n",
            "step: 4209\n",
            "loss: 64.97201538085938\n",
            "step: 4210\n",
            "loss: 32.01337814331055\n",
            "step: 4211\n",
            "loss: 51.896522521972656\n",
            "step: 4212\n",
            "loss: 49.034881591796875\n",
            "step: 4213\n",
            "loss: 43.35182571411133\n",
            "step: 4214\n",
            "loss: 65.8501205444336\n",
            "step: 4215\n",
            "loss: 29.2574405670166\n",
            "step: 4216\n",
            "loss: 45.480934143066406\n",
            "step: 4217\n",
            "loss: 40.89561462402344\n",
            "step: 4218\n",
            "loss: 45.346946716308594\n",
            "step: 4219\n",
            "loss: 43.98667907714844\n",
            "step: 4220\n",
            "loss: 40.89753341674805\n",
            "step: 4221\n",
            "loss: 37.05864715576172\n",
            "step: 4222\n",
            "loss: 43.91951370239258\n",
            "step: 4223\n",
            "loss: 43.20957946777344\n",
            "step: 4224\n",
            "loss: 68.86248016357422\n",
            "step: 4225\n",
            "loss: 42.73698425292969\n",
            "step: 4226\n",
            "loss: 54.65302276611328\n",
            "step: 4227\n",
            "loss: 51.68766784667969\n",
            "step: 4228\n",
            "loss: 30.026947021484375\n",
            "step: 4229\n",
            "loss: 30.91546630859375\n",
            "step: 4230\n",
            "loss: 44.18564987182617\n",
            "step: 4231\n",
            "loss: 29.70831298828125\n",
            "step: 4232\n",
            "loss: 45.314109802246094\n",
            "step: 4233\n",
            "loss: 59.971473693847656\n",
            "step: 4234\n",
            "loss: 50.028839111328125\n",
            "step: 4235\n",
            "loss: 39.23967742919922\n",
            "step: 4236\n",
            "loss: 45.75482940673828\n",
            "step: 4237\n",
            "loss: 41.1716194152832\n",
            "step: 4238\n",
            "loss: 50.83618927001953\n",
            "step: 4239\n",
            "loss: 59.39165496826172\n",
            "step: 4240\n",
            "loss: 56.356956481933594\n",
            "step: 4241\n",
            "loss: 47.84510040283203\n",
            "step: 4242\n",
            "loss: 44.31977462768555\n",
            "step: 4243\n",
            "loss: 44.97052001953125\n",
            "step: 4244\n",
            "loss: 38.212257385253906\n",
            "step: 4245\n",
            "loss: 43.81640625\n",
            "step: 4246\n",
            "loss: 37.84135437011719\n",
            "step: 4247\n",
            "loss: 36.525386810302734\n",
            "step: 4248\n",
            "loss: 43.22031784057617\n",
            "step: 4249\n",
            "loss: 28.843036651611328\n",
            "step: 4250\n",
            "loss: 35.42064666748047\n",
            "step: 4251\n",
            "loss: 54.82859420776367\n",
            "step: 4252\n",
            "loss: 49.49266052246094\n",
            "step: 4253\n",
            "loss: 50.03530502319336\n",
            "step: 4254\n",
            "loss: 61.88560485839844\n",
            "step: 4255\n",
            "loss: 35.2822265625\n",
            "step: 4256\n",
            "loss: 53.74073028564453\n",
            "step: 4257\n",
            "loss: 31.081886291503906\n",
            "step: 4258\n",
            "loss: 40.03645324707031\n",
            "step: 4259\n",
            "loss: 49.459259033203125\n",
            "step: 4260\n",
            "loss: 58.74903869628906\n",
            "step: 4261\n",
            "loss: 38.44206237792969\n",
            "step: 4262\n",
            "loss: 59.402488708496094\n",
            "step: 4263\n",
            "loss: 54.9344482421875\n",
            "step: 4264\n",
            "loss: 58.89471435546875\n",
            "step: 4265\n",
            "loss: 49.28263473510742\n",
            "step: 4266\n",
            "loss: 67.03861999511719\n",
            "step: 4267\n",
            "loss: 57.03599548339844\n",
            "step: 4268\n",
            "loss: 42.75463104248047\n",
            "step: 4269\n",
            "loss: 44.85630798339844\n",
            "step: 4270\n",
            "loss: 36.02550506591797\n",
            "step: 4271\n",
            "loss: 68.82270812988281\n",
            "step: 4272\n",
            "loss: 41.18165588378906\n",
            "step: 4273\n",
            "loss: 29.566242218017578\n",
            "step: 4274\n",
            "loss: 56.97264099121094\n",
            "step: 4275\n",
            "loss: 43.37408447265625\n",
            "step: 4276\n",
            "loss: 39.47429656982422\n",
            "step: 4277\n",
            "loss: 46.142372131347656\n",
            "step: 4278\n",
            "loss: 43.47225570678711\n",
            "step: 4279\n",
            "loss: 46.61018371582031\n",
            "step: 4280\n",
            "loss: 35.680763244628906\n",
            "step: 4281\n",
            "loss: 42.247615814208984\n",
            "step: 4282\n",
            "loss: 63.674278259277344\n",
            "step: 4283\n",
            "loss: 55.203208923339844\n",
            "step: 4284\n",
            "loss: 54.76146697998047\n",
            "step: 4285\n",
            "loss: 46.74143981933594\n",
            "step: 4286\n",
            "loss: 47.67683410644531\n",
            "step: 4287\n",
            "loss: 46.65320587158203\n",
            "step: 4288\n",
            "loss: 57.468318939208984\n",
            "step: 4289\n",
            "loss: 93.51434326171875\n",
            "step: 4290\n",
            "loss: 40.4349365234375\n",
            "step: 4291\n",
            "loss: 46.982421875\n",
            "step: 4292\n",
            "loss: 51.06071853637695\n",
            "step: 4293\n",
            "loss: 21.69130516052246\n",
            "step: 4294\n",
            "loss: 65.79183197021484\n",
            "step: 4295\n",
            "loss: 32.9141960144043\n",
            "step: 4296\n",
            "loss: 50.57915496826172\n",
            "step: 4297\n",
            "loss: 45.636688232421875\n",
            "step: 4298\n",
            "loss: 33.971832275390625\n",
            "step: 4299\n",
            "loss: 33.56586456298828\n",
            "step: 4300\n",
            "loss: 37.96342086791992\n",
            "step: 4301\n",
            "loss: 62.288822174072266\n",
            "step: 4302\n",
            "loss: 46.7890510559082\n",
            "step: 4303\n",
            "loss: 51.78410339355469\n",
            "step: 4304\n",
            "loss: 40.68541717529297\n",
            "step: 4305\n",
            "loss: 70.5718002319336\n",
            "step: 4306\n",
            "loss: 52.57009506225586\n",
            "step: 4307\n",
            "loss: 53.59484100341797\n",
            "step: 4308\n",
            "loss: 57.80982971191406\n",
            "step: 4309\n",
            "loss: 43.94139862060547\n",
            "step: 4310\n",
            "loss: 50.033546447753906\n",
            "step: 4311\n",
            "loss: 63.736976623535156\n",
            "step: 4312\n",
            "loss: 66.31170654296875\n",
            "step: 4313\n",
            "loss: 42.43898010253906\n",
            "step: 4314\n",
            "loss: 53.522926330566406\n",
            "step: 4315\n",
            "loss: 48.37458038330078\n",
            "step: 4316\n",
            "loss: 44.94762420654297\n",
            "step: 4317\n",
            "loss: 63.72032928466797\n",
            "step: 4318\n",
            "loss: 48.55669403076172\n",
            "step: 4319\n",
            "loss: 43.87324523925781\n",
            "step: 4320\n",
            "loss: 53.47093200683594\n",
            "step: 4321\n",
            "loss: 34.131614685058594\n",
            "step: 4322\n",
            "loss: 56.852359771728516\n",
            "step: 4323\n",
            "loss: 62.34326934814453\n",
            "step: 4324\n",
            "loss: 42.46188735961914\n",
            "step: 4325\n",
            "loss: 56.95003890991211\n",
            "step: 4326\n",
            "loss: 50.81871032714844\n",
            "step: 4327\n",
            "loss: 46.7862663269043\n",
            "step: 4328\n",
            "loss: 73.29609680175781\n",
            "step: 4329\n",
            "loss: 56.8643913269043\n",
            "step: 4330\n",
            "loss: 60.76555252075195\n",
            "step: 4331\n",
            "loss: 54.72505569458008\n",
            "step: 4332\n",
            "loss: 44.72727966308594\n",
            "step: 4333\n",
            "loss: 33.156951904296875\n",
            "step: 4334\n",
            "loss: 64.8150863647461\n",
            "step: 4335\n",
            "loss: 37.50977325439453\n",
            "step: 4336\n",
            "loss: 34.05778503417969\n",
            "step: 4337\n",
            "loss: 51.44147491455078\n",
            "step: 4338\n",
            "loss: 52.51848220825195\n",
            "step: 4339\n",
            "loss: 55.36790466308594\n",
            "step: 4340\n",
            "loss: 44.83848190307617\n",
            "step: 4341\n",
            "loss: 52.61558532714844\n",
            "step: 4342\n",
            "loss: 51.446571350097656\n",
            "step: 4343\n",
            "loss: 40.155982971191406\n",
            "step: 4344\n",
            "loss: 38.47615051269531\n",
            "step: 4345\n",
            "loss: 35.24639129638672\n",
            "step: 4346\n",
            "loss: 82.51736450195312\n",
            "step: 4347\n",
            "loss: 36.763946533203125\n",
            "step: 4348\n",
            "loss: 56.948333740234375\n",
            "step: 4349\n",
            "loss: 50.30780029296875\n",
            "step: 4350\n",
            "loss: 45.39146041870117\n",
            "step: 4351\n",
            "loss: 51.525856018066406\n",
            "step: 4352\n",
            "loss: 56.3388671875\n",
            "step: 4353\n",
            "loss: 54.834861755371094\n",
            "step: 4354\n",
            "loss: 26.203845977783203\n",
            "step: 4355\n",
            "loss: 46.85585403442383\n",
            "step: 4356\n",
            "loss: 43.96782302856445\n",
            "step: 4357\n",
            "loss: 45.184356689453125\n",
            "step: 4358\n",
            "loss: 69.08232116699219\n",
            "step: 4359\n",
            "loss: 55.82167053222656\n",
            "step: 4360\n",
            "loss: 49.42752456665039\n",
            "step: 4361\n",
            "loss: 58.37150192260742\n",
            "step: 4362\n",
            "loss: 52.268287658691406\n",
            "step: 4363\n",
            "loss: 55.11792755126953\n",
            "step: 4364\n",
            "loss: 60.74114990234375\n",
            "step: 4365\n",
            "loss: 51.61137390136719\n",
            "step: 4366\n",
            "loss: 55.29758071899414\n",
            "step: 4367\n",
            "loss: 40.16395568847656\n",
            "step: 4368\n",
            "loss: 44.94765853881836\n",
            "step: 4369\n",
            "loss: 55.464691162109375\n",
            "step: 4370\n",
            "loss: 51.881019592285156\n",
            "step: 4371\n",
            "loss: 48.37474060058594\n",
            "step: 4372\n",
            "loss: 52.28176498413086\n",
            "step: 4373\n",
            "loss: 46.20054244995117\n",
            "step: 4374\n",
            "loss: 59.15468215942383\n",
            "step: 4375\n",
            "loss: 65.53120422363281\n",
            "step: 4376\n",
            "loss: 65.74148559570312\n",
            "step: 4377\n",
            "loss: 46.14972686767578\n",
            "step: 4378\n",
            "loss: 49.723854064941406\n",
            "step: 4379\n",
            "loss: 49.454288482666016\n",
            "step: 4380\n",
            "loss: 56.481842041015625\n",
            "step: 4381\n",
            "loss: 69.79640197753906\n",
            "step: 4382\n",
            "loss: 50.056026458740234\n",
            "step: 4383\n",
            "loss: 44.083641052246094\n",
            "step: 4384\n",
            "loss: 48.75558853149414\n",
            "step: 4385\n",
            "loss: 40.803916931152344\n",
            "step: 4386\n",
            "loss: 65.60882568359375\n",
            "step: 4387\n",
            "loss: 41.1301155090332\n",
            "step: 4388\n",
            "loss: 39.43150329589844\n",
            "step: 4389\n",
            "loss: 56.90796661376953\n",
            "step: 4390\n",
            "loss: 46.082969665527344\n",
            "step: 4391\n",
            "loss: 76.62879943847656\n",
            "step: 4392\n",
            "loss: 51.21506881713867\n",
            "step: 4393\n",
            "loss: 59.47808074951172\n",
            "step: 4394\n",
            "loss: 47.802459716796875\n",
            "step: 4395\n",
            "loss: 55.97779083251953\n",
            "step: 4396\n",
            "loss: 42.47688293457031\n",
            "step: 4397\n",
            "loss: 59.62255096435547\n",
            "step: 4398\n",
            "loss: 59.18678283691406\n",
            "step: 4399\n",
            "loss: 64.44110107421875\n",
            "step: 4400\n",
            "loss: 34.49647521972656\n",
            "step: 4401\n",
            "loss: 50.588157653808594\n",
            "step: 4402\n",
            "loss: 67.16252899169922\n",
            "step: 4403\n",
            "loss: 33.976261138916016\n",
            "step: 4404\n",
            "loss: 46.162071228027344\n",
            "step: 4405\n",
            "loss: 49.15630340576172\n",
            "step: 4406\n",
            "loss: 71.14396667480469\n",
            "step: 4407\n",
            "loss: 48.469810485839844\n",
            "step: 4408\n",
            "loss: 57.731964111328125\n",
            "step: 4409\n",
            "loss: 66.4551010131836\n",
            "step: 4410\n",
            "loss: 60.69920349121094\n",
            "step: 4411\n",
            "loss: 55.03774642944336\n",
            "step: 4412\n",
            "loss: 53.575653076171875\n",
            "step: 4413\n",
            "loss: 65.82820892333984\n",
            "step: 4414\n",
            "loss: 44.04163360595703\n",
            "step: 4415\n",
            "loss: 39.783348083496094\n",
            "step: 4416\n",
            "loss: 51.48637008666992\n",
            "step: 4417\n",
            "loss: 39.747779846191406\n",
            "step: 4418\n",
            "loss: 26.723773956298828\n",
            "step: 4419\n",
            "loss: 48.569061279296875\n",
            "step: 4420\n",
            "loss: 40.15547180175781\n",
            "step: 4421\n",
            "loss: 38.62559509277344\n",
            "step: 4422\n",
            "loss: 62.06663513183594\n",
            "step: 4423\n",
            "loss: 42.7427864074707\n",
            "step: 4424\n",
            "loss: 46.985755920410156\n",
            "step: 4425\n",
            "loss: 43.946250915527344\n",
            "step: 4426\n",
            "loss: 46.89128494262695\n",
            "step: 4427\n",
            "loss: 34.63024139404297\n",
            "step: 4428\n",
            "loss: 42.07916259765625\n",
            "step: 4429\n",
            "loss: 35.24609375\n",
            "step: 4430\n",
            "loss: 41.048583984375\n",
            "step: 4431\n",
            "loss: 43.009002685546875\n",
            "step: 4432\n",
            "loss: 37.36979293823242\n",
            "step: 4433\n",
            "loss: 44.461605072021484\n",
            "step: 4434\n",
            "loss: 36.330352783203125\n",
            "step: 4435\n",
            "loss: 52.78815460205078\n",
            "step: 4436\n",
            "loss: 53.764488220214844\n",
            "step: 4437\n",
            "loss: 63.38067626953125\n",
            "step: 4438\n",
            "loss: 52.60358428955078\n",
            "step: 4439\n",
            "loss: 36.377723693847656\n",
            "step: 4440\n",
            "loss: 29.19647979736328\n",
            "step: 4441\n",
            "loss: 39.216148376464844\n",
            "step: 4442\n",
            "loss: 36.304115295410156\n",
            "step: 4443\n",
            "loss: 33.547332763671875\n",
            "step: 4444\n",
            "loss: 17.809329986572266\n",
            "step: 4445\n",
            "loss: 31.247539520263672\n",
            "step: 4446\n",
            "loss: 42.150840759277344\n",
            "step: 4447\n",
            "loss: 51.60017395019531\n",
            "step: 4448\n",
            "loss: 34.974632263183594\n",
            "step: 4449\n",
            "loss: 33.026329040527344\n",
            "step: 4450\n",
            "loss: 53.04084777832031\n",
            "step: 4451\n",
            "loss: 54.1300048828125\n",
            "step: 4452\n",
            "loss: 44.513431549072266\n",
            "step: 4453\n",
            "loss: 50.23313903808594\n",
            "step: 4454\n",
            "loss: 38.33163070678711\n",
            "step: 4455\n",
            "loss: 49.34131622314453\n",
            "step: 4456\n",
            "loss: 65.227294921875\n",
            "step: 4457\n",
            "loss: 45.01140213012695\n",
            "step: 4458\n",
            "loss: 55.24945831298828\n",
            "step: 4459\n",
            "loss: 75.41885375976562\n",
            "step: 4460\n",
            "loss: 40.000755310058594\n",
            "step: 4461\n",
            "loss: 30.60114288330078\n",
            "step: 4462\n",
            "loss: 33.90215301513672\n",
            "step: 4463\n",
            "loss: 37.03630828857422\n",
            "step: 4464\n",
            "loss: 41.396636962890625\n",
            "step: 4465\n",
            "loss: 44.736961364746094\n",
            "step: 4466\n",
            "loss: 57.13051986694336\n",
            "step: 4467\n",
            "loss: 53.12670135498047\n",
            "step: 4468\n",
            "loss: 35.404354095458984\n",
            "step: 4469\n",
            "loss: 41.86744689941406\n",
            "step: 4470\n",
            "loss: 48.19994354248047\n",
            "step: 4471\n",
            "loss: 39.60662841796875\n",
            "step: 4472\n",
            "loss: 45.36174774169922\n",
            "step: 4473\n",
            "loss: 55.40733337402344\n",
            "step: 4474\n",
            "loss: 37.566410064697266\n",
            "step: 4475\n",
            "loss: 43.79130554199219\n",
            "step: 4476\n",
            "loss: 57.46418762207031\n",
            "step: 4477\n",
            "loss: 51.01552200317383\n",
            "step: 4478\n",
            "loss: 27.887847900390625\n",
            "step: 4479\n",
            "loss: 29.02469825744629\n",
            "step: 4480\n",
            "loss: 44.57433319091797\n",
            "step: 4481\n",
            "loss: 34.09196472167969\n",
            "step: 4482\n",
            "loss: 36.87477111816406\n",
            "step: 4483\n",
            "loss: 68.96700286865234\n",
            "step: 4484\n",
            "loss: 28.054729461669922\n",
            "step: 4485\n",
            "loss: 52.585933685302734\n",
            "step: 4486\n",
            "loss: 44.139381408691406\n",
            "step: 4487\n",
            "loss: 66.09455871582031\n",
            "step: 4488\n",
            "loss: 48.974510192871094\n",
            "step: 4489\n",
            "loss: 31.545886993408203\n",
            "step: 4490\n",
            "loss: 38.454498291015625\n",
            "step: 4491\n",
            "loss: 53.28013610839844\n",
            "step: 4492\n",
            "loss: 47.25165557861328\n",
            "step: 4493\n",
            "loss: 57.15114212036133\n",
            "step: 4494\n",
            "loss: 56.62574005126953\n",
            "step: 4495\n",
            "loss: 47.999916076660156\n",
            "step: 4496\n",
            "loss: 66.42555236816406\n",
            "step: 4497\n",
            "loss: 42.766761779785156\n",
            "step: 4498\n",
            "loss: 54.825050354003906\n",
            "step: 4499\n",
            "loss: 52.531494140625\n",
            "step: 4500\n",
            "loss: 51.85622787475586\n",
            "step: 4501\n",
            "loss: 39.73415756225586\n",
            "step: 4502\n",
            "loss: 42.932533264160156\n",
            "step: 4503\n",
            "loss: 34.292606353759766\n",
            "step: 4504\n",
            "loss: 34.00490951538086\n",
            "step: 4505\n",
            "loss: 34.40315246582031\n",
            "step: 4506\n",
            "loss: 66.60635375976562\n",
            "step: 4507\n",
            "loss: 37.94696807861328\n",
            "step: 4508\n",
            "loss: 36.9211311340332\n",
            "step: 4509\n",
            "loss: 55.124534606933594\n",
            "step: 4510\n",
            "loss: 47.88816833496094\n",
            "step: 4511\n",
            "loss: 47.981964111328125\n",
            "step: 4512\n",
            "loss: 44.87941360473633\n",
            "step: 4513\n",
            "loss: 39.350486755371094\n",
            "step: 4514\n",
            "loss: 49.2794075012207\n",
            "step: 4515\n",
            "loss: 36.88788604736328\n",
            "step: 4516\n",
            "loss: 55.03641128540039\n",
            "step: 4517\n",
            "loss: 23.96586799621582\n",
            "step: 4518\n",
            "loss: 56.007354736328125\n",
            "step: 4519\n",
            "loss: 53.759185791015625\n",
            "step: 4520\n",
            "loss: 47.097930908203125\n",
            "step: 4521\n",
            "loss: 41.901580810546875\n",
            "step: 4522\n",
            "loss: 26.486499786376953\n",
            "step: 4523\n",
            "loss: 47.694854736328125\n",
            "step: 4524\n",
            "loss: 52.594234466552734\n",
            "step: 4525\n",
            "loss: 41.88787841796875\n",
            "step: 4526\n",
            "loss: 63.6470832824707\n",
            "step: 4527\n",
            "loss: 53.375221252441406\n",
            "step: 4528\n",
            "loss: 45.41759490966797\n",
            "step: 4529\n",
            "loss: 75.1865234375\n",
            "step: 4530\n",
            "loss: 34.249061584472656\n",
            "step: 4531\n",
            "loss: 41.037681579589844\n",
            "step: 4532\n",
            "loss: 50.46282196044922\n",
            "step: 4533\n",
            "loss: 67.4801025390625\n",
            "step: 4534\n",
            "loss: 48.599082946777344\n",
            "step: 4535\n",
            "loss: 53.77483367919922\n",
            "step: 4536\n",
            "loss: 40.03837585449219\n",
            "step: 4537\n",
            "loss: 50.00729751586914\n",
            "step: 4538\n",
            "loss: 48.50730895996094\n",
            "step: 4539\n",
            "loss: 33.39456558227539\n",
            "step: 4540\n",
            "loss: 38.03564453125\n",
            "step: 4541\n",
            "loss: 59.62297058105469\n",
            "step: 4542\n",
            "loss: 48.66834259033203\n",
            "step: 4543\n",
            "loss: 40.31987762451172\n",
            "step: 4544\n",
            "loss: 69.3472900390625\n",
            "step: 4545\n",
            "loss: 47.541748046875\n",
            "step: 4546\n",
            "loss: 48.479740142822266\n",
            "step: 4547\n",
            "loss: 39.39643096923828\n",
            "step: 4548\n",
            "loss: 49.88302230834961\n",
            "step: 4549\n",
            "loss: 68.65536499023438\n",
            "step: 4550\n",
            "loss: 35.91027069091797\n",
            "step: 4551\n",
            "loss: 57.51971435546875\n",
            "step: 4552\n",
            "loss: 59.910133361816406\n",
            "step: 4553\n",
            "loss: 63.687416076660156\n",
            "step: 4554\n",
            "loss: 39.094268798828125\n",
            "step: 4555\n",
            "loss: 28.323122024536133\n",
            "step: 4556\n",
            "loss: 58.34706497192383\n",
            "step: 4557\n",
            "loss: 52.29016876220703\n",
            "step: 4558\n",
            "loss: 64.3586196899414\n",
            "step: 4559\n",
            "loss: 22.173717498779297\n",
            "step: 4560\n",
            "loss: 46.87698745727539\n",
            "step: 4561\n",
            "loss: 55.857086181640625\n",
            "step: 4562\n",
            "loss: 51.79417419433594\n",
            "step: 4563\n",
            "loss: 52.223876953125\n",
            "step: 4564\n",
            "loss: 38.07884979248047\n",
            "step: 4565\n",
            "loss: 55.5556755065918\n",
            "step: 4566\n",
            "loss: 46.64734649658203\n",
            "step: 4567\n",
            "loss: 49.127376556396484\n",
            "step: 4568\n",
            "loss: 45.12476348876953\n",
            "step: 4569\n",
            "loss: 84.87871551513672\n",
            "step: 4570\n",
            "loss: 48.2381591796875\n",
            "step: 4571\n",
            "loss: 31.063289642333984\n",
            "step: 4572\n",
            "loss: 63.067718505859375\n",
            "step: 4573\n",
            "loss: 29.708621978759766\n",
            "step: 4574\n",
            "loss: 72.4033432006836\n",
            "step: 4575\n",
            "loss: 77.72407531738281\n",
            "step: 4576\n",
            "loss: 45.99058151245117\n",
            "step: 4577\n",
            "loss: 53.375431060791016\n",
            "step: 4578\n",
            "loss: 83.61506652832031\n",
            "step: 4579\n",
            "loss: 33.03289031982422\n",
            "step: 4580\n",
            "loss: 37.427696228027344\n",
            "step: 4581\n",
            "loss: 47.712669372558594\n",
            "step: 4582\n",
            "loss: 51.78045654296875\n",
            "step: 4583\n",
            "loss: 50.17561340332031\n",
            "step: 4584\n",
            "loss: 61.07063293457031\n",
            "step: 4585\n",
            "loss: 48.24877166748047\n",
            "step: 4586\n",
            "loss: 61.022891998291016\n",
            "step: 4587\n",
            "loss: 51.56367111206055\n",
            "step: 4588\n",
            "loss: 43.36288070678711\n",
            "step: 4589\n",
            "loss: 39.65328598022461\n",
            "step: 4590\n",
            "loss: 43.539283752441406\n",
            "step: 4591\n",
            "loss: 74.25057983398438\n",
            "step: 4592\n",
            "loss: 28.34572410583496\n",
            "step: 4593\n",
            "loss: 46.08692932128906\n",
            "step: 4594\n",
            "loss: 50.95609664916992\n",
            "step: 4595\n",
            "loss: 38.31269836425781\n",
            "step: 4596\n",
            "loss: 23.98224639892578\n",
            "step: 4597\n",
            "loss: 56.44647979736328\n",
            "step: 4598\n",
            "loss: 35.92024612426758\n",
            "step: 4599\n",
            "loss: 42.978824615478516\n",
            "step: 4600\n",
            "loss: 47.512386322021484\n",
            "step: 4601\n",
            "loss: 59.42486572265625\n",
            "step: 4602\n",
            "loss: 47.22695541381836\n",
            "step: 4603\n",
            "loss: 48.6351318359375\n",
            "step: 4604\n",
            "loss: 43.883392333984375\n",
            "step: 4605\n",
            "loss: 44.47611999511719\n",
            "step: 4606\n",
            "loss: 47.922786712646484\n",
            "step: 4607\n",
            "loss: 63.56024932861328\n",
            "step: 4608\n",
            "loss: 35.311798095703125\n",
            "step: 4609\n",
            "loss: 55.33604431152344\n",
            "step: 4610\n",
            "loss: 52.41100311279297\n",
            "step: 4611\n",
            "loss: 33.93634033203125\n",
            "step: 4612\n",
            "loss: 66.26539611816406\n",
            "step: 4613\n",
            "loss: 42.468292236328125\n",
            "step: 4614\n",
            "loss: 55.0278434753418\n",
            "step: 4615\n",
            "loss: 56.39417266845703\n",
            "step: 4616\n",
            "loss: 66.66517639160156\n",
            "step: 4617\n",
            "loss: 58.606903076171875\n",
            "step: 4618\n",
            "loss: 52.2412223815918\n",
            "step: 4619\n",
            "loss: 59.53715896606445\n",
            "step: 4620\n",
            "loss: 35.691680908203125\n",
            "step: 4621\n",
            "loss: 48.599853515625\n",
            "step: 4622\n",
            "loss: 30.920394897460938\n",
            "step: 4623\n",
            "loss: 43.85162353515625\n",
            "step: 4624\n",
            "loss: 41.88669204711914\n",
            "step: 4625\n",
            "loss: 62.080238342285156\n",
            "step: 4626\n",
            "loss: 42.36952209472656\n",
            "step: 4627\n",
            "loss: 44.249778747558594\n",
            "step: 4628\n",
            "loss: 47.88359832763672\n",
            "step: 4629\n",
            "loss: 39.69050979614258\n",
            "step: 4630\n",
            "loss: 52.258445739746094\n",
            "step: 4631\n",
            "loss: 47.65596008300781\n",
            "step: 4632\n",
            "loss: 33.219295501708984\n",
            "step: 4633\n",
            "loss: 59.542198181152344\n",
            "step: 4634\n",
            "loss: 41.89905548095703\n",
            "step: 4635\n",
            "loss: 47.479576110839844\n",
            "step: 4636\n",
            "loss: 32.260047912597656\n",
            "step: 4637\n",
            "loss: 47.26756286621094\n",
            "step: 4638\n",
            "loss: 29.90802001953125\n",
            "step: 4639\n",
            "loss: 49.929386138916016\n",
            "step: 4640\n",
            "loss: 56.72819900512695\n",
            "step: 4641\n",
            "loss: 67.21732330322266\n",
            "step: 4642\n",
            "loss: 63.191619873046875\n",
            "step: 4643\n",
            "loss: 45.08588790893555\n",
            "step: 4644\n",
            "loss: 44.222286224365234\n",
            "step: 4645\n",
            "loss: 45.66154479980469\n",
            "step: 4646\n",
            "loss: 48.99775695800781\n",
            "step: 4647\n",
            "loss: 55.55099868774414\n",
            "step: 4648\n",
            "loss: 31.270029067993164\n",
            "step: 4649\n",
            "loss: 47.23561477661133\n",
            "step: 4650\n",
            "loss: 41.86183547973633\n",
            "step: 4651\n",
            "loss: 109.78337860107422\n",
            "step: 4652\n",
            "loss: 46.89677429199219\n",
            "step: 4653\n",
            "loss: 39.93419647216797\n",
            "step: 4654\n",
            "loss: 65.95331573486328\n",
            "step: 4655\n",
            "loss: 58.343448638916016\n",
            "step: 4656\n",
            "loss: 48.61109924316406\n",
            "step: 4657\n",
            "loss: 45.00468444824219\n",
            "step: 4658\n",
            "loss: 35.027870178222656\n",
            "step: 4659\n",
            "loss: 41.817527770996094\n",
            "step: 4660\n",
            "loss: 35.438053131103516\n",
            "step: 4661\n",
            "loss: 39.4100227355957\n",
            "step: 4662\n",
            "loss: 43.137046813964844\n",
            "step: 4663\n",
            "loss: 46.09881591796875\n",
            "step: 4664\n",
            "loss: 38.033138275146484\n",
            "step: 4665\n",
            "loss: 40.533836364746094\n",
            "step: 4666\n",
            "loss: 42.658592224121094\n",
            "step: 4667\n",
            "loss: 29.780803680419922\n",
            "step: 4668\n",
            "loss: 36.522422790527344\n",
            "step: 4669\n",
            "loss: 37.14824676513672\n",
            "step: 4670\n",
            "loss: 37.96807861328125\n",
            "step: 4671\n",
            "loss: 48.898494720458984\n",
            "step: 4672\n",
            "loss: 54.39582824707031\n",
            "step: 4673\n",
            "loss: 71.14656066894531\n",
            "step: 4674\n",
            "loss: 30.76723861694336\n",
            "step: 4675\n",
            "loss: 42.88373565673828\n",
            "step: 4676\n",
            "loss: 62.446678161621094\n",
            "step: 4677\n",
            "loss: 47.02626037597656\n",
            "step: 4678\n",
            "loss: 63.90823745727539\n",
            "step: 4679\n",
            "loss: 37.498191833496094\n",
            "step: 4680\n",
            "loss: 43.541656494140625\n",
            "step: 4681\n",
            "loss: 50.08518981933594\n",
            "step: 4682\n",
            "loss: 54.886932373046875\n",
            "step: 4683\n",
            "loss: 28.663610458374023\n",
            "step: 4684\n",
            "loss: 26.340003967285156\n",
            "step: 4685\n",
            "loss: 52.10259246826172\n",
            "step: 4686\n",
            "loss: 44.26483917236328\n",
            "step: 4687\n",
            "loss: 46.6598014831543\n",
            "step: 4688\n",
            "loss: 39.40907287597656\n",
            "step: 4689\n",
            "loss: 53.914039611816406\n",
            "step: 4690\n",
            "loss: 22.343994140625\n",
            "step: 4691\n",
            "loss: 42.94243621826172\n",
            "step: 4692\n",
            "loss: 27.144054412841797\n",
            "step: 4693\n",
            "loss: 49.65521240234375\n",
            "step: 4694\n",
            "loss: 51.84175491333008\n",
            "step: 4695\n",
            "loss: 39.17850112915039\n",
            "step: 4696\n",
            "loss: 44.066856384277344\n",
            "step: 4697\n",
            "loss: 56.689205169677734\n",
            "step: 4698\n",
            "loss: 40.63916778564453\n",
            "step: 4699\n",
            "loss: 35.39080810546875\n",
            "step: 4700\n",
            "loss: 32.48835754394531\n",
            "step: 4701\n",
            "loss: 61.73232650756836\n",
            "step: 4702\n",
            "loss: 38.23512268066406\n",
            "step: 4703\n",
            "loss: 40.97631072998047\n",
            "step: 4704\n",
            "loss: 34.1655387878418\n",
            "step: 4705\n",
            "loss: 44.68659973144531\n",
            "step: 4706\n",
            "loss: 53.062721252441406\n",
            "step: 4707\n",
            "loss: 51.33745193481445\n",
            "step: 4708\n",
            "loss: 62.18471145629883\n",
            "step: 4709\n",
            "loss: 32.609710693359375\n",
            "step: 4710\n",
            "loss: 36.932064056396484\n",
            "step: 4711\n",
            "loss: 26.11178207397461\n",
            "step: 4712\n",
            "loss: 55.62840270996094\n",
            "step: 4713\n",
            "loss: 47.10789489746094\n",
            "step: 4714\n",
            "loss: 49.09081268310547\n",
            "step: 4715\n",
            "loss: 41.64722442626953\n",
            "step: 4716\n",
            "loss: 32.43363571166992\n",
            "step: 4717\n",
            "loss: 53.72357940673828\n",
            "step: 4718\n",
            "loss: 30.966915130615234\n",
            "step: 4719\n",
            "loss: 51.84184265136719\n",
            "step: 4720\n",
            "loss: 58.6503791809082\n",
            "step: 4721\n",
            "loss: 32.942893981933594\n",
            "step: 4722\n",
            "loss: 49.312530517578125\n",
            "step: 4723\n",
            "loss: 40.61865997314453\n",
            "step: 4724\n",
            "loss: 41.85673522949219\n",
            "step: 4725\n",
            "loss: 48.75666809082031\n",
            "step: 4726\n",
            "loss: 37.867713928222656\n",
            "step: 4727\n",
            "loss: 28.93739128112793\n",
            "step: 4728\n",
            "loss: 35.30696487426758\n",
            "step: 4729\n",
            "loss: 44.81788635253906\n",
            "step: 4730\n",
            "loss: 49.846099853515625\n",
            "step: 4731\n",
            "loss: 49.38154220581055\n",
            "step: 4732\n",
            "loss: 52.82902526855469\n",
            "step: 4733\n",
            "loss: 51.48282241821289\n",
            "step: 4734\n",
            "loss: 51.95917892456055\n",
            "step: 4735\n",
            "loss: 62.456390380859375\n",
            "step: 4736\n",
            "loss: 53.030250549316406\n",
            "step: 4737\n",
            "loss: 34.90730285644531\n",
            "step: 4738\n",
            "loss: 46.181724548339844\n",
            "step: 4739\n",
            "loss: 56.85136032104492\n",
            "step: 4740\n",
            "loss: 46.039756774902344\n",
            "step: 4741\n",
            "loss: 43.89425277709961\n",
            "step: 4742\n",
            "loss: 38.55867004394531\n",
            "step: 4743\n",
            "loss: 38.748016357421875\n",
            "step: 4744\n",
            "loss: 53.52100372314453\n",
            "step: 4745\n",
            "loss: 35.31913757324219\n",
            "step: 4746\n",
            "loss: 36.229156494140625\n",
            "step: 4747\n",
            "loss: 32.94359588623047\n",
            "step: 4748\n",
            "loss: 30.66497039794922\n",
            "step: 4749\n",
            "loss: 60.072532653808594\n",
            "step: 4750\n",
            "loss: 41.571537017822266\n",
            "step: 4751\n",
            "loss: 36.76953125\n",
            "step: 4752\n",
            "loss: 45.0053596496582\n",
            "step: 4753\n",
            "loss: 45.726219177246094\n",
            "step: 4754\n",
            "loss: 46.71790313720703\n",
            "step: 4755\n",
            "loss: 43.03266906738281\n",
            "step: 4756\n",
            "loss: 38.62239456176758\n",
            "step: 4757\n",
            "loss: 42.11381149291992\n",
            "step: 4758\n",
            "loss: 44.42936706542969\n",
            "step: 4759\n",
            "loss: 50.034339904785156\n",
            "step: 4760\n",
            "loss: 52.85565948486328\n",
            "step: 4761\n",
            "loss: 51.39623260498047\n",
            "step: 4762\n",
            "loss: 53.44385528564453\n",
            "step: 4763\n",
            "loss: 56.21757507324219\n",
            "step: 4764\n",
            "loss: 33.69751739501953\n",
            "step: 4765\n",
            "loss: 51.17034912109375\n",
            "step: 4766\n",
            "loss: 60.559471130371094\n",
            "step: 4767\n",
            "loss: 34.47670364379883\n",
            "step: 4768\n",
            "loss: 41.1588249206543\n",
            "step: 4769\n",
            "loss: 51.3298454284668\n",
            "step: 4770\n",
            "loss: 41.770042419433594\n",
            "step: 4771\n",
            "loss: 33.38008117675781\n",
            "step: 4772\n",
            "loss: 62.47868347167969\n",
            "step: 4773\n",
            "loss: 39.15782928466797\n",
            "step: 4774\n",
            "loss: 50.269065856933594\n",
            "step: 4775\n",
            "loss: 46.50692367553711\n",
            "step: 4776\n",
            "loss: 42.754241943359375\n",
            "step: 4777\n",
            "loss: 54.93828201293945\n",
            "step: 4778\n",
            "loss: 60.51922607421875\n",
            "step: 4779\n",
            "loss: 49.447898864746094\n",
            "step: 4780\n",
            "loss: 44.44308090209961\n",
            "step: 4781\n",
            "loss: 44.92823028564453\n",
            "step: 4782\n",
            "loss: 60.06946563720703\n",
            "step: 4783\n",
            "loss: 45.7752571105957\n",
            "step: 4784\n",
            "loss: 61.0998649597168\n",
            "step: 4785\n",
            "loss: 64.63648986816406\n",
            "step: 4786\n",
            "loss: 54.82471466064453\n",
            "step: 4787\n",
            "loss: 59.253013610839844\n",
            "step: 4788\n",
            "loss: 35.73064041137695\n",
            "step: 4789\n",
            "loss: 60.025657653808594\n",
            "step: 4790\n",
            "loss: 61.179473876953125\n",
            "step: 4791\n",
            "loss: 56.45590591430664\n",
            "step: 4792\n",
            "loss: 66.70291137695312\n",
            "step: 4793\n",
            "loss: 66.788330078125\n",
            "step: 4794\n",
            "loss: 61.13898849487305\n",
            "step: 4795\n",
            "loss: 48.17300796508789\n",
            "step: 4796\n",
            "loss: 45.828556060791016\n",
            "step: 4797\n",
            "loss: 28.15072250366211\n",
            "step: 4798\n",
            "loss: 35.33362579345703\n",
            "step: 4799\n",
            "loss: 40.610862731933594\n",
            "step: 4800\n",
            "loss: 70.11878967285156\n",
            "step: 4801\n",
            "loss: 45.56098937988281\n",
            "step: 4802\n",
            "loss: 38.65863037109375\n",
            "step: 4803\n",
            "loss: 29.2249755859375\n",
            "step: 4804\n",
            "loss: 42.93410110473633\n",
            "step: 4805\n",
            "loss: 54.63521957397461\n",
            "step: 4806\n",
            "loss: 43.86260223388672\n",
            "step: 4807\n",
            "loss: 45.00419616699219\n",
            "step: 4808\n",
            "loss: 35.74897384643555\n",
            "step: 4809\n",
            "loss: 46.33460998535156\n",
            "step: 4810\n",
            "loss: 49.059288024902344\n",
            "step: 4811\n",
            "loss: 34.6196174621582\n",
            "step: 4812\n",
            "loss: 40.99911880493164\n",
            "step: 4813\n",
            "loss: 42.08750915527344\n",
            "step: 4814\n",
            "loss: 44.5203742980957\n",
            "step: 4815\n",
            "loss: 44.544837951660156\n",
            "step: 4816\n",
            "loss: 87.50328826904297\n",
            "step: 4817\n",
            "loss: 43.20310974121094\n",
            "step: 4818\n",
            "loss: 62.716636657714844\n",
            "step: 4819\n",
            "loss: 40.046836853027344\n",
            "step: 4820\n",
            "loss: 41.63801956176758\n",
            "step: 4821\n",
            "loss: 32.22050094604492\n",
            "step: 4822\n",
            "loss: 37.97140884399414\n",
            "step: 4823\n",
            "loss: 40.80345153808594\n",
            "step: 4824\n",
            "loss: 62.99293518066406\n",
            "step: 4825\n",
            "loss: 37.779930114746094\n",
            "step: 4826\n",
            "loss: 54.712623596191406\n",
            "step: 4827\n",
            "loss: 53.06626510620117\n",
            "step: 4828\n",
            "loss: 31.30144691467285\n",
            "step: 4829\n",
            "loss: 53.8988037109375\n",
            "step: 4830\n",
            "loss: 48.40911865234375\n",
            "step: 4831\n",
            "loss: 40.855430603027344\n",
            "step: 4832\n",
            "loss: 39.48613357543945\n",
            "step: 4833\n",
            "loss: 45.39641571044922\n",
            "step: 4834\n",
            "loss: 50.01130676269531\n",
            "step: 4835\n",
            "loss: 34.70076370239258\n",
            "step: 4836\n",
            "loss: 33.97913360595703\n",
            "step: 4837\n",
            "loss: 44.186248779296875\n",
            "step: 4838\n",
            "loss: 57.46012878417969\n",
            "step: 4839\n",
            "loss: 69.79945373535156\n",
            "step: 4840\n",
            "loss: 59.49770736694336\n",
            "step: 4841\n",
            "loss: 53.95845413208008\n",
            "step: 4842\n",
            "loss: 41.5511474609375\n",
            "step: 4843\n",
            "loss: 49.71729278564453\n",
            "step: 4844\n",
            "loss: 51.205142974853516\n",
            "step: 4845\n",
            "loss: 39.21867370605469\n",
            "step: 4846\n",
            "loss: 49.88899612426758\n",
            "step: 4847\n",
            "loss: 71.05010986328125\n",
            "step: 4848\n",
            "loss: 51.98518371582031\n",
            "step: 4849\n",
            "loss: 43.666229248046875\n",
            "step: 4850\n",
            "loss: 33.06640625\n",
            "step: 4851\n",
            "loss: 42.37815475463867\n",
            "step: 4852\n",
            "loss: 38.72248840332031\n",
            "step: 4853\n",
            "loss: 46.20656967163086\n",
            "step: 4854\n",
            "loss: 54.633827209472656\n",
            "step: 4855\n",
            "loss: 49.441200256347656\n",
            "step: 4856\n",
            "loss: 30.467082977294922\n",
            "step: 4857\n",
            "loss: 45.00897216796875\n",
            "step: 4858\n",
            "loss: 45.08815002441406\n",
            "step: 4859\n",
            "loss: 46.648841857910156\n",
            "step: 4860\n",
            "loss: 59.74463653564453\n",
            "step: 4861\n",
            "loss: 56.40807342529297\n",
            "step: 4862\n",
            "loss: 60.75522232055664\n",
            "step: 4863\n",
            "loss: 27.020599365234375\n",
            "step: 4864\n",
            "loss: 40.32817459106445\n",
            "step: 4865\n",
            "loss: 46.93704605102539\n",
            "step: 4866\n",
            "loss: 57.76580810546875\n",
            "step: 4867\n",
            "loss: 59.35555648803711\n",
            "step: 4868\n",
            "loss: 42.959625244140625\n",
            "step: 4869\n",
            "loss: 61.16975402832031\n",
            "step: 4870\n",
            "loss: 40.487545013427734\n",
            "step: 4871\n",
            "loss: 48.11122131347656\n",
            "step: 4872\n",
            "loss: 39.56211471557617\n",
            "step: 4873\n",
            "loss: 43.37532043457031\n",
            "step: 4874\n",
            "loss: 51.729454040527344\n",
            "step: 4875\n",
            "loss: 52.606929779052734\n",
            "step: 4876\n",
            "loss: 50.786888122558594\n",
            "step: 4877\n",
            "loss: 62.06049346923828\n",
            "step: 4878\n",
            "loss: 50.79301452636719\n",
            "step: 4879\n",
            "loss: 34.130821228027344\n",
            "step: 4880\n",
            "loss: 44.37099838256836\n",
            "step: 4881\n",
            "loss: 44.658546447753906\n",
            "step: 4882\n",
            "loss: 31.12601089477539\n",
            "step: 4883\n",
            "loss: 54.56465530395508\n",
            "step: 4884\n",
            "loss: 38.88475799560547\n",
            "step: 4885\n",
            "loss: 57.95448303222656\n",
            "step: 4886\n",
            "loss: 46.233219146728516\n",
            "step: 4887\n",
            "loss: 43.51840591430664\n",
            "step: 4888\n",
            "loss: 39.614227294921875\n",
            "step: 4889\n",
            "loss: 38.6468505859375\n",
            "step: 4890\n",
            "loss: 44.19190216064453\n",
            "step: 4891\n",
            "loss: 28.29739761352539\n",
            "step: 4892\n",
            "loss: 53.48832321166992\n",
            "step: 4893\n",
            "loss: 55.05183410644531\n",
            "step: 4894\n",
            "loss: 41.90732955932617\n",
            "step: 4895\n",
            "loss: 35.82556915283203\n",
            "step: 4896\n",
            "loss: 54.87134552001953\n",
            "step: 4897\n",
            "loss: 35.99200439453125\n",
            "step: 4898\n",
            "loss: 26.45147705078125\n",
            "step: 4899\n",
            "loss: 46.1363639831543\n",
            "step: 4900\n",
            "loss: 48.41344451904297\n",
            "step: 4901\n",
            "loss: 59.40330123901367\n",
            "step: 4902\n",
            "loss: 34.47658920288086\n",
            "step: 4903\n",
            "loss: 51.016685485839844\n",
            "step: 4904\n",
            "loss: 66.541015625\n",
            "step: 4905\n",
            "loss: 46.75153350830078\n",
            "step: 4906\n",
            "loss: 34.9677734375\n",
            "step: 4907\n",
            "loss: 48.0806884765625\n",
            "step: 4908\n",
            "loss: 46.29841995239258\n",
            "step: 4909\n",
            "loss: 70.7811279296875\n",
            "step: 4910\n",
            "loss: 51.263343811035156\n",
            "step: 4911\n",
            "loss: 22.41142463684082\n",
            "step: 4912\n",
            "loss: 69.56645965576172\n",
            "step: 4913\n",
            "loss: 58.551387786865234\n",
            "step: 4914\n",
            "loss: 39.72364044189453\n",
            "step: 4915\n",
            "loss: 27.48301124572754\n",
            "step: 4916\n",
            "loss: 50.91285705566406\n",
            "step: 4917\n",
            "loss: 44.288787841796875\n",
            "step: 4918\n",
            "loss: 60.07445526123047\n",
            "step: 4919\n",
            "loss: 38.79734420776367\n",
            "step: 4920\n",
            "loss: 42.674835205078125\n",
            "step: 4921\n",
            "loss: 28.91735076904297\n",
            "step: 4922\n",
            "loss: 38.347015380859375\n",
            "step: 4923\n",
            "loss: 38.64745330810547\n",
            "step: 4924\n",
            "loss: 46.44481658935547\n",
            "step: 4925\n",
            "loss: 48.81822967529297\n",
            "step: 4926\n",
            "loss: 44.407161712646484\n",
            "step: 4927\n",
            "loss: 37.294517517089844\n",
            "step: 4928\n",
            "loss: 53.32184982299805\n",
            "step: 4929\n",
            "loss: 35.85152053833008\n",
            "step: 4930\n",
            "loss: 28.2329158782959\n",
            "step: 4931\n",
            "loss: 59.04381561279297\n",
            "step: 4932\n",
            "loss: 36.55028533935547\n",
            "step: 4933\n",
            "loss: 35.877525329589844\n",
            "step: 4934\n",
            "loss: 26.14657974243164\n",
            "step: 4935\n",
            "loss: 52.8397331237793\n",
            "step: 4936\n",
            "loss: 51.22606658935547\n",
            "step: 4937\n",
            "loss: 51.14954376220703\n",
            "step: 4938\n",
            "loss: 24.34770393371582\n",
            "step: 4939\n",
            "loss: 62.23471450805664\n",
            "step: 4940\n",
            "loss: 28.916454315185547\n",
            "step: 4941\n",
            "loss: 44.294647216796875\n",
            "step: 4942\n",
            "loss: 46.48719024658203\n",
            "step: 4943\n",
            "loss: 27.59308624267578\n",
            "step: 4944\n",
            "loss: 31.330808639526367\n",
            "step: 4945\n",
            "loss: 33.187232971191406\n",
            "step: 4946\n",
            "loss: 29.552093505859375\n",
            "step: 4947\n",
            "loss: 31.703224182128906\n",
            "step: 4948\n",
            "loss: 40.2639274597168\n",
            "step: 4949\n",
            "loss: 58.056419372558594\n",
            "step: 4950\n",
            "loss: 48.787574768066406\n",
            "step: 4951\n",
            "loss: 28.110610961914062\n",
            "step: 4952\n",
            "loss: 49.78276824951172\n",
            "step: 4953\n",
            "loss: 47.82539367675781\n",
            "step: 4954\n",
            "loss: 33.16999053955078\n",
            "step: 4955\n",
            "loss: 34.295066833496094\n",
            "step: 4956\n",
            "loss: 35.42716979980469\n",
            "step: 4957\n",
            "loss: 43.82828140258789\n",
            "step: 4958\n",
            "loss: 27.09804344177246\n",
            "step: 4959\n",
            "loss: 28.493274688720703\n",
            "step: 4960\n",
            "loss: 57.642364501953125\n",
            "step: 4961\n",
            "loss: 41.420692443847656\n",
            "step: 4962\n",
            "loss: 50.802433013916016\n",
            "step: 4963\n",
            "loss: 52.29158020019531\n",
            "step: 4964\n",
            "loss: 40.17280578613281\n",
            "step: 4965\n",
            "loss: 48.82807159423828\n",
            "step: 4966\n",
            "loss: 55.33930969238281\n",
            "step: 4967\n",
            "loss: 49.52378845214844\n",
            "step: 4968\n",
            "loss: 49.87308120727539\n",
            "step: 4969\n",
            "loss: 35.571834564208984\n",
            "step: 4970\n",
            "loss: 43.13002014160156\n",
            "step: 4971\n",
            "loss: 51.2373046875\n",
            "step: 4972\n",
            "loss: 37.08188247680664\n",
            "step: 4973\n",
            "loss: 54.388431549072266\n",
            "step: 4974\n",
            "loss: 56.0378532409668\n",
            "step: 4975\n",
            "loss: 26.379629135131836\n",
            "step: 4976\n",
            "loss: 58.366065979003906\n",
            "step: 4977\n",
            "loss: 50.7907829284668\n",
            "step: 4978\n",
            "loss: 45.87265396118164\n",
            "step: 4979\n",
            "loss: 40.182525634765625\n",
            "step: 4980\n",
            "loss: 30.827388763427734\n",
            "step: 4981\n",
            "loss: 44.760009765625\n",
            "step: 4982\n",
            "loss: 45.213523864746094\n",
            "step: 4983\n",
            "loss: 38.80668640136719\n",
            "step: 4984\n",
            "loss: 57.93179702758789\n",
            "step: 4985\n",
            "loss: 53.48208999633789\n",
            "step: 4986\n",
            "loss: 61.52494812011719\n",
            "step: 4987\n",
            "loss: 42.34373474121094\n",
            "step: 4988\n",
            "loss: 33.5445442199707\n",
            "step: 4989\n",
            "loss: 51.85641098022461\n",
            "step: 4990\n",
            "loss: 47.71925735473633\n",
            "step: 4991\n",
            "loss: 36.181976318359375\n",
            "step: 4992\n",
            "loss: 42.208457946777344\n",
            "step: 4993\n",
            "loss: 37.78495407104492\n",
            "step: 4994\n",
            "loss: 46.872650146484375\n",
            "step: 4995\n",
            "loss: 34.747962951660156\n",
            "step: 4996\n",
            "loss: 42.38610076904297\n",
            "step: 4997\n",
            "loss: 48.287681579589844\n",
            "step: 4998\n",
            "loss: 45.944190979003906\n",
            "step: 4999\n",
            "loss: 43.5251579284668\n"
          ]
        }
      ],
      "source": [
        "# Тренировка сети\n",
        "\n",
        "loss_history = []  # каждые display_step шагов сохраняйте в этом список текущую ошибку нейросети\n",
        "accuracy_history = [] # каждые display_step шагов сохраняйте в этом список текущую точность нейросети\n",
        "\n",
        "# В этом цикле мы будем производить обучение нейронной сети\n",
        "# из тренировочного датасета train_data извлеките случайное подмножество, на котором \n",
        "# произведется тренировка. Используйте метод take, доступный для тренировочного датасета.\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(buffer_size)):  # train_data.take(batch_size)\n",
        "    print(f'step: {step}')  ##-\n",
        "    # Обновляем веса нейронной сети\n",
        "    train(neural_net, batch_x, batch_y, learning_rate=learning_rate)\n",
        "    pred = neural_net(batch_x)\n",
        "    current_loss = cross_entropy(pred, batch_y)\n",
        "    print(f'loss: {current_loss}')  ##-\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        # pred = neural_net(batch_x)\n",
        "        loss_history.append(current_loss)\n",
        "        accuracy_history.append(accuracy(pred, batch_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_yCBfG6MbQB2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Выведите графики зависимости изменения точности и потерь от шага\n",
        "# Если все сделано правильно, то точность должна расти, а потери уменьшаться\n",
        "\n",
        "# Место для вашего кода\n",
        "def draw_2simple_2d(x1: np.array, y1: np.array, x2: np.array, y2: np.array, suptitle: str) -> None:\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "    axs[0].plot(x1, y1)\n",
        "    axs[0].grid()\n",
        "    axs[1].plot(x1, y2)\n",
        "    fig.suptitle(suptitle)\n",
        "    # plt.legend()\n",
        "    # plt.grid()\n",
        "    axs[1].grid()\n",
        "\n",
        "\n",
        "x = np.array([point * display_step for point in range(len(loss_history))])\n",
        "\n",
        "draw_2simple_2d(x, loss_history, x, accuracy_history, suptitle='loss_history & accuracy_history')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE3g4gDyUSNY"
      },
      "outputs": [],
      "source": [
        "# Вычислите точность обученной нейросети\n",
        "\n",
        "# Место для вашего кода"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EEHAubOUSNY"
      },
      "outputs": [],
      "source": [
        "# Протестируем обученную нейросеть на 10 изображениях. Из тестовой выборки возьмите 5 \n",
        "# случайных изображений и передайте их в нейронню сеть.\n",
        "# Выведите изображение и выпишите рядом ответ нейросети.\n",
        "# Сделайте вывод о том ошибается ли ваша нейронная сеть и если да, то как часто?\n",
        "\n",
        "# Место для вашего кода"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tensorflow_mnist_hw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
