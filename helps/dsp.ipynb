{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Name__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description & tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 10:00:32.481837: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-15 10:00:32.504008: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-15 10:00:32.671606: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-15 10:00:32.672809: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 10:00:33.460386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math \n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.activations import mish, relu, sigmoid, softmax\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`OBTAIN` & `SCRUB`__ (DATASET)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Loading the prepared:`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28),\n",
       " (5000, 28, 28),\n",
       " (5000, 28, 28),\n",
       " (60000, 10),\n",
       " (5000, 10),\n",
       " (5000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(images_train, labels_train), (images_test, labels_test) = fashion_mnist.load_data()\n",
    "# images_train.dtype, images_train[0].shape\n",
    "NUM_FEATURES = images_train[0].shape[0] * images_train[0].shape[1]\n",
    "# NUM_FEATURES\n",
    "images_train, images_test = np.array(images_train, np.float32), np.array(images_test, np.float32)  # .astype('float32')\n",
    "# print(min(images_train.min(), images_test.min()))  # 0  255\n",
    "maximum = max(images_train.max(), images_test.max()) # np.max([images_train.max(), images_test.max()]) \n",
    "# Normalize (min = 0):\n",
    "images_train, images_test = images_train / maximum, images_test / maximum\n",
    "# images_train.shape, images_test.shape, labels_train.shape, labels_test.shape\n",
    "max(labels_train.max(), labels_test.max()), min(labels_train.min(), labels_test.min())  # 0  9\n",
    "NUM_CLASSES = len(set(np.concatenate((labels_train, labels_test), axis=0)))  # 10\n",
    "# (10000, 10) into ((5000, 10), (5000, 10)):\n",
    "images_valid, images_test, labels_valid, labels_test = train_test_split(\n",
    "                                                                        images_test, \n",
    "                                                                        labels_test, \n",
    "                                                                        test_size=0.5,  # 50%\n",
    "                                                                        shuffle=True, \n",
    "                                                                        stratify=labels_test\n",
    "                                                                        )  # (stratify для рівномірного розподілу за значенням y)\n",
    "labels_train = tf.one_hot(labels_train, depth=NUM_CLASSES).numpy()  # 5 into [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "labels_test = tf.one_hot(labels_test, depth=NUM_CLASSES).numpy()\n",
    "labels_valid = tf.one_hot(labels_valid, depth=NUM_CLASSES).numpy()\n",
    "# labels_train.shape, labels_test.shape, labels_valid.shape  # ((60000, 10), (5000, 10), (5000, 10))\n",
    "images_train.shape, images_test.shape, images_valid.shape, labels_train.shape, labels_test.shape, labels_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Loading from 'RAW-files':`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Loading from files:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`EXPLORE`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`MODEL`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`INTERPRET`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`RE-TEST`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __`RESULTS` & `CONCLUSIONS`__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datas-cYPLqW4U-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
